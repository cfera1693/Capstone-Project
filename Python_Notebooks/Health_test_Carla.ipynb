{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Health_test_Carla.ipynb","provenance":[{"file_id":"1gXauiG3I8WGAOVUTP2dH2IR64X50-Mbv","timestamp":1595441775613}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ebb69da96c8341f5889b2b86d044a6a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_caa468e3d9f743879ca3aa7b442e1445","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eb18feece1324188bd2303ee32dd5611","IPY_MODEL_861131d5d053432e9ab48a7714bf43c4"]}},"caa468e3d9f743879ca3aa7b442e1445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb18feece1324188bd2303ee32dd5611":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2f4c280485aa4b8ba010474bddc93ce3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c234dde75634be58a27572e5bee418f"}},"861131d5d053432e9ab48a7714bf43c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5994febc1e0b411b87791cfc1a0640ac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:10&lt;00:00, 40.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98b0e570645b49ddb9921234e4841348"}},"2f4c280485aa4b8ba010474bddc93ce3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7c234dde75634be58a27572e5bee418f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5994febc1e0b411b87791cfc1a0640ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"98b0e570645b49ddb9921234e4841348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1fb4ee6dface4909b88d1aa0f1854db4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_521686e14fa94718aceeaa7bc57e495c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bb0b0ddcd80f449e83e328292cd30a06","IPY_MODEL_e516b1c6602d40b9afe949400a579115"]}},"521686e14fa94718aceeaa7bc57e495c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb0b0ddcd80f449e83e328292cd30a06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_09948dbeb9b148238d54451ff1ca1c8b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f07b2909218b4e41bd2f5d04d52743cb"}},"e516b1c6602d40b9afe949400a579115":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ce793514380a48c2ba2fdeeaf311e1e8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 44.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c95196c527745d9a757f9006ae390e4"}},"09948dbeb9b148238d54451ff1ca1c8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f07b2909218b4e41bd2f5d04d52743cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce793514380a48c2ba2fdeeaf311e1e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c95196c527745d9a757f9006ae390e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"506069f72e1f4c318cba79d2c3f83bd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_61d66f38e47142dd8ffd61e418b84d24","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c67a7379a1d1496eb5dc7904891e457f","IPY_MODEL_e75b43db7ec14359b97978c0b369518c"]}},"61d66f38e47142dd8ffd61e418b84d24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c67a7379a1d1496eb5dc7904891e457f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c92db3f7d2d34aaa9846174735910fac","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47d7550a46ec43c4bb788b40560fcbff"}},"e75b43db7ec14359b97978c0b369518c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_27eece68fe0d4c61b9f15f426de2aace","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 302kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_117f09a09cb4400fbb98849c113e3c5d"}},"c92db3f7d2d34aaa9846174735910fac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"47d7550a46ec43c4bb788b40560fcbff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27eece68fe0d4c61b9f15f426de2aace":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"117f09a09cb4400fbb98849c113e3c5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"xqxKY-UFy8uP","colab_type":"text"},"source":["# **First Test - No Augmentation**"]},{"cell_type":"code","metadata":{"id":"L-Bnqn00VGfY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":641},"executionInfo":{"status":"ok","timestamp":1596593809257,"user_tz":420,"elapsed":11058,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"2cecdc16-6f42-4e91-cc0e-a67d86e9477d"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 14.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 13.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 40.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=1b187619775cf29091fd8836efad45c342ca4028c8ac59bc1f7b8026efae9a8f\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"67970XzEVCAL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596593816904,"user_tz":420,"elapsed":6674,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["import torch\n","import transformers\n","# per the setting of transformers, to use any of its NLP model\n","# we need to have three things: that is BertTokenizer, BertModel, BertConfig\n","from transformers import BertTokenizer, BertModel, BertConfig"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4socdVzVEHS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596593818474,"user_tz":420,"elapsed":647,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"17367ec8-ae38-4341-91a0-5924c0744e3f"},"source":["# first, let's see if we have GPU so that we could train our model in GPU\n","# GPU is really at parallel computation\n","from torch import cuda\n","if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","  print(device)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"59RK1lkXU9NH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1596593842566,"user_tz":420,"elapsed":22756,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"30f5bc70-6d3c-4581-bca6-f7e2b85fc614"},"source":["# collect Google Drive to Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o2L80RjhU9s_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["ebb69da96c8341f5889b2b86d044a6a5","caa468e3d9f743879ca3aa7b442e1445","eb18feece1324188bd2303ee32dd5611","861131d5d053432e9ab48a7714bf43c4","2f4c280485aa4b8ba010474bddc93ce3","7c234dde75634be58a27572e5bee418f","5994febc1e0b411b87791cfc1a0640ac","98b0e570645b49ddb9921234e4841348","1fb4ee6dface4909b88d1aa0f1854db4","521686e14fa94718aceeaa7bc57e495c","bb0b0ddcd80f449e83e328292cd30a06","e516b1c6602d40b9afe949400a579115","09948dbeb9b148238d54451ff1ca1c8b","f07b2909218b4e41bd2f5d04d52743cb","ce793514380a48c2ba2fdeeaf311e1e8","3c95196c527745d9a757f9006ae390e4"]},"executionInfo":{"status":"ok","timestamp":1596593859047,"user_tz":420,"elapsed":15693,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"622a70e4-bcb7-474f-805b-9280dba16f30"},"source":["# create an instance of BERT model \n","# note that it takes time to download the BERT model (~ 440M)\n","# BERT model is big, because it has a lot of paramters. \n","model = BertModel.from_pretrained('bert-base-uncased')"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebb69da96c8341f5889b2b86d044a6a5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fb4ee6dface4909b88d1aa0f1854db4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PKo8Z3XUYKJ_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["506069f72e1f4c318cba79d2c3f83bd6","61d66f38e47142dd8ffd61e418b84d24","c67a7379a1d1496eb5dc7904891e457f","e75b43db7ec14359b97978c0b369518c","c92db3f7d2d34aaa9846174735910fac","47d7550a46ec43c4bb788b40560fcbff","27eece68fe0d4c61b9f15f426de2aace","117f09a09cb4400fbb98849c113e3c5d"]},"executionInfo":{"status":"ok","timestamp":1596593862658,"user_tz":420,"elapsed":3599,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"b17ffce9-8333-4177-8ac0-7546480e4551"},"source":["# creat an instance of BERT tokenizer\n","# as you can tell, the tokenizer is pretty small, only 232k in size\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"506069f72e1f4c318cba79d2c3f83bd6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NyhRDyuDUGwu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":893},"executionInfo":{"status":"ok","timestamp":1596404059924,"user_tz":420,"elapsed":1519,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"e9766193-a536-4bd3-c742-30639e1c9869"},"source":["import pandas as pd\n","import numpy as np\n","\n","url = 'amazon_data.csv'\n","raw_review = pd.read_csv(url)\n","raw_review"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>marketplace</th>\n","      <th>customer_id</th>\n","      <th>review_id</th>\n","      <th>product_id</th>\n","      <th>product_parent</th>\n","      <th>product_title</th>\n","      <th>product_category</th>\n","      <th>star_rating</th>\n","      <th>helpful_votes</th>\n","      <th>total_votes</th>\n","      <th>vine</th>\n","      <th>verified_purchase</th>\n","      <th>review_headline</th>\n","      <th>review_body</th>\n","      <th>review_date</th>\n","      <th>social connectedness</th>\n","      <th>environment</th>\n","      <th>self_sufficiency</th>\n","      <th>transparency_authenticity</th>\n","      <th>tradition</th>\n","      <th>individuality</th>\n","      <th>diversity_equality</th>\n","      <th>privacy</th>\n","      <th>status</th>\n","      <th>thrift_value</th>\n","      <th>innovation</th>\n","      <th>fun_adventure</th>\n","      <th>health</th>\n","      <th>Unnamed: 29</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3525027</td>\n","      <td>US</td>\n","      <td>3145405</td>\n","      <td>R1Y9RICO8ZJ81Y</td>\n","      <td>B008TV4BTI</td>\n","      <td>324530391.0</td>\n","      <td>BOSS HUGO BOSS Men's Starfish Swim Trunk</td>\n","      <td>Apparel</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Good quality</td>\n","      <td>The quality is good, fits good but I didnt pay...</td>\n","      <td>2014-06-23</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5120532</td>\n","      <td>US</td>\n","      <td>67557</td>\n","      <td>R1KSZIZUI25LXF</td>\n","      <td>B002JLFMLK</td>\n","      <td>109099956.0</td>\n","      <td>Vedette Megane Firm Compression Sensual Corset...</td>\n","      <td>Apparel</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>I like this bodyshaper.</td>\n","      <td>This body shaper does what it says. It makes y...</td>\n","      <td>2013-09-01</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>523451</td>\n","      <td>US</td>\n","      <td>13232823</td>\n","      <td>RK6JCVD27KHG5</td>\n","      <td>B00OO1GHLM</td>\n","      <td>600113027.0</td>\n","      <td>Adult Stilinski 24 Beacon Hills Lacrosse 2-Sid...</td>\n","      <td>Apparel</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Nice hoodie</td>\n","      <td>It looks well made.  I bought it for my grandd...</td>\n","      <td>2015-08-03</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3620630</td>\n","      <td>US</td>\n","      <td>10055103</td>\n","      <td>R3HZ4WB8L7URPG</td>\n","      <td>B008G7JOBA</td>\n","      <td>381781741.0</td>\n","      <td>Carhartt Men's Sherpa Lined Sandstone Hooded M...</td>\n","      <td>Apparel</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Size Small Means Medium</td>\n","      <td>Other than the sizing that is bigger than the ...</td>\n","      <td>2014-10-02</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2464514</td>\n","      <td>US</td>\n","      <td>15251195</td>\n","      <td>R1MTD681OUV0K9</td>\n","      <td>B00DUK7SLQ</td>\n","      <td>571539834.0</td>\n","      <td>Roxy Juniors Gallery Backpack</td>\n","      <td>Apparel</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Five Stars</td>\n","      <td>Love my backpack.</td>\n","      <td>2014-09-15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1654</th>\n","      <td>85384</td>\n","      <td>US</td>\n","      <td>4752121</td>\n","      <td>R29BY4XZPERCRE</td>\n","      <td>B00AMFTLLW</td>\n","      <td>660000000.0</td>\n","      <td>Virus Removal Service - Jupiter Support</td>\n","      <td>Software</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>IE issue</td>\n","      <td>i just got done with jupiter on i script prob ...</td>\n","      <td>4/26/2014</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1655</th>\n","      <td>200758</td>\n","      <td>US</td>\n","      <td>22733472</td>\n","      <td>R3THOGV2C7919H</td>\n","      <td>B0041DTNI2</td>\n","      <td>474000000.0</td>\n","      <td>Family Tree Maker 2011 Deluxe [Old Version]</td>\n","      <td>Software</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>Not for use on a netbook</td>\n","      <td>I used this software on my netbook and it divi...</td>\n","      <td>9/23/2011</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1656</th>\n","      <td>230985</td>\n","      <td>US</td>\n","      <td>14537207</td>\n","      <td>R2UNXHF3TG8YKM</td>\n","      <td>B001BSGC3Y</td>\n","      <td>834000000.0</td>\n","      <td>Learn Italian: Fluenz Italian 1 for Mac, PC, i...</td>\n","      <td>Software</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>awesome program</td>\n","      <td>hi, Just want to say it what a great company! ...</td>\n","      <td>4/30/2010</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1657</th>\n","      <td>262294</td>\n","      <td>US</td>\n","      <td>50325594</td>\n","      <td>R1I59RZ3O0O36Z</td>\n","      <td>B0018EI3I8</td>\n","      <td>852000000.0</td>\n","      <td>Kaspersky Internet Security 2009 (3 User)</td>\n","      <td>Software</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Great product</td>\n","      <td>Great internet security product. I guess the b...</td>\n","      <td>12/22/2008</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1658</th>\n","      <td>124359</td>\n","      <td>US</td>\n","      <td>39157929</td>\n","      <td>R1S99QSP8AAWDF</td>\n","      <td>B008TND0L6</td>\n","      <td>643000000.0</td>\n","      <td>Norton 360 2013 - 1 User / 3 PC</td>\n","      <td>Software</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Disapointing right out of the box</td>\n","      <td>If you are allergic to the chocolate and you a...</td>\n","      <td>9/12/2013</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1659 rows × 30 columns</p>\n","</div>"],"text/plain":["      Unnamed: 0 marketplace  customer_id  ... fun_adventure health  Unnamed: 29\n","0        3525027          US      3145405  ...             0      0          NaN\n","1        5120532          US        67557  ...             0      1          NaN\n","2         523451          US     13232823  ...             0      0          NaN\n","3        3620630          US     10055103  ...             0      1          NaN\n","4        2464514          US     15251195  ...             0      0          NaN\n","...          ...         ...          ...  ...           ...    ...          ...\n","1654       85384          US      4752121  ...             0      0          NaN\n","1655      200758          US     22733472  ...             0      0          NaN\n","1656      230985          US     14537207  ...             0      0          NaN\n","1657      262294          US     50325594  ...             0      0          NaN\n","1658      124359          US     39157929  ...             0      0          NaN\n","\n","[1659 rows x 30 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"bO_VL6_GV6gF","colab_type":"code","colab":{}},"source":["train_review = pd.DataFrame(None)\n","\n","train_review[['text','label']] = raw_review[['review_body','health']].iloc[0:1661,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4F0PknWZqxf","colab_type":"code","colab":{}},"source":["train_review = train_review.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajQpmwt2Xfds","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"ok","timestamp":1596404076658,"user_tz":420,"elapsed":1487,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"e111a007-25f8-49ed-d1a0-19af84541678"},"source":["train_review.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1658.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.068154</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.252087</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             label\n","count  1658.000000\n","mean      0.068154\n","std       0.252087\n","min       0.000000\n","25%       0.000000\n","50%       0.000000\n","75%       0.000000\n","max       1.000000"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"513Gaudcu56u","colab_type":"text"},"source":["## Define a Customized Dataset Class and Setup the Dataloader\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"luKm7Mh6vZi4","colab":{},"executionInfo":{"status":"ok","timestamp":1596593870205,"user_tz":420,"elapsed":926,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["# first let's define some key parameters we will use later\n","# note this is a relatively large number, making the training process slow, \n","# but it's necessary becuase a lot of reviews are long.\n","max_length = 128\n","# how many raw inputs we feed into the train and validation model at once\n","train_batch = 32\n","valid_batch = 32\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"APMXoM-b81B4","colab":{},"executionInfo":{"status":"ok","timestamp":1596593871710,"user_tz":420,"elapsed":919,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["# then we need to import the libraries we need\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5zOBRz6rvwfh","colab":{},"executionInfo":{"status":"ok","timestamp":1596593873171,"user_tz":420,"elapsed":627,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["class AmazonDataset(Dataset):\n","\n","  # here we want to  create a customized dataset--YelpDataset--which could take a raw text as input\n","  # and encode it in BERT's way with a tokenizer. \n","  # The tokenized input will be then fed into a BERT Model in the NN, which we will create later\n","\n","  # __init__ defines some necessary attributes for any instance created\n","  # like: the dataset with raw text reviews, what tokenizer we want to use for encoding, \n","  # the max length of sentence we need to pad or trancate\n","  def __init__(self, dataset, tokenizer, max_len):\n","    self.tokenizer = tokenizer\n","    self.data = dataset\n","    self.text = dataset.text\n","    self.label = dataset.label\n","    self.max_len = max_len\n","  \n","\n","  def __len__(self):\n","    return len(self.text)\n","\n","\n","  def __getitem__(self, index):\n","    # __getitem__ take index as input, \n","    # in general/without customizatin, it returns the sample with the index in the dataset\n","    # further we could customize its functionality, letting it to apply some operations on the \n","    # index-specified sample before return a value for us\n","    # here we use index to locate a specific review text we want to pre-process\n","    # text = str(self.text[index])\n","    # text = \" \".join(text.split())\n","    text = self.text.iloc[index]\n","\n","    # then, we put the text into a BERT encode_plus\n","    # important debug tips: \n","    # for encode_plus, to keep all the raw inputs in the same lenght\n","    # we need to specify BOTH padding and trancation in addition to max_length\n","    # the former for short sentences and the latter for long ones\n","    # failing to do either one will result in uneven lengths of encoded inputs,\n","    # which will create troubles for your dataloader in the nn training sessions\n","    outputs = self.tokenizer.encode_plus(\n","        text,\n","        max_length = self.max_len,\n","        padding = \"max_length\",\n","        truncation = \"longest_first\",\n","        # note that in some versions of transformer in you local machine, the code is \n","        # pad_to_max_length = True,\n","        # truncation_strategy = 'longest_first',\n","        # we might need to change the argument name a little to fit different version of transformers\n","        add_special_tokens = True,\n","        return_tensors = 'pt'\n","    )\n","    # recall the BERT Tokenizer session, it takes raw text as input\n","    # and return input_ids, attention_mask\n","    input_ids = outputs['input_ids']\n","    attention_mask = outputs['attention_mask']\n","    # we then store those values and put them together with the label info in the sample\n","    # as the return of the __getitem__ method\n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype = torch.long),\n","        'attention_mask': torch.tensor(attention_mask, dtype = torch.long),\n","        'label': torch.tensor(self.label.iloc[index], dtype = torch.float) \n","    }\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tZLP1R7vBuKL","colab":{}},"source":["# split the train and validate dataset\n","from sklearn.model_selection import train_test_split\n","train_raw, valid_raw = train_test_split(train_review, test_size = 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eRqVwGM5v2_d","colab":{}},"source":["# create instances of the YelpDataset for raw trianing and validate datasets\n","# recall that tokenizer has be defined by: tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') in the BERT tokenizer session\n","train_processed = AmazonDataset(train_raw, tokenizer, max_length)\n","valid_processed = AmazonDataset(valid_raw, tokenizer, max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eEl2Jkdksm4i","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596148532245,"user_tz":420,"elapsed":450,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"47677286-2226-4dbf-a6eb-2c2c00d19300"},"source":["# check the attributes and method of train_processed\n","train_processed.__len__()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1492"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s7HaY0bQCTXw","colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"status":"ok","timestamp":1596148534091,"user_tz":420,"elapsed":710,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"abfe3ac0-fe37-4f37-f812-c73b485e562e"},"source":["# test the customized Dataset instance\n","print(train_processed.__getitem__(10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'input_ids': tensor([[  101,  2023,  2003,  1037,  2152,  3737,  4031,  1998,  2200,  3733,\n","          2000, 16500,  1010,  2074,  1037, 11224, 23663,  2099,  3223,  1012,\n","          2069,  1015,  1013,  1016,  1996,  3976,  1997,  1996,  7235,  8875,\n","          2853,  2083,  1037, 27902,  3573,  1012,  2009,  2003, 24501,  7856,\n","          3468,  1999,  3976,  1998,  2009,  3369,  2306,  2048,  2420,  1012,\n","           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]]), 'label': tensor(0.)}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hvnlzcFRRcxw","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1596148535853,"user_tz":420,"elapsed":609,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"4e3a8270-9537-4633-f826-4f9f569ee17b"},"source":["# see the dimension of the pre-processed data\n","print(train_processed.__getitem__(10)['input_ids'].shape)\n","# we can use the squeeze() method to remove the axis of \"1\", a method we will use later\n","print(train_processed.__getitem__(10)['input_ids'].squeeze().shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([1, 128])\n","torch.Size([128])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k4T7kvxJEpZX","colab":{}},"source":["# important, run it again to create a new dataset loader for every NN model you train\n","# lastly, set up the dataloader that serves as a pipeline feeding pre-processed data into the neural network\n","train_sampler = RandomSampler(train_processed)\n","train_loader = DataLoader(train_processed, batch_size = train_batch, num_workers = 0)\n","valid_sampler = SequentialSampler(valid_processed)\n","valid_loader = DataLoader(valid_processed, batch_size = valid_batch, num_workers = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gl3urqqxHeH9","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596148538528,"user_tz":420,"elapsed":703,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"f988199c-1dcb-43b3-9b2c-19a16d71227b"},"source":["# exploer the attributes of dataloder\n","# length of dataloader = len(dataset)/batch size\n","print(len(train_loader))\n","print(len(valid_loader))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["47\n","6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B4yLzjne6Tm6","colab_type":"text"},"source":["## Define a Customized Neural Network with the First Hidden Layer as NLP Encoding Layer\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hLuI0Q3ZF2C2"},"source":["Up to now, we have defined the customized Dataset class that preprocess the raw input, encoding them into input_ids and attention_mask that BERT model needs. We also set up the Dataloader that feed the pre-processed data into the Neural Network we are creating now. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oGetmmKNafv5","colab":{},"executionInfo":{"status":"ok","timestamp":1596593877710,"user_tz":420,"elapsed":1173,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["# import the functions we need use in the Netwrok Model\n","import torch.nn.functional as F"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ld8Oqz5Jv43c","colab":{},"executionInfo":{"status":"ok","timestamp":1596593879061,"user_tz":420,"elapsed":861,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["# the neural network we create is a class called  YelpBERT, which inherits\n","# the attributes and structures of the torch.nn.Module\n","\n","# the __init__ functino defines the necessary hidden layers of the NN\n","# and the forward function set up the computation graph: the real calculation procedures of the NN\n","# see the class session 7's slides and recording for details \n","\n","class AmazonBERT(torch.nn.Module):\n","  def __init__(self):\n","    super(AmazonBERT, self).__init__()\n","    # recall that, we have defined model as: model = BertModel.from_pretrained('bert-base-uncased')\n","    # see BERT Model's input and output: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n","    self.l1 = model\n","\n","    # with this layer a percentage of all neurons will be randomly turned-off to prevent overfitting\n","    # since our training dataset might be small, we really cannot afford a large neural network\n","    # the output of the BERT layer is a vector of 768 elements, if fully connected to next linear layer\n","    # then the current layer would have 768 neurons, too much! \n","    # using dropout mechanism, we can randomly turn off a percentage of the neuraon in the training process\n","    # literally reduced the number of neuron in the layer\n","    self.l2 = torch.nn.Dropout(0.3) \n","\n","    # if you want to have multiple fully connected linear layer, use this\n","    # self.l2 = torch.nn.Linear(768, 10)\n","    # but again, if your training dataset is not very large, we may only offard one linear layer\n","    \n","    # last layer\n","    self.l3 = torch.nn.Linear(768, 1)\n","\n","\n","  \n","  def forward(self, input_ids, attention_mask):\n","    # first layer\n","    # the first layer utilize the BERT model (call \"model\" in __init__) to transfer the input_ids into\n","    # contextualized word embeddings --numerical vectors\n","    # we can customize the output of this layer such as using the [CLS] token or the mean of all input tokens\n","   \n","    # if you want to use the BERT output of the last self-attention layer, use this:\n","    last, pooler = self.l1(input_ids = input_ids, attention_mask = attention_mask)\n","   \n","    # if you want to use BERT output from OTHER self-attention layers,use this:\n","    # (note that BERT base model has 12 hidden self-attention layers), \n","    # last, pooler, all = self.l1(input_ids = input_ids, attention_mask = attention_mask, output_hidden_states = True)\n","    \n","    # second layer\n","    # here we could use the mean value of tokens of all raw inputs as the embedding of the whole input text\n","    # and feed it into the second layer, use this: \n","    # output from last BERT self-attention layer:\n","    # initial index \"0\" for mean value of [cls] token and all non-padded tokens\n","    # initial index \"1\" for mean value of all non-padded tokens only\n","    output = last[:, 0 : attention_mask.sum(), :].mean(dim = 1)\n","    # BERT output from other hidden self-attention layer:\n","    # output = all[11][:, 0 : attention_mask.sum(), :].mean(dim = 1)\n","    \n","    # or use the [CLS] token of last layer\n","    # output = last[:, 0, :]\n","\n","    # output from BERT model now be fed into a relu activation funcation adn\n","    # the second layer of the Neural Network\n","    output = F.relu(output.squeeze())\n","    output = F.relu(self.l2(output))\n","\n","    # why squeeze(): to make the dimension of input-output across layers consistent\n","    # e.g., the output of layer 1--self.l1, is in the shape of (1, 768),\n","    # we use .squeeze() to make it in a shape of (768) only, \n","    # because the later layer--l2 adn l2--take (768) as input dimension not (1, 768)\n","\n","    # third layer\n","    output = self.l3(output)\n","\n","    # last sigmoid layer to furhter transfer the single scalar of l3 into a probability\n","    return torch.sigmoid(output)\n","    # note that we can also customize the layers after the 1st one, \n","    # making more layers (i.e., a deeper NN) and see if it perform betters "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m8yf6W_iSdCJ","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1596148544503,"user_tz":420,"elapsed":665,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"dfa4b53e-0abd-4f68-e0c2-5be050d06d70"},"source":["# test the model step-by-step\n","# compare the output dimension to your expectation\n","# https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n","# testing each layer in the NN is very important\n","# we should pay close attention the the dimensions of the inputs and outputs of each layer \n","# use .squeeze() to remove uncessary axis whose length is 1 to make the dimensions consistent. like \"output = pooler.squeeze()\" in the NN above\n","l1 = model\n","l1.to(device)\n","input_ids = train_processed.__getitem__(10)['input_ids'].to(device)\n","attention_mask = train_processed.__getitem__(10)['attention_mask'].to(device)\n","last, pooler = l1(input_ids = input_ids, attention_mask = attention_mask)\n","print(last.shape)\n","print(last.squeeze().shape)\n","print(pooler.shape)\n","print(pooler.squeeze().shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([1, 128, 768])\n","torch.Size([128, 768])\n","torch.Size([1, 768])\n","torch.Size([768])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zuR1CGxHpNDt","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1596148546556,"user_tz":420,"elapsed":624,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"4ba2a093-d8d5-4400-c79b-002d157add04"},"source":["# similarly, test if the dimensions of input and output \n","output = last[:, 1 : attention_mask.sum(), :].mean(dim = 1)\n","output = output.squeeze()\n","output.shape\n","l2 = torch.nn.Dropout(0.3)   \n","l2.to(device)\n","l3 = torch.nn.Linear(768, 1)\n","l3.to(device)\n","output.to(device)\n","l3(l2(torch.tensor(output)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  # Remove the CWD from sys.path while we load stuff.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["tensor([0.2467], device='cuda:0', grad_fn=<AddBackward0>)"]},"metadata":{"tags":[]},"execution_count":118}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NaSSY_mynUVw"},"source":["## Create a BERT + NN Model as an Instance of the Customized Model Classs Defined Above and Setup the Loss Function and Optimizer\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aFDDnyD6wlD4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596593893788,"user_tz":420,"elapsed":12328,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"2749221e-d878-4056-c415-6e96e9a8fe81"},"source":["# create an instance of the YelpBERT model\n","# remember to recreat a instance of the Model Class after you modified the YelpBERT class\n","model_amazon = AmazonBERT()\n","model_amazon.to(device)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AmazonBERT(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2BnImCNBLxG_","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596148553579,"user_tz":420,"elapsed":705,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"dd9fe520-59d0-442c-b0d7-838c67c56083"},"source":["# test the model_yelp\n","# recall that the train_processed is a special class that could pre-process the raw input words into input_ids\n","# and attentino_mask using its method __getitem__ method\n","# we then use this method to get the input_ids and attention_mask that we need to feed in the YelpBERT() model\n","\n","test_output = model_amazon(input_ids, attention_mask)\n","print(len(test_output))\n","print(test_output)\n","# note that the output is a scalar, becasue ofthe last hidden layer in the NN, self.l3 = torch.nn.Linear(768, 1)\n","# the scalar then can be put into a softmax for prediction \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","tensor([0.5151], device='cuda:0', grad_fn=<SigmoidBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7QmZRjGkPVAI","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596148555618,"user_tz":420,"elapsed":746,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"7a467c2e-1571-4131-81da-0381ccc5eb84"},"source":["print(input_ids.shape)\n","print(attention_mask.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([1, 128])\n","torch.Size([1, 128])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Nrrzk6ukepKO","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596148557580,"user_tz":420,"elapsed":718,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"5ecdf356-9e57-46f7-e533-376110936f50"},"source":["# check out the model parameters\n","# note that the first BERT layer, the word embeddings are in the shape of (30522, 768)\n","# and we can tell that the first 12 layers of our model are normal BERT layers, \n","# the last two are what we customized-- a dropout layer and the linear layer\n","model_amazon.parameters"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.parameters of AmazonBERT(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): Linear(in_features=768, out_features=1, bias=True)\n",")>"]},"metadata":{"tags":[]},"execution_count":122}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4enOR93aXnCG"},"source":["Up to now, we have the Dataset (pre-process/encode the raw text inputs, making them into input_ids that BERT model takes as input), the Dataloader (feed the processed data into the NN in batchs), the neural network (with the first layer as a BERT model, the transfer the encoded input_ids into word embeddings, and later layers just work on those embeddings/numerical vectors as normal neural network). \n","\n","And finally, we could set up our training loops"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iZpo8C-zc-B3"},"source":["First we start with: the loss function (e.g., crossentropy loss or mean squared error loss) and the optimize schedule (some thing about learning rate, adaptive learning rate, see class 7)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7TRC6Dbzc8oZ","colab":{}},"source":["import torch.nn as nn\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q4QtC037dzxO","colab":{}},"source":["# criterion is the loss function we use\n","# here we use Binary CrossEntropy Loss, you can try others see the performance difference\n","# https://pytorch.org/docs/master/generated/torch.nn.BCELoss.html\n","criterion = nn.BCELoss()\n","# note that loss function in pytorch framework usually take the pair of (prediction, ground_truth) as input\n","# and give the loss value as output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d0MvxRbleYiO","colab":{}},"source":["# optimizer is our optimize strategy, here we use stachastic gradient descending as the approch \n","# to update our model parameters. \n","# tips: previously I trained multiple models but with learning rate = 1e-05, 3e-05, \n","# after 4 epochs the model performance almost doesn't change\n","# thus now I use 10e-05, it seems the performance improves faster\n","learning_rate = 10e-05\n","# SGD is a common optimizer, but let's use Adam here, AdamW is a optimizer developed by Huggingface using Adam's mechanism\n","# optimizer = optim.SGD(model_yelp.parameters(), lr = learning_rate, momentum = 0.9)\n","# http://deeplearning.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/\n","# you can try out other optimization method and see performance difference"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"njBahjNyjByc","colab":{}},"source":["# set the epoch\n","epochs = 5\n","# epochs means how many rounds each training sample will be fed into the NN.\n","# next, we need to supply our model \"model_yelp\" to the GPU, so it can be run on GPU\n","# model_yelp.to(device)\n","# since the GPU has a lot of cores, it takes some time to supply to model to the GPU\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEUQBFhMhsHt","colab_type":"code","colab":{}},"source":["# try another optimizer\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","optimizer = AdamW(model_amazon.parameters(),lr = learning_rate,eps = 1e-8)\n","                  \n","total_steps = len(train_loader) * epochs\n","\n","# Create the learning rate scheduler that update the learning rate gradully, this scheduler is with AdamW\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WUy2sgBBgz50","colab":{}},"source":["# lastly, let's define a helper function we can use for calculating the prediction accuracy\n","import numpy as np\n","# the idea of the funtion is that a vector of predicted probablity of being good review, \n","# which is the output of the sigmoid/last layer of the neural network, is compared with the true label\n","# is the predicted probability >= 0.5, we assign 1, otherwise we assign 0, we use np.around() achieve this\n","def pred_accuracy (prediction, label):\n","  pred_flat = np.around(prediction).flatten()\n","  label_flat = label.flatten()\n","  return np.sum(pred_flat == label_flat) / len(label_flat)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U2WFSgu6_1VL","colab_type":"text"},"source":["## Train the BERT + NN Model and Evaluate the Performance"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DFPc5CRqiESW","colab":{}},"source":["# set the random set the same, making the results reproducible\n","import random\n","seed_val = 45\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_SCqZW_Dn6x5"},"source":["OK, finally, we strat to train the model"]},{"cell_type":"code","metadata":{"id":"CpYKGk-NeCUZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596149677255,"user_tz":420,"elapsed":1269,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"6ba8694c-7ba5-4e74-f511-5340ec866f8e"},"source":["# create an instance of the YelpBERT model\n","model_amazon = AmazonBERT()\n","model_amazon.to(device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AmazonBERT(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":155}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a417dCiz3VWS","colab":{}},"source":["# set up the directory for storing the trained model\n","import os\n","# save to Google Drive\n","dir = \"/content/drive/My Drive\"\n","# save to local file\n","# dir = \"E://OneDrive - lmu.edu//Python Projects//BERT and ML\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H0gMiqrmix5g","colab":{"base_uri":"https://localhost:8080/","height":683},"executionInfo":{"status":"ok","timestamp":1596067815944,"user_tz":420,"elapsed":196642,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"0759534e-d7d0-4a48-f8a6-4fc910a66512"},"source":["# Very Important: Each Time When You Train a Neural Network Again, \n","# Plase recreate the nural network, the dataloader, and the optimizer and its scheduler.\n","\n","\n","# train the model \n","# store the total loss and accuracy values of each epoch\n","training_stats = []\n","\n","# the epoch loop, number of rounds specified by epochs\n","for epoch_i in range(0, epochs):\n","  print('======== Epoch {:} / {:} =========='.format(epoch_i + 1, epochs))\n","  # zero the values of total loss and accuracy of the epoch\n","  total_loss = 0\n","  total_accuracy = 0\n","  # in the training stage, set the model into train mode\n","  model_amazon.train()\n","\n","  # the training step loop\n","  # recall that train_loader feed data into the NN in batchs to save memory and improve efficiency\n","  # then the # of total steps is about (# of samples/batch size)\n","  print(\"training\")\n","  for step, batch in enumerate(train_loader, 0):\n","    # feed the data into GPU using .to(device) method\n","    # note that the input_ids for one raw input is in the shape of (1, max_length)\n","    # after be processed into batch, the input_ids become (batch_size, 1, max_length)\n","    # however, BERT only takes input_ids in the shape of (batch_size, max_length),\n","    # (see here: https://huggingface.co/transformers/model_doc/bert.html#bertmodel)\n","    # so we need to do \"batch['input_ids'].squeeze()\" inestead of \"batch['input_ids']\"\n","    # to remove the unnecessy axis of \"1\". \n","    # same operation for attention_mask\n","    input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n","    attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n","    label = batch['label'].to(device, dtype = torch.float)\n","\n","    # at each step, before the NN does the feed forward, let's set the gradient to 0\n","    # as pytorch nn.Module automatically cumulates gradient from previous rounds\n","    # this is good for RNN training, but not necessy for us here. Thus, we turn it off.   \n","    optimizer.zero_grad()\n","    \n","    # for each raw input, the feed forward calculation give us two scalar, \n","    # representing the score/probability of the sample being 0/bad review class or 1/good review class  \n","    # note that since we feed the inputs/raw samples in batch, \n","    # the prediciton should be in the shape of (batch_size, # of classes)\n","    prediction = model_amazon(input_ids, attention_mask)\n","    prediction = prediction.squeeze()\n","\n","    # criterion is defined as a cross entropy loss function\n","    # it takes (prediction, ground truth) as input arugments\n","    # the former should be in the shape of (batch_size, # of classes), \n","    # the latter should be in the sahpe of (batch_szie, 1), \"1\" dimension records the true class id of the input\n","    # https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html   \n","    loss = criterion(prediction, label)\n","\n","    # with the loss, we can do back propagation to calculate the gradient\n","    # very easy, just one line of code  \n","    loss.backward()\n","\n","    # with the gradient, we can update the model paramters. \n","    # recall how we define the optimizer in the above cell  \n","    optimizer.step()\n","    \n","    # update the learning rate\n","    scheduler.step()\n","\n","    # to keep tracking on the model performance, we accumulate the total loss in every epoch  \n","    total_loss += loss.item()\n","      \n","    # for every 10 steps, we print out the epoce # and loss\n","    # again, the max_length of raw text input is 256, relatively long than usual, thus it will take longer to train. \n","    if step%10 == 0 and step != 0:\n","      print(f'Epoch:{epoch_i + 1}, Total_Loss:{total_loss}, Average_Loss:{total_loss/step}')\n","  \n","  # calcualte and store the average training loss of each batch in the current epoch\n","  avg_train_loss = total_loss / len(train_loader)\n","\n","  \n","\n","  # now let's set up the validation loop, meaning the trained model above will be used to evaluate the sample in validation dataset\n","  # note that this validation loop is in the same \"indent\" level as the training loop, and they both under the epoches loop\n","  print(\"validating\")\n","  # set the model now in the evaluation mode\n","  model_amazon.eval()\n","  # zero the values of total loss and accuracy\n","  total_loss = 0\n","  #total_accuracy = 0\n","\n","  # validation loop\n","  for step, batch in enumerate(valid_loader, 0):\n","    input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n","    attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n","    label = batch['label'].to(device, dtype = torch.float)\n","\n","    with torch.no_grad():\n","        prediction = model_amazon(input_ids, attention_mask)\n","        prediction = prediction.squeeze()\n","        loss = criterion(prediction, label)\n","\n","    total_loss += loss.item()\n","\n","    if step%10 == 0 and step != 0:\n","      print(f'Epoch:{epoch_i + 1}, Total_Loss:{total_loss}, Average_Loss:{total_loss/step}')\n","\n","  # calcualte and store the average training loss of each batch in the current epoch\n","  avg_valid_loss = total_loss / len(valid_loader)\n","\n","  training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_valid_loss\n","        }\n","    )\n","  \n","\n","\n","  # lastly, at the end of each epoch, let's save the model for later use\n","  # note that dir is defined before as \"./content/drive/My Drive\"  \n","  torch.save(model_amazon.state_dict(), os.path.join(dir, 'exper-epoch-{}.pt'.format(epoch_i)))\n","\n","print(\"training complete!\")\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["======== Epoch 1 / 5 ==========\n","training\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch:1, Total_Loss:3.3165699243545532, Average_Loss:0.3316569924354553\n","Epoch:1, Total_Loss:5.021376013755798, Average_Loss:0.2510688006877899\n","Epoch:1, Total_Loss:6.6858440190553665, Average_Loss:0.22286146730184556\n","Epoch:1, Total_Loss:8.720756813883781, Average_Loss:0.21801892034709452\n","validating\n","======== Epoch 2 / 5 ==========\n","training\n","Epoch:2, Total_Loss:1.6394238322973251, Average_Loss:0.1639423832297325\n","Epoch:2, Total_Loss:2.710770085453987, Average_Loss:0.13553850427269937\n","Epoch:2, Total_Loss:3.928369164466858, Average_Loss:0.13094563881556193\n","Epoch:2, Total_Loss:5.16026159003377, Average_Loss:0.12900653975084425\n","validating\n","======== Epoch 3 / 5 ==========\n","training\n","Epoch:3, Total_Loss:0.8325163368135691, Average_Loss:0.0832516336813569\n","Epoch:3, Total_Loss:1.1220505135133862, Average_Loss:0.05610252567566931\n","Epoch:3, Total_Loss:1.4631953155621886, Average_Loss:0.04877317718540629\n","Epoch:3, Total_Loss:2.169942763634026, Average_Loss:0.05424856909085065\n","validating\n","======== Epoch 4 / 5 ==========\n","training\n","Epoch:4, Total_Loss:0.27392085082829, Average_Loss:0.027392085082828997\n","Epoch:4, Total_Loss:0.3796693254262209, Average_Loss:0.018983466271311044\n","Epoch:4, Total_Loss:0.49413195718079805, Average_Loss:0.016471065239359935\n","Epoch:4, Total_Loss:0.9120860486291349, Average_Loss:0.022802151215728372\n","validating\n","======== Epoch 5 / 5 ==========\n","training\n","Epoch:5, Total_Loss:0.20653841737657785, Average_Loss:0.020653841737657785\n","Epoch:5, Total_Loss:0.28820826951414347, Average_Loss:0.014410413475707174\n","Epoch:5, Total_Loss:0.3726186119019985, Average_Loss:0.012420620396733284\n","Epoch:5, Total_Loss:0.7345441193319857, Average_Loss:0.018363602983299643\n","validating\n","training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"B5soA_VPd2Ry","colab":{"base_uri":"https://localhost:8080/","height":478},"executionInfo":{"status":"ok","timestamp":1596067836987,"user_tz":420,"elapsed":1934,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"54076c25-ad52-43df-def2-f12cd191f891"},"source":["# plot the train statistics stored in training_stats\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","sns.set(style = \"darkgrid\")\n","\n","sns.set(font_scale = 1.5)\n","plt.rcParams['figure.figsize'] = [12, 6]\n","\n","df_stats = pd.DataFrame(data = training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f57618ce5c0>"]},"metadata":{"tags":[]},"execution_count":39},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvoAAAGaCAYAAAB+A+cSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVzUdf4H8NfMMAcwM5zDIZc3eABylJpUah6kqHlA3qVmaXlktatm/bbatFJbjw53PcokzYTEM800s811c0UTTdS8OQVR7muGmd8fwMgIKMP1HfD1fDxal898v5/PZz47ue/58P6+PyKDwWAAERERERG1KmKhJ0BERERERI2PgT4RERERUSvEQJ+IiIiIqBVioE9ERERE1Aox0CciIiIiaoUY6BMRERERtUIM9ImIqFbJycnw9fXFJ598Uu8+FixYAF9f30acVf34+vpiwYIFQk+DiKjZWAk9ASIiqjtzAuZDhw7B09OzCWdDRESWTMQDs4iIWo6dO3ea/BwfH49vv/0Wzz77LEJCQkxeGzhwIGxsbBo0nsFgQGlpKSQSCays6rc3pNVqodfrIZfLGzSXhvL19cXIkSPx4YcfCjoPIqLmwh19IqIWZMSIESY/l5WV4dtvv0WPHj2qvXav/Px8KJVKs8YTiUQNDtClUmmD7iciovphjj4RUSvUv39/TJo0CefOncO0adMQEhKC4cOHAygP+FesWIHIyEj07NkT3bt3x8CBA7F8+XIUFRWZ9FNTjn7VtsOHD2P06NHw9/dHWFgYPvroI+h0OpM+asrRr2zLy8vD3/72N/Tu3Rv+/v4YO3YsTp8+Xe393LlzBwsXLkTPnj0RFBSEyZMn49y5c5g0aRL69+/foLWKiYnByJEjERAQgJCQEEydOhUnTpyodt3PP/+MiRMnomfPnggICEDfvn0xa9YsXL161XhNWloaFi5ciH79+qF79+7o3bs3xo4di7i4uAbNkYioPrijT0TUSqWmpuK5555DeHg4Bg0ahMLCQgDAzZs3ERsbi0GDBiEiIgJWVlY4fvw41q9fj8TERGzYsKFO/R85cgRbtmzB2LFjMXr0aBw6dAhffPEF7OzsMGPGjDr1MW3aNDg6OuKVV15BdnY2vvzyS7z44os4dOiQ8bcPpaWlmDJlChITEzFq1Cj4+/vjwoULmDJlCuzs7Oq3OBWWLVuG9evXIyAgAK+99hry8/Oxbds2PPfcc/j888/x5JNPAgCOHz+OmTNnolOnTnjppZegUqmQkZGBY8eO4caNG2jXrh10Oh2mTJmCmzdvYvz48Wjbti3y8/Nx4cIFnDhxAiNHjmzQXImIzMVAn4iolUpOTsb777+PyMhIk3YvLy/8/PPPJik1EyZMwMqVK7FmzRokJCQgICDggf1funQJe/bsMT7wO27cOAwbNgxff/11nQP9rl274p133jH+3KFDB7z66qvYs2cPxo4dC6B8xz0xMRGvvvoqZs6caby2c+fOeO+99+Dh4VGnse515coVbNiwAcHBwfjqq68gk8kAAJGRkRg6dCjeffdd/Pjjj5BIJDh06BD0ej2+/PJLODk5Gft45ZVXTNbj6tWreOONNzB9+vR6zYmIqDExdYeIqJWyt7fHqFGjqrXLZDJjkK/T6ZCTk4Pbt2/jscceA4AaU2dq8tRTT5lU9RGJROjZsycyMzNRUFBQpz6ef/55k5979eoFALh+/bqx7fDhw5BIJJg8ebLJtZGRkVCpVHUapyaHDh2CwWDACy+8YAzyAcDV1RWjRo1CSkoKzp07BwDGcX744YdqqUmVKq/57bffkJWVVe95ERE1Fu7oExG1Ul5eXpBIJDW+tnnzZmzduhWXLl2CXq83eS0nJ6fO/d/L3t4eAJCdnQ1bW1uz+3BwcDDeXyk5ORkuLi7V+pPJZPD09ERubm6d5nuv5ORkAECnTp2qvVbZlpSUBH9/f0yYMAGHDh3Cu+++i+XLlyMkJASPP/44IiIi4OjoCADw8PDAjBkzsHbtWoSFhaFLly7o1asXwsPD6/QbEiKixsYdfSKiVsra2rrG9i+//BLvvfceXFxc8N5772Ht2rX48ssvjWUn61p1ubYvEY3Rh6VVfnZwcEBsbCw2bdqESZMmoaCgAB988AEGDx6MU6dOGa+bN28eDhw4gDfffBNeXl6IjY1FZGQkli1bJuDsiehhxR19IqKHzM6dO+Hh4YF169ZBLL673/PLL78IOKvaeXh44NixYygoKDDZ1ddqtUhOToZara5Xv5W/Tfjzzz/h7e1t8tqlS5dMrgHKv5T07NkTPXv2BACcP38eo0ePxpo1a7B27VqTfidNmoRJkyahpKQE06ZNw/r16zF16lST/H4ioqbGHX0iooeMWCyGSCQy2TXX6XRYt26dgLOqXf/+/VFWVoZNmzaZtG/btg15eXkN6lckEmHDhg3QarXG9oyMDGzfvh0eHh7o2rUrAOD27dvV7m/fvj3kcrkx1SkvL8+kHwCQy+Vo3749gLqnRBERNRbu6BMRPWTCw8Px8ccfY/r06Rg4cCDy8/OxZ8+eep9829QiIyOxdetWrFy5Ejdu3DCW19y/fz98fHxqfTj2Qdq3b2/cbZ84cSKefvppFBQUYNu2bSgsLMTy5cuNqUVvv/020tPTERYWhjZt2qC4uBj79u1DQUGB8aCy3377DW+//TYGDRqEdu3awdbWFmfPnkVsbCwCAwONAT8RUXOxzL/ViYioyUybNg0GgwGxsbFYvHgxNBoNnn76aYwePRpDhgwRenrVyGQyfPXVV1i6dCkOHTqEffv2ISAgABs3bsSiRYtQXFxc777/8pe/wMfHB1u2bMHHH38MqVSKwMBAfPzxxwgNDTVeN2LECGzfvh1xcXG4ffs2lEolOnbsiNWrV2Pw4MEAAF9fXwwcOBDHjx/H7t27odfr4e7ujpdeeglTp05t8DoQEZlLZLC0J56IiIjqoKysDL169UJAQECdD/kiInqYMEefiIgsXk279lu3bkVubi769OkjwIyIiCwfU3eIiMjivfXWWygtLUVQUBBkMhlOnTqFPXv2wMfHB1FRUUJPj4jIIjF1h4iILN6OHTuwefNmXLt2DYWFhXBycsKTTz6JuXPnwtnZWejpERFZJAb6REREREStEHP0iYiIiIhaIQb6REREREStEB/GbUJ37hRAr2/ezCgnJyWysvKbdcyWjOtlPq6Zebhe5uF6mYfrZR6ul3m4XuYRar3EYhEcHGxrfI2BfhPS6w3NHuhXjkt1x/UyH9fMPFwv83C9zMP1Mg/XyzxcL/NY2noxdYeIiIiIqBVioE9ERERE1Aox0CciIiIiaoUY6BMRERERtUIM9ImIiIiIWiFW3SEiIiJqZkVFBcjPz0FZmVboqdQqI0MMvV4v9DRajMZeL4lECqXSDtbWNZfOrAsG+kRERETNSKstRV7eHdjbO0MqlUMkEgk9pRpZWYmh0zHQr6vGXC+DwQCttgTZ2bdgZSWFVCqrVz9M3SEiIiJqRnl52VAq7SCTKSw2yCdhiUQiyGQK2NraIT8/u979MNAnIiIiakY6XSnkcmuhp0EtgEJhDa22tN73M3WnlTj2Rzq2H7mM27klcFTLMerJDujdzU3oaREREdE99PoyiMUSoadBLYBYLIFeX1b/+xtxLmYrLS3FsmXLEBYWhoCAAERFReHYsWMPvO/AgQN49dVX0b9/fwQGBiI8PBwfffQR8vLyarw+JiYGTz/9NPz9/TF48GBs3ry5xutu3ryJuXPnIjQ0FMHBwXj55ZeRlJTUoPfYHI79kY6v9p1HVm4JDACyckvw1b7zOPZHutBTIyIiohowZYfqoqGfE0ED/QULFuCrr77C8OHDsWjRIojFYkyfPh2nTp26731vv/02Ll++jBEjRuCtt95CWFgYoqOjMW7cOJSUlJhcu3XrVrz11lvo3Lkz3n77bQQGBuK9997DF198YXJdQUEBJk+ejPj4eMyYMQNz5szBuXPnMHnyZOTk5DT6e29M249cRuk9D3+U6vTYfuSyQDMiIiIiIqEJlrqTkJCAvXv3YuHChXj++ecBAM888wwiIiKwfPnyWnfdAWD16tXo2bOnSVv37t0xf/587N27F6NGjQIAFBcXY8WKFXjqqaewatUqAEBUVBT0ej0+/fRTREZGQqVSAQC2bNmC69evY/v27ejatSsA4PHHH8ewYcOwceNGzJ07t7GXoNFk5ZaY1U5ERETU0sya9SIA4NNP1zbrvS2ZYIH+/v37IZVKERkZaWyTy+UYM2YMVqxYgYyMDLi4uNR4771BPgAMGDAAAHD58t1d7N9++w3Z2dkYP368ybUTJkzA7t278csvv2Do0KEAgB9++AE9evQwBvkA0KFDB/Tu3Rv79u2z6EDfSS2vMahXWUsFmA0RERE9TMLCQut0XUzMLri7t2ni2VBVggX6iYmJaNeuHWxtTQ8BCAgIgMFgQGJiYq2Bfk1u3boFAHBwcDC2nTt3DkD5bn9V3bp1g1gsxrlz5zB06FDo9XpcuHABzz77bLV+/f39cfToURQVFcHa2jKfkB/1ZAd8te+8SfqOCEBekRYHTyRhQKiXcJMjIiKiVu3tt98z+Xnbtm9w82YaZs9+zaTd3t4BDbFixWeC3NuSCRboZ2ZmwtXVtVq7RqMBAGRkZJjV37p16yCRSDBo0CCTMWQyGezt7U2urWyrHCM7OxulpaXGse+dj8FgQGZmJry9vc2aU3OprK5TterO8LB2+P3PW9hy8E9k5RYjsl9HiPngDxERETWywYOHmPz888+HkJOTXa39XsXFxVAoFHUeRyqtf6ZCQ+5tyQQL9IuLi2tcdLlcDgDVHqq9n927dyM2NhYvvfSSSTBe2xiV41SOUfmnTFb91LHK+RQXF9d5PpWcnJRm31Nfw/uqMLxvJ5O2Ef06Y92OM9h79CryS8rw2rhgyKQs53UvjUYl9BRaHK6Zebhe5uF6mYfrZR5LWK+MDDGsrFrGUUb1mWdlpZiq986cOR35+XlYsOAtrFr1D1y4kIiJE5/D9Okz8MsvP2PHju24ePE8cnJy4OLiiqFDh+G556ZCIpGY9AEAa9asAwDEx5/AK6+8iA8+WIarV68gLi4WOTk5CAgIxPz5i+Dl5d0o9wJAbOy32LLla2Rl3UKHDh0xZ848/Otfa0z6rO96PYhYLK7351awQF+hUECr1VZrrwy6KwPsBzlx4gQWLVqEvn37VsujVygUKC2t+ZCBkpIS4xiVf9Z0beV8zPnGWSkrKx96vcHs+xpCo1EhM/NumdFRYW1hK5Ng2+FLuJlVgDmjA6Bk7r7RvetFD8Y1Mw/XyzxcL/NwvcxjKeul1+uhu6daXkNVnqeTlVsCp0Y6T8fKSlyveRoM5bFP1XsNBgPu3LmD11+fi0GDwjF48BC4urpBp9Nj9+5dUCisERU1ATY21oiPP4G1a9cgLy8fr7wyt9Z+y8rK//zyy/UQiyUYN24y8vJy8c030fi//1uEdeu+apR74+Ji8fHHH6FHj2BERY1DWloa/vrX16FSqaDRuBj7rO96PYher7/v51YsFtW6uSxYoK/RaGpMz8nMzASAOuXnnz9/HjNnzoSvry9WrFhh8q2vcgytVovs7GyT9J3S0lJkZ2cbx7C3t4dMJjOOfe98RCJRjWk9LYFIJEJ4T284quVYv+cclkTH49WoQLjYW+bzBkRERGSeyvN0Kp/VqzxPB4BFHZ5561YmFix4GxERI0za33nnfcjldzdUn3lmDJYtW4K4uBhMnz6zxoyLqnQ6Hb744itYWZWHtWq1HVatWo4rVy6hffuODbpXq9Vi/fo16NbNHytXfm68rmPHTli8+B1oNHV/nlQIggX6fn5+iI6ORkFBgckDuadPnza+fj83btzACy+8AEdHR/zrX/+CjY1NtWu6dOkCADh79izCwsKM7WfPnoVerze+LhaL0blzZ5w9e7ZaHwkJCfDx8bHYB3Hr6tEurrBXyvHJdwlYsukE5kYGop27WuhpEREREYCjZ9Lwa0Jave69nJoDXZlpBkGpTo8vv0/EL7+nmtVXWIA7+vi712seD6JQKBAePrRae9Ugv7CwAKWlWgQGBmHnzu24fv0aOnXqfN9+hw4dbgzAASAwsAcAIDU15YGB/oPuPX/+HHJycvDyyyNNrhs4MByrV//jvn1bAsESxMLDw6HVahETE2NsKy0txfbt2xEcHGx8UDc1NdWkZCZQvss+depUiEQibNiwAY6OjjWO0atXL9jb22PLli0m7d988w1sbGzwxBNPGNsGDx6M33//3VipBwCuXLmC//73vwgPD2/w+7UEnb3s8eakEMikEny05SR+//OW0FMiIiKiBro3yH9Qu1A0GheTYLnSlSuXsXDhGxg8+EkMGvQkIiIG4L333gYAFBTkP7BfV1fT31qoVOUbmXl5D07TetC96enlX748PU0rGFpZWcHdvWm+EDUmwXb0AwMDER4ejuXLlxsr2sTFxSE1NRUffPCB8br58+fj+PHjuHDhgrHthRdeQFJSEl544QXEx8cjPj7e+Jq3tzeCgoIAlH9znDNnDt577z3MnTsXYWFhOHHiBHbt2oU33ngDavXdHe3x48cjJiYGL774IqZMmQKJRIKNGzdCo9EYD/RqDdydbLFocihWxZzGJ9sTMHFgZ/QL9hR6WkRERA+1Pv7130n/y+dHazxPx0ktx/wJwQ2dWqOpunNfKS8vD7NnvwgbGyWmTZsBDw9PyGQyXLx4HmvWfAK9/sE572JxzYVGKvPym+relkCwQB8Ali5dipUrV2Lnzp3IycmBr68v1q5di5CQkPved/58ed7Z+vXrq702cuRIY6APlB+OJZVK8cUXX+DQoUNwd3fHokWLMHnyZJP7lEoloqOjsWTJEnz++efQ6/Xo2bMnFi1aZFKbvzWws5Vh/vhg/HPnWUQfuIhbOcUY3bcDy28SERG1QDWdpyOzEmPUkx0EnFXdnDoVj5ycHCxevAw9etz9UpKWZl7KUVNxcyv/8pWcnITAwLvxpU6nQ1paGjp0uH9qkNAEDfTlcjnmz5+P+fPn13pNdHR0tbaqu/t1ERUVhaioqAde5+bmhtWrV5vVd0sll0kwa7Q/Nv/4J/b9dgNZucWYNrQrpC2k3BcRERGVq3qeTmNW3WkOYnF53FF1B12r1SIuLqa2W5qVn19X2NnZYdeuOAwePMSYevTjj/uRl5cr8OweTNBAn4QlEYsxaVBnONspEPvzZWTnl2L2aH/YKlh+k4iIqCXp3c2tRQT29/L3D4BKpcbixe9gzJhnIRKJ8MMP38NSMmekUimmTn0RK1Ysw6uvvox+/Z5CWloa9u3bDQ8PT+OZAZaK27cPOZFIhCG9fPDi8K64kpqDJdHxuJVdJPS0iIiI6CFgZ2ePpUtXwMnJGevWrcE333yN0NCeePnlOUJPzWj06Gfx6qtvID09DZ99tgqnT5/Chx/+A0qlCjJZ3c59EorI0FqeNrBAlnBgljku3LiDT747A6mVGHMjA9DWrfWX37SUw1NaEq6Zebhe5uF6mYfrZR5LWa/09Otwc/MRehoP1FQHQLUGer0eERED8eST/TB//lsAmm69HvR5ud+BWdzRJyNfbwcsnBQCK4kIH20+hYTLLL9JRERED7eSkuoVjfbv34vc3BwEBd2/gIzQmKNPJjycy8tvrow5jdWxZzBxcGf07eEh9LSIiIiIBJGQ8DvWrPkEffv2h1pth4sXz2Pv3l1o374D+vUbIPT07ouBPlVjr5RjwYRgrNnxBzbtv4CsnGKMeqK9xT9wQkRERNTY2rTxgLOzBrGx3yI3NwdqtR3Cw4dixoxZkEotu4AJA32qkUJmhTlj/BH9wwXsPXYdWbnFmDqkC6wkzPYiIiKih4eHhyeWLl0h9DTqhYE+1UoiFuO5cD8421lj+y9XkJ1Xglmj/GHD8ptEREREFo/bs3RfIpEIEY+1xfSIrvgzOQcffH0St3OLhZ4WERERET0AA32qk97d3fBaVCBu5xXj/U0ncOOm8OXJiIiIiKh2DPSpzrq0dcTCiSEQiUT4YPNJnL2SJfSUiIiIiKgWDPTJLJ4aJd6aHAoXe2usjEnAv0+nCj0lIiIiIqoBA30ym4OqvPxml7YO+HLfeez49xXwgGUiIiIiy8JAn+rFWm6FuWMCEObvjl1Hr+GLvYnQlfGYbCIiIiJLwUCf6s1KIsaUIX54Jqwdjp5Nx8qY0ygq0Qk9LSIiImrhvv9+N8LCQpGWdjdFeMyYYVi8+J163dtQJ0+eQFhYKE6ePNFofTYHBvrUICKRCMPD2mHa0C64cCOb5TeJiIgeQn/96zwMGBCGoqKiWq957bVZGDz4SZSUlDTjzMxz8OAP2LZti9DTaDQM9KlR9PF3x6uRgbiVU4TF0fFIysgXekpERETUTAYOHIzi4mL8+uuRGl+/c+c24uP/hyee6Ae5XF6vMbZs+Q7z57/VkGk+0KFDB7Bt2zfV2nv0CMahQ0fRo0dwk47f2BjoU6Pp1q68/CYAfLg5Hn9cuy3wjIiIiKg5PP54X1hb2+DgwR9qfP2nnw6irKwMgwaF13sMmUwGKyuret/fEGKxGHK5HGJxywqdhVktarW8XJRYNCkEK2NOY+W203j+aT/08XcXelpERETUhBQKBR5//EkcPnwQubm5UKvVJq8fPPgDnJyc4OXlg+XLP0R8/HHcvHkTCoUCwcGheOWVuXB3b3PfMcaMGYagoBAsWvSOse3KlctYuXIZzp49Azs7O4wYMQrOzppq9/773z9j1644XLx4Abm5OdBoXDBkyDBMmjQFEokEADBr1ov4/feTAICwsFAAgJubO2Jjd+PkyROYM2cGVq/+J4KDQ439Hjp0AF9/vRHXr1+Dra0tHnvsccycOQf29vbGa2bNehH5+fn4v/97D//4x1IkJv4BlUqNyMixmDDhOfMW2kwM9KnROaoVWDAhBJ/FncGGvYnIyi3GsMfaQiQSCT01IiKiVul4+knsurwfd0qy4SC3x/AO4XjUrXnTTAYODMeBA/vw88+HMHz4SGN7enoazp5NwJgxY5GY+AfOnk3AgAGDodG4IC0tFTt2fIfZs1/C11/HQKFQ1Hm8rKxbmDNnBvR6PSZOfA4KhTV27YqrMTXo++/3wNraBs8+OwE2NtaIjz+B9ev/iYKCArzyylwAwHPPTUVRURFu3kzD7NmvAQCsrW1qHf/773djyZJ30a2bP2bOnINbt24iJuZbJCb+gXXrNpnMIzc3B6+/Pgf9+j2Fp54ahMOHD2LNmk/Qvn1H9O7dp87v2VwM9KlJ2CisMC8qEBv3nceOf19FVk4xJg32hZWkZf3Ki4iIyNIdTz+JLee/g1avBQDcKcnGlvPfAUCzBvuPPNIT9vYOOHjwB5NA/+DBH2AwGDBw4GB06NAR/foNMLmvT58nMGPGFPz88yGEhw+t83ibN3+FnJxsrF8fDV9fPwDA009HYNy4kdWufeed9yGX3/0S8cwzY7Bs2RLExcVg+vSZkMlkeOSRXti+PQY5OdkYPHjIfcfW6XRYs+YTdOzYGZ988q+KtCIxOnXywzvvLMLu3XEYM2as8fqMjJv429/ex8CB5alLEREjMGZMBPbu3clAn1omK4kY04Z2gbOdAruOXsOdvBLMfKY7rOX82BEREVX1W1o8jqX9r173Xs25AZ3BtLy1Vq/F5sRY/Cf1uFl99XZ/BD3dQ+o1DysrK/TvPwA7dnyHW7duwdnZGQBw8OABeHp6oWvX7ibX63Q6FBTkw9PTC0qlChcvnjcr0D927Cj8/QONQT4AODg4YODApxEXF2NybdUgv7CwAKWlWgQGBmHnzu24fv0aOnXqbNZ7PX/+HO7cuW38klCpf/+B+OyzVfjPf46aBPpKpRIDBgw2/iyVStGlSzekpqaYNa65GHFRkxKJRHjm8fZwVCuwaf8FfLT5JOZGBsJBVb8n7omIiMjUvUH+g9qb0sCB4di+PQY//XQAUVHjce3aVVy6dBFTpkwHAJSUFCM6eiO+/343MjMzYDAYjPfm55tXse/mzXT4+wdWa/f29qnWduXKZaxbtwYnT/4PBQUFJq8VFJhfKTA9Pa3GscRiMTw9vXDzZppJu4uLa7UUZpVKjcuXL5k9tjkY6FOzeCKwDRxVcny24ywWR5/AvMhAeGiUQk+LiIjIIvR0D6n3TvpbR5fgTkl2tXYHuT1eDZ7R0KmZxd8/EO7uHvjxx/2IihqPH3/cDwDGlJUVK5bh++93IzJyHLp394dSqQQgwjvvvGkS9DemvLw8zJ79ImxslJg2bQY8PDwhk8lw8eJ5rFnzCfR6fZOMW5VYLKmxvanes3HcJu2dqIru7Z2wYHwwyvQGLPn6JBKv3xF6SkRERC3e8A7hkIqlJm1SsRTDO9S/lGVDDBgwCImJ55CcnIRDhw7A17eLcee7Mg9/9ux56NdvAB55pBcCAnqYvZsPAK6ubkhOTqrWfuPGdZOfT52KR05ODhYt+huiosahT5/H8cgjPaFSqavdC9StcIibm3uNYxkMBiQnJ8HV1TIqDjLQp2bl46bCW5NC4aiS4x/f/o5jf6QLPSUiIqIW7VG3YIz3Gw0HeXlJRwe5Pcb7jW72qjuVBg16GgDw6acrkJycZFI7v6ad7e+++xZlZWVmj9O7dx+cOXMaFy6cN7bduXMHP/64z+S6ytr3VXfPtVpttTx+ALC2tq7Tlw4/v65wcHDEjh2x0Gq1xvbDhw8hMzMDjz3WdA/YmkPQ1J3S0lKsWrUKO3fuRG5uLvz8/DBv3jz07t37vvclJCRg+/btSEhIwMWLF6HVanHhwoVq133yySf49NNPa+1ny5YtCAkp/zXZggULEBcXV+2awMBAbNu2zcx3RvfjZKfAwonB+HT7GazbfQ5ZOcUY2tuH5TeJiIjq6VG3YMEC+3u1a9ceHTt2xq+//gKxWIynnrr7EOpjj4Xhhx++h62tEm3btsMff5zBiRPHYWdnZ/Y448c/hx9++B6vvfYKxowZC7lcgV274uDq6o78/D+N1/n7B0ClUmPx4ncwZsyzEIlE+OGH71FT1oyvrx8OHNiHTz75B/z8usLa2gZhYU9Uu87KygozZ87GkiXvYpIuIbIAACAASURBVPbslzBgwCBkZmYgJmYr2rfvgGHDqlf+EYKggf6CBQtw4MABTJ48GT4+PoiLi8P06dMRHR2NoKCgWu87cuQIYmJi4OvrCy8vL1y5cqXG6wYOHAhvb+9q7StWrEBhYSH8/f1N2q2trfHuu++atDk6OtbjndGD2CikmBfVA1/uS8T2X64gK7cYEwd1hqSFnThHRERE1Q0aFI5Lly4iKCjEWH0HAObOfQNisRg//rgPJSWl8PcPxMqVn+G112abPYazszNWr/4XVqxYiujojSYHZn344d+N19nZ2WPp0hX49NOVWLduDVQqNQYNehqhoY/itddmmfQ5YsRoXLx4Ht9/vwfffrsFbm7uNQb6ADBkyDDIZDJs3vwVPvtsFWxtbTFwYDhmzJhdYy1/IYgMTf0UQC0SEhIQGRmJhQsX4vnnnwcAlJSUICIiAi4uLti8eXOt9966dQtKpRIKhQKLFy/Gpk2batzRr0laWhr69euHyMhI/P3vdz8ECxYswMGDB3HixIkGva+qsrLyodc37/JqNCpkZuY165gNYTAYsP2XK9h77DoCOjhhxohuUMia7/tnS1svS8A1Mw/XyzxcL/NwvcxjKeuVnn4dbm7VK8NYGisrMXS6pn9QtbVoqvV60OdFLBbByanmAieCbZ/u378fUqkUkZGRxja5XI4xY8YgPj4eGRkZtd7r7Oxs1slpVe3ZswcGgwHDhg2r8fWysrJ6PRBC9SMSiTD6yQ6YHO6Ls1du46PNp5CTXyL0tIiIiIhaPMEC/cTERLRr1w62trYm7QEBATAYDEhMTGyScXfv3g13d3c88sgj1V4rKChASEgIQkJC0LNnT3zwwQcoKWHQ2Rz69vDAnDH+SL9diPc3xSP1VsGDbyIiIiKiWgkW6GdmZsLFxaVau0ajAYD77ujX159//okLFy5g6NCh1R781Gg0eOGFF7BkyRJ8/PHHCAsLw8aNG/HKK680+jyoZgEdnDF/QhC0ZXosiY7HhRssv0lERERUX4I9jFtcXAypVFqtvfLhhabYSd+9ezcA1Ji28/rrr5v8HBERAVdXV2zYsAFHjx5Fnz7ml0mqLV+qqWk0KkHGbQwajQr/8HDAO+uO4eNvT2PeuCA8EeTZ5GOSebhm5uF6mYfrZR6ul3ksYb0yMsSwsmoZxSdayjwtRVOsl1gsrvfnVrBAX6FQmNQdrVQZ4Df208oGgwF79uxB586d4efnV6d7pk6dig0bNuDYsWP1CvT5MG79iAHMHx+ET747g2Vfx+NacjbCe3o3SfnN1rBezY1rZh6ul3m4XubhepnHUtZLr9e3iIdc+TCueZpqvfR6/X0/txb5MK5Go6kxPSczMxMAakzraYj4+HikpKTU+hBuTZydnSGVSpGTk9Ooc6EHs1VI8fqzPfBoFxfE/HwZXx+4iLJmOKKaiIiIqLUQLND38/PD1atXUVBg+tDl6dOnja83pt27d0MkEiEiIqLO96Snp0Or1bKWvkCkVmK8OLwbnu7pjcOnUvDZ9rMoKTX/5DwiIiKih5FggX54eDi0Wi1iYu4eP1xaWort27cjODgYrq6uAIDU1FRcvny5QWNptVrs378fISEhaNOmTbXXS0pKaiyp+fnnnwMAwsLCGjQ+1Z9YJEJkv46YMLAzTl++haXfnEROQanQ0yIiImoQgY4xohamoZ8TwXL0AwMDER4ejuXLlyMzMxPe3t6Ii4tDamoqPvjgA+N18+fPx/Hjx00OxEpJScHOnTsBAGfOnAFwNyj38/ND//79Tcb69ddfkZ2dXWvaTmZmJkaOHImIiAi0b98eer0ehw8fxrFjxzBkyJAaS3FS83oqxBOOajn+tfMPLN50AvOiAuHuZPvgG4mIiCyMRGIFrbYUMpllnJ5KlkurLYVEUv9wXbBAHwCWLl2KlStXYufOncjJyYGvry/Wrl2LkJCQ+96XnJyMVatWmbRV/jxy5Mhqgf7u3bshlUoRHh5eY39qtRp9+/bF0aNHERcXB71ej7Zt22LBggWYPHlyA94hNaagThr8dXwwVsWexpLoeMweHYDOXvZCT4uIiMgsSqU9srMzYW+vgVQqa5JiE9SyGQwGaLWlyM7OhErlUO9+RAb+7qjJsOpO08jILsKKbaeRlVOM6cO64hG/+j+4/TCsV2PjmpmH62Uerpd5uF7msaT1KioqQH5+NsrKdEJPpVZisRh6FsKos8ZeL4nECkqlPayt75/BcL+qO4Lu6BPVh4u9NRZNCsHq2ASs2XEWWf06YvCjXtwRISKiFsPa2vaBAZzQLOmLUUtgievFUxCoRVJaS/HG2B4I9dVg2+FL2HLwz2b/7QkRERGRJWOgTy2WTCrBjGe6Y9AjXjgUn4zP4s6gRMvym0REREQAA31q4cQiEcY+1QnjBnTC73/ewrJvTiG3kOU3iYiIiBjoU6swMNQLL4/0R1JGPpZsisfN24VCT4mIiIhIUAz0qdUI8dXgr+OCUFiiw+LoeFxKyRF6SkRERESCYaBPrUoHDzssmhwCG4UVln1zCvEXMoWeEhEREZEgGOhTq+PqYIM3J4XA20WJz+PO4McTSUJPiYiIiKjZMdCnVkltI8Mb44IQ1FmDbw7+ia2H/oSeZ8MRERHRQ4SBPrVacqkELz/THQNCPHHgf0lYs+MsSll+k4iIiB4SDPSpVROLRRg/sDPG9u+IkxcysXzr78hj+U0iIiJ6CDDQp4fCoEe9MfOZ7riWnocl0fHIuMPym0RERNS6MdCnh0aonwv+Mq4H8ou0WBwdjyupuUJPiYiIiKjJMNCnh0onT3ssmhwKhUyCpVtO4rezaUJPiYiIiKhJMNCnh46bow0WTQqFh8YWSzYex6H4ZKGnRERERNToGOjTQ0ltK8NfxwXjka5u2PzjRWw7fInlN4mIiKhVYaBPDy25TIKFzz+K/sEe2P/bDazd9Qe0OpbfJCIiotbBSugJEAlJIhZhwsDOcLazxrbDl5CdV4JZowOgtJYKPTUiIiKiBuGOPj30RCIRwnt6Y8aIbriSlosl0fHIzC4SelpEREREDcJAn6jCo11c8cbYIOQVlmJxdDyuprH8JhEREbVcDPSJqujsZY+FE0MgsxLjoy0n8fulW0JPiYiIiKheGOgT3aONsy0WTQqBu5MtPvkuAT+fShF6SkRERERmY6BPVAM7pRzzxwfBv70TNv1wAbE/X2b5TSIiImpRGOgT1UIhs8Ls0f7o26MNvv/vdazffQ5anV7oaRERERHVCctrEt2HRCzGpMG+cLJT4LsjV3AnrwSzRvvDVsHym0RERGTZuKNP9AAikQhDe7fFi8O64lJKDj74+iRu5bD8JhEREVk2QQP90tJSLFu2DGFhYQgICEBUVBSOHTv2wPsSEhLwzjvvYNSoUejevTt8fX1rvC45ORm+vr41/vPLL79Uu/7y5cuYNm0agoKC8Oijj2L+/Pm4fft2g98ntQ69urnh9Wd74E5eCRZvisf19Dyhp0RERERUK0FTdxYsWIADBw5g8uTJ8PHxQVxcHKZPn47o6GgEBQXVet+RI0cQExMDX19feHl54cqVK/cdZ/jw4QgLCzNp8/PzM/k5PT0dEyZMgFqtxrx581BYWIgvvvgCFy9exLZt2yCVMlWDAD8fB7w5MRgrY07jw80nMfOZ7gjo4CT0tIiIiIiqESzQT0hIwN69e7Fw4UI8//zzAIBnnnkGERERWL58OTZv3lzrvePGjcP06dOhUCiwePHiBwb63bp1w4gRI+57zT//+U+UlJQgOjoarq6uAICAgABMmTIFO3fuxJgxY8x7g9RqeWiUeHNSKFbFnsbq2ARMDvfFE4FthJ4WERERkQnBUnf2798PqVSKyMhIY5tcLseYMWMQHx+PjIyMWu91dnaGQqEwa7zCwkKUlpbW+vqBAwfQv39/Y5APAI899hjatm2Lffv2mTUWtX4OKjnmjw9G13YO2LjvPLb/cgUGlt8kIiIiCyJYoJ+YmIh27drB1tbWpD0gIAAGgwGJiYmNNtaqVasQFBSEgIAAPPvss/jf//5n8vrNmzeRlZWF7t27V7s3ICCgUedCrYe13ApzRgfgiUB37PnPNazfkwhdGctvEhERkWUQLHUnMzPTZPe8kkajAYD77ujXlVgsRlhYGAYOHAgXFxdcv34dGzZswJQpU7Bx40aEhoaajFU59r3zycrKQllZGSQSSYPnRK2LlUSM58L94GRnjbhfriA7vwSvjPSHjYKVa4mIiEhYgkUjxcXFNT7gKpfLAQAlJSUNHqNNmzbYsGGDSduQIUMwdOhQLF++HFu3bjUZSyaT1Tqf4uLiar99eBAnJ2V9pt1gGo1KkHFbqsZYr6kj/NHWwx6rvz2FZVtP4W8v9IbGwboRZmeZ+BkzD9fLPFwv83C9zMP1Mg/XyzyWtl6CBfoKhQJarbZae2XQXRlgNzZXV1cMHToU27ZtQ1FREaytrY1j1ZTDXzkfc58JAICsrHzo9c2bt63RqJCZybKPddWY6+XvY495UYH4LO4MXlv5M16NDIS3q2X9C98Y+BkzD9fLPFwv83C9zMP1Mg/XyzxCrZdYLKp1c1mwHH2NRlNjek5mZiYAwMXFpcnGdnd3h16vR25urslYlWPfOx8nJyem7VCddG3riIUTQiASifDh5pM4ezVL6CkRERHRQ0qwQN/Pzw9Xr15FQUGBSfvp06eNrzeVpKQkSCQS2NnZASjf5Xd0dMTZs2erXZuQkIAuXbo02Vyo9fF0UeKtyaFwtrPGqpgE/DshVegpERERURM5nn4Sbx1dgme/nYm3ji7B8fSTQk/JSLBAPzw8HFqtFjExMca20tJSbN++HcHBwcYHdVNTU3H58uV6jVHTqbbXr1/H3r17ERoaapKOM2jQIPz000+4efOmse3YsWO4du0awsPD6zU+PbwcVHIsnBgMP297fPn9eez4N8tvEhERtTbH009iy/nvcKckGwYAd0qyseX8dxYT7AuWox8YGIjw8HAsX74cmZmZ8Pb2RlxcHFJTU/HBBx8Yr5s/fz6OHz+OCxcuGNtSUlKwc+dOAMCZM2cAAJ9//jmA8t8E9O/fHwCwbNkyJCUloVevXnBxccGNGzeMD+DOnz/fZD4zZszA/v37MXnyZEycOBGFhYXYsGED/Pz8HnjYFlFNrOVWmBsZiE37L2DX0WvIyi3Gc+F+sJII9v2aiIiIalGmL0OhrggF2gLkawtRqC1EgbYQBbqKPyv+KazSll2SU60frV6LXZf341G3YAHehSlBawAuXboUK1euxM6dO5GTkwNfX1+sXbsWISEh970vOTkZq1atMmmr/HnkyJHGQL9Pnz7YunUrvv76a+Tl5UGtVqNPnz6YNWsWOnXqZHK/u7s7vv76a3z44Yf4+OOPIZVK0bdvXyxcuLDGajxEdWElEWPKED842Smw89eryM4rwcsj/WEtZ/lNIiKipqA36FGsK0Z+ZWB+T6Bu2laAAm0RCrSFKC4rrrVPsUgMWysb2EptYCO1gaPCAV4qD/w37USN198pyW6qt2cWkYH5BE2GVXcsX3Ou168Jafhq/3m4O9liXlQgHFRNU1mqqfEzZh6ul3m4XubhepmH62UeodfLYDCgpKy01sC8QFeAQm1RRdvdXfZCbREMqDn+EkEEayuFMWC3ldrA1soWtlLr8v8utYWtlXX5n1WuUUjkEIlE1fp76+iSGoN6B7k93u/zZqOvSU3uV3WH24pEzSQswB32Khk+jzuL9zedwLzIQHi6CHPWAhERUXPS6nUo0NYemN/bVpkiozOU1dqnXCIzCcwdFQ5Vgvfqwbqt1AY2VtYQixovhXZ4h3BsOf8dtPq7JeOlYimGd7CM5zsZ6BM1o+7tnLBgQjBWxpzGB5vjMWukP7q0dRR6WkRERHVSpi9Dka64PDCvIXc9X1clj71KjntpWfWziipZiSR3d9OlNnCx0RjTZGxNgnQb43U2UmtIxcKHsZV5+Lsu70d2STbs5fYY3iHcIvLzAQb6RM3O21WFtyaHYkXMafxj22lMGeKHx7q7Cz0tIiJ6iBgMBhSXFVfLXa+6q152qRS383PvpszoilCkK6q1TxFEJoG5vdwOHkr3ewJ2W9hU7LYrK3bbZWJpjWkxLcWjbsF41C1Y8FSnmjDQJxKAo1qBhRNC8FncGazfk4is3BJE9PZp0X/RERFR8zMYDNDqtSjQFt6tFGOy016RLqOrSI2pSJMp1BVBb9DX2q+1lQJquRIKsTVspNbQ2DhVpMTc3VE3BusVO+0KK3mjpsVQwzHQJxKIjcIK86ICsXHfecT9cgVZOUWYOMiX5TeJiB5SOr0OBdqiGh48Lai1ekyBrhA6va7WPmViqUlg3kZpVy1/XXlPaoyNlTUkYolF7lCTeRjoEwnISiLGtKFd4KRWYPd/ruF2XglmjujO8ptERC2Y3qBHoa7INE/d5OHTmtuKy0pq7VNSkcduU7GrrrF2go/aq8ou+93Sj8Y0GSsbSCXSZnznZGkYTRAJTCQSYeQT7eFkp8Cm/Rfw0ZaTeDUyEPbKlll+k6g+jqeftNiH2ajlq+/nqzyPvaTGg5Mq2/LvKf1YqC1Coe7+5R3Lc9TLg3G1TAV3W9faA/aK0o/yWso7Et0PA30iC/FEYBs4qOT4fMdZLN50Aq9G9YCHs63Q0yJqcpVHyFeWp6s8Qh4Ag32CwWAwBs1Vj/4xtla0GYytVa8z4MTN04j9c5fJ52tzYiyu5ybB3dYVhdoi5Ffkr99b5rFQW4Sy+5R3VEjkJhVhnBQOFSkxVVJjjGky5X9aWymYx07NhgdmNaHmPDCLu2H1Y4n5h9fT87Ay5jRKdXrMHuUPPx8HoadkwhLXzJJxve7PYDBg0dHFyCnNrfaaXCJDqGsP3P1/qYogDobKqO5uAAjDPdeZFxhWbTOOUpdxa+m/6m7u3bndM+49bZX93723an81jyuxEkOnK6t2nXE2VfozvabKuMb3XuVugwHVZmK455oqbSZ9Gu6Of3cJq/4vZdpWfVzTtuYgFVvVGpiblnU0TYuRiCXNOs/mxr+/zCPUevHArFaOu2Gti4+bCosmh2DFttP4x7bfMXVIF/Tq5ib0tIgaRV5pPq7nJpX/k5eM67lJyNcW1HhtSVkpztxKxN1kBZExdUFUtVVU+VOV/6xoM14nqvzvVe6895qKvir7r+ynas+i8o5Mr4EIdzMqqreJKv67CGKT/oxXikzeYZW54p6+qs9NLrdCaYnubm+iu++m1v6N8zF33Mr+77lTVHW06n3d21bbepuOUdO4d+df0VT1HVUOVO19x13ai9q8/9ibsJXaQsY8dmqlGOi3Arsu7zc5kQ0AtHotdl7ex0C/hXK2s8abk0Lw6XdnsHb3OWTlFmNIL5bfpJalpKwUSXkpxsD+Wm4SsopvAygPxtxtXdHduQsSMv9AYQ21uZvzCPmWijuuD/Zz0lHcKcmu1u4gt4eDwl6AGRE1Hwb6rUBNf4EBQHZJDt7+zwfwVnnAS+UBL5UnvFUeUMlq/vUOWRZbhRSvPdsDX3yfiO+OXEFWbgkmDOwEiZi5nWR5yvRlSCu4aQzor+clITU/3ZiC4SC3R1u1Fx736IW2ai94qTygsFIAAI47nLToI+SpZRveIZyfL3poMdBvBRzk9jUG+9ZWCrRTeyMpLwW/Z541ttvL7eCt8oSXqk3Fn56wk6uac8pUR1IrMaYP6wontQLf//c6bucWY8aIblDI+K8uCcdgMCCr+HZ5QF8R2CflpRgDKRsra/iovRDQtit81F7wUXtBLav97xhLP0KeWjZ+vuhhxodxm1BzPYx7b44+UL5bMd5vtPEvsiJdEZLzUnEjLwU38pKRlJeKjMJM426bnUwFL5UnvFQe8FZ5wFvtCTuZutWnirSkX3sfPpWCrw9cgLerCq+OCYCdQOU3W9KaWYLWsF6VefXXjLn1SSjQFgIof4jRS+UBH7UX2qq84K32gsbaqd5/d7SG9WpOXC/zcL3Mw/UyDx/GpSZRl90KaytrdHLogE4OHYxtxbpiJOenIckY/Kfgj6zzxuBfJVXCS+1Rsetf/gXAQW7f6oN/S9UvyAMOKjn+ufMsFkfHY15UINydWH6TGlexrqQ8rz4vyZhbn1V8B8DdvPpA527wVnuhrdoLbWzdWn3lESKiloo7+k2oOctrVmrot8mSslKk5Jfv/Cflln8BSC/MgN6gBwAopbYV+f4eFcG/J5wUDi02+G+JuxVX03KxKuY0yvQGzB4dgM5ezfswWUtcMyFZ8nqV6cuQWpBu8rBsWsFN45d9J4WDMaD3UVXm1Tftb5Iseb0sEdfLPFwv83C9zMMdfbJ4cokM7e3aor1dW2NbaZkWKRU7/0l5ybiRl4KDN44Yg38bK2tj0O+lagMvlWeDfnVP99fOXY1Fk0OxYttpLN96Ci9EdMWjXVyFnhZZOIPBgFtFt3E99wauVezWl+fV6wAAtlY28FF7IVDTvTywV3vxwX0iohaOgT49kEwiRTs7b7Sz8za2afU6pBrTfsq/ABxO+jd0FScIWlsp4KlsY5L2o7Fx5mmAjURjX15+85PvEvDPnX/gdm4JBj/qxS9XZJRbmmeyU38jNxkFusq8eim8VB543KN3eW692gtOCkd+foiIWhkG+lQvUrGVsZpGJZ1eh7SCm8aHfW/kJeNIyn+gq9gxlEtk8FR6wFvtAS9l+QO/rjYaBv/1pLSW4o2xPbB+TyK2Hb6EWzlFGD+gM8RiBmsPm/K8+uQqD8sm43aVvPo2SjfjTr232gttbF2ZV09E9BBgoE+Nxqqi+oaXysPYVqYvQ3phBm7kJiMpPwU3clPwa8pvxgpBMrEUnhXpPpX1/t1sXBiE1JHUSoKXRnSDk50C+3+7gdu5JXhpRDfIpVy/1qpMX4aUgrSK3fryk2VN8+od0U7tjSc9H0NbtTe8VB6QS2QCz5qIiITAQJ+alEQsgYfSHR5Kd/TGIwDKA5WbhZkVOf/lD/weS/sfjiQfBVCeVuCpdDce8uWl8uAO5H2IRSJE9esIJ7UCWw5exNItpzB3TADUtgzuWjqDwYDMolvGgP5abhKS8+/m1SultvBWe6KHprvxN2zMqyciokoM9KnZScQStFG6oY3SDT3dQwAAeoMeGYW3jGU+k/JScDz9JH5JOQag/LcFHrbuVQ758oC70g1SMT/ClZ4K8YSjSo5/7foDi6NPYF5UD7g52gg9LTJDTkkebuRVqVefm4RCXRGA8t9+VebVlz8s692iK14REVHTY5REFkEsEsPN1gVuti7G+v96gx63irJMDvmKz0jAr6m/AQAkovIvDF6Vef8qD3jYukMqkQr5VgQV1FmDv4wPwurYBCzedAJzxgSgk2fzlt+kuinWFeNGXorJQVSVJ1yLRWK427oiyMW/4mFZb6a0ERGR2Rjok8USi8RwsdHAxUaDUNceAO6WCCzP9y/f/T+deRb/STtuvMfd1rVKuU8PeCrdIXuIcpQ7tLHDokkhWLHtNJZ98zteHNYVoX4uQk/roabT65Can25ysmx6QYYxr95Z4Yj2dj5oqw6Dj9obXqo2D9VnloiImgYDfWpRRCIRNDZO0Ng4IdglAEB58H+7+I6x1OeNvGScvZWI/6adKL+n4jTPqod8eSjdm/zgHyG5ONhUlN88gzU7zuLZ/h0x6FHvB99IDaY36JFZlGXcqU89nYqrd5KM1aeUUlu0VXsh2CWgPK9e5QWljCccExFR42OgTy2eSCSCk7UjnKwd0cPFH0B58J9dkmOs8X8jLwXnbl/Ab+nx5fdABFcbDTpp2sJF6gIvlSc8VW1gbaUQ8q00KpWNDG+M7YF1e85h60+XcCu3GGP7d2L5zUaWU5JbUae+IgUnLxlFVfLqOzj54EmPx4z16h2ZV09ERM1E0EC/tLQUq1atws6dO5Gbmws/Pz/MmzcPvXv3vu99CQkJ2L59OxISEnDx4kVotVpcuHCh2nWXL1/Gd999h6NHj+LGjRuwtbVFt27dMGfOHHTr1s3k2gULFiAuLq5aH4GBgdi2bVvD3ig1O5FIBAeFPRwU9gjU3P3fOrskx+SQrz8yLuLfRceNr7vYOJsc8uWp9ICN1FqIt9AoZFIJZj7THdt+uoQD/0vC7dwSvDisK2Qsv1kvRbpik3r113KTkF2SA6A8bayNrRuCXQKMJ8u62bjAzdWeR8gTEZEgBA30FyxYgAMHDmDy5Mnw8fFBXFwcpk+fjujoaAQFBdV635EjRxATEwNfX194eXnhypUrNV4XGxuL2NhYDBo0COPHj0deXh6+/fZbREVFYcOGDejVq5fJ9dbW1nj33XdN2hwdHRv+Rsli2MvtYC+3g79zVwCARqPC5ZTUinz/VCTlJeNy9jWcuPm78R5naydjjf/KLwG20pZTzUYsEmHsU53gpFZg66E/seybU5g9JgBqG+aA349Or0NKfprJw7I3CzPv5tVbO6GjfTvjTr2nknn1RERkWUQGg8EgxMAJCQmIjIzEwoUL8fzzzwMASkpKEBERARcXF2zevLnWe2/dugWlUgmFQoHFixdj06ZNNe7onz17Fu3atYOt7d381zt37mDIkCHo2LEjoqOjje0LFizAwYMHceLEiUZ7j1lZ+dDrm3d5NRoVdw/NUNt65ZXmV6nzX777n1Vx0igAOCkcjDX+K78EtIT65fEXMrB29zk4qOSYFxUIVwfzv7C0xs+Y3qBHZuGtitSb8oOokvNSoDOUAQBUUqUxoPdRe8Fb7QmltG559a1xvZoS18s8XC/zcL3Mw/Uyj1DrJRaL4ORUcwwi2I7+/v37IZVKERkZaWyTy+UYM2YMVqxYgYyMDLi41FwpxNnZuU5jdO/evVqbg4MDQkNDER8fX+M9ZWVlKCoqglJp+UEbNR2VTImuTr7o6uRrbCvQFhoP+Kr8AvB75hnj6w5ye2PQ76XygLfaE2qZSojp1yrE1wV/UcorEqTcCgAAIABJREFUym/GY+6YAHTwsBN6Ws0uuyTHuFN/IzcZ1/OSUKQrBgDIJDL4qDzR1yvM+LCso8KeefVERNTiCBboJyYmVtttB4CAgAAYDAYkJibWGug3VGZmJhwcHKq1FxQUICQkBEVFRbC3t8czzzyD1157DXJ5663OQnVnK7WBn2Mn+Dl2MrYVaouQnF+561/+JeD0rT+Mr9vJ1OU1/pXlgb+XygN2MrWgQWNHj7vlN5d+cwovDuuGEF+NYPNpakW6IlzPTcaN3GRcyytPwamaV++hdEeISyB81N5oq/aCm60LxCKxwLMmIiJqOMEC/czMTLi6ulZr12jKA46MjIwmGffEiRP4/fffMWvWrGrjvvDCC+jSpQv0ej0OHz6MjRs34vLly1i/fn2TzIVaPhupNTo7dERnh47GtiJdMZIr8v1vVPx59tZ5Y263SqaEt8rTJO/fXm7XrMG/q6MN3pwcgtWxCfg87gzGDeiEAaFezTZ+U9HqdUjNTzN5WPZm4d2/SzQVefVt1d7wMebVP7wHrBERUesmWKBfXFwMqbT6/8FW7p6XlJQ0+phZWVl4/fXX4e3tjalTp5q89vrrr5v8HBERAVdXV2zYsAFHjx5Fnz59zB6vtnyppqbRWFa6iKVr/PVSwdtdAyDQ2FKsLca17BRcuXMdV+7cwNU7Sdh//QIqH5FRy5Vo5+CN9g7eaOfghfaOPtDYODZp8K8B8NHsx/Hx5nhsOfgnCrV6TInoVqfym5bwGdMb9EjLy8ClrGu4dLv8n+vZKcZ69XYKNTo6+qBv+57o6NQWHRx8oJQLU6/eEtarJeF6mYfrZR6ul3m4XuaxtPUSLNBXKBTQarXV2isD/MZOlyksLMRLL72EoqIibNiwATY2D34IcerUqdiwYQOOHTtWr0CfD+NavuZcLye4wMnBBY84PAIAKC0rRUp+mvGQr6S8FJy5eR56gx4AYGtlY8z3r9z5d7Zu/OD/hSFdYCu3wo4jl5Gcnovpw7pCalV7+U2hPmPZJTkmO/U3cpNRXFaeVy+XyOCt8kQ/z4q8erUnHOSmefVFuXoUofnnzX8nzcP1Mg/XyzxcL/NwvczDh3Gr0Gg0NabnZGZmAkCj5ueXlpZi9uzZuHjxIr744gt07NjxwTeh/KFfqVSKnJycRpsLUSWZRIZ2dj5oZ+djbNOWaZFSkFae75+bgqT8FPyU9G+UVVR/sbZSwEvpAS+1B7yVHvBSe0Jj7dSgnHKxWITxAzrB2U6Bb3+6hOyC3zFndACU1sKltBRqi3Cjol595UFUOaW55fMVieGpdMcjbkHwUXmW16tnXj0REVE1ggX6fn5+iI6ORkFBgckDuadPnza+3hj0ej3mz5+PY8eOYfXq1QgNDa3zvenp6dBqtaylT81GKpGirdobbdXegEd5m1avQ1p+epWKP6k4kvwfY4qKQiKHp6qNyUFfLjYaswJfkUiEwY96w1GtwLrd57A4Oh7zogLhYt/0h4Vpy7RIzk+rKGt5t159JRcbZ3R26GBSr17KvHoiIqIHEizQDw8PxxdffIGYmBhjHf3S0lJs374dwcHBxgd1U1NTUVRUhA4dOtRrnL///e/4f/buPC7Kcu8f+GdW9p0BkV1kUdlHJUzLpZIIUystTVEr02PPczw+p+eodU6LPenJpezY8fQzMZK0FA9IlmtmyzGWBBUVBAU3BGVARVlnYOb3BzKJgDKyzDDzeb9evWTu+77m/s63S/ne91z3de3evRvLli3DY4891u4xDQ0NUKlUbabUXL9+PQBg5MiRD3Ruou4gEYrhZesBL1sPPIwoAECTugmlNVdvz/Vfgou3LuOXy+lQ3S7+pSIpPKz7t3rg19VSBpHw3iviDgtygZ2VFOv+nYvlm49g4ZQw+LrZdttnUWvUKK9VtBqCc7m6TPuNha3UBt62nhjeL/L21JYesOxDi5MREREZEr0V+mFhYYiJicHq1auhUCjg5eWF1NRUlJaWYsWKFdrjFi9ejKysrFYLYl2+fBlpaWkAgBMnmucxbynKg4KCMHbsWABAYmIitm7dioiICJibm2vbtJg4cSKA5uFCkydPRlxcHAYMGKCddSc9PR2xsbEYNmxYzyWC6AGIhCJ42vSHp01/AM39s0ndhCu15a0W+fq1NAtKdfOzMBKhBB7WbvC8Y8YfNyvXNsV/gKc93rg9/eYHW3Mw/+lghPt3bu2KO2k0mlbz1V+4eQkXb5Wgvqn5ORxzkRm8bDww1nOUdiGq3p59iIiIyJjprdAHgJUrV2Lt2rVIS0tDVVUVAgMDsWHDBsjl8nu2Kykpwccff9xqW8vryZMnawv906dPAwCOHj2Ko0ePtnmflkLf1tYWo0ePxuHDh5Gamgq1Wg0fHx8sWbIE8fHxXf6cRL1BJBTB3doN7tZueMiteYiaWqPG1VoFLt4swaXq5nH/mVeO4OfLvwIAxEIx3K3cmsf83y7++1v1g5uTFd6MH4p/7DiOdSm5mPF4AMrUZ/Br5Y9Qi+sgbLTACKfRmD50jPb8tapaXLhVcsfDspdQpWx+KEkkaI6t5U69j62nzsOLiIiISDcCTcv8ftTtOOuO4TPFfKk1aihqK1ot8nXpVql2BhuRQIT+1v3gZeMON4v+yMqpx9mKEkh88iAQqbXvo1ELMcAiEM72Frhw6yLKayu0+1wtZbdnv2leWdbD2s1kx9WbYh/rCuZLN8yXbpgv3TBfujHaWXcaGxtx8OBBVFVVYcyYMdpFr4jI8AgFQrhaucDVygXD+kUAaC7+K+quacf7X7p1GTnlJ1DXmAXYARJb4O4RNQKhGuca8nHtug18bL0Q1W8ofGw94WXjAUtJzz/ES0RERPemc6G/cuVKZGZm4t///jeA5nG4c+bMwZEjR6DRaGBvb4/t27fDy8ur24Mlop4hFAjhYukMF0tnyF3DATT/3a6sv46Lt0qw8cSX7bbTaIDlI//Wm6ESERFRJ+k8QPaXX35pNUXlDz/8gN9++w0vv/wy1qxZAwDYsGFD90VIRHohEAjgbOGISJdQCBvbv0Pf0XYiIiLSP53v6F+5cgXe3r8v8HPo0CF4eHjg9ddfBwCcOXMGu3bt6r4IiUjvRjiNxn+u72s9Rr9JCLOKIVDcqIOsF+bbJyIiIt3ofEdfpVJBLP79+iAzMxMjRozQvvb09NSubktExmH60DEY6TAeApUFNBpAoLLAQM0oNJS74q1NWfgltxR8rp+IiMiw6HxHv1+/fjh69CimTp2KM2fO4NKlS/jjH/+o3V9ZWQlLSy5wQ2Rspg8dg+kY02pWgcqoeiR8l4fPd5/G8bOViI8JhK2lVM+REhEREfAAhf5TTz2F9evX49q1azhz5gysra3x6KOPavfn5+fzQVwiE+FkZ47Xp0Vgf9YlpPxchLcSqjDnySCEDdR9gS0iIiLqXjoP3Zk3bx4mT56MY8eOQSAQ4IMPPoCtrS0A4NatW/jhhx8QHR3d7YESkWESCgSIifLCW7OGwdZSgo935GLzvgI0KJv0HRoREZFJ0/mOvlQqxfLly9vdZ2Vlhf/85z8wNzfvcmBE1Ld4uFjjb7OGIfXnYuzLuoj889fwyoTB8Otvp+/QiIiITFK3rj/f2NgIGxsbSCSmuQImkamTiIWYOnYg/ndaBBqb1FiRlIOdvxSjsUl9/8ZERETUrXQu9H/66SesW7eu1bYtW7YgMjIS4eHh+POf/wyVStVtARJR3xPk7YB3X4pC1GBXfHP4PFZ8mYMr12r1HRYREZFJ0bnQT0hIQHFxsfZ1UVERli9fDhcXF4wYMQK7d+/Gli1bujVIIup7LM3FmDthMP4wKRjl12vxzqYsHMop4TScREREvUTnQr+4uBjBwcHa17t374aZmRl27NiBjRs3IjY2Fjt37uzWIImo7xoW5IJlL0fB39MeSfsLsTY5F1XVDfoOi4iIyOjpXOhXVVXBwcFB+/rXX3/FQw89BGtrawDA8OHDUVJS0n0RElGf52Bjhv+ZGoYXHw/A6YvX8beELGQXcGE9IiKinqRzoe/g4IDS0lIAQHV1NU6cOIGhQ4dq9zc2NqKpidPqEVFrAoEA4+QeeGfOMDjZmeOfqSew6bt81DU06js0IiIio6Tz9Jrh4eH4+uuvMXDgQPz8889oamrCI488ot1/4cIFuLi4dGuQRGQ83Jys8OZMOb45fA7fpV/A6YvX8UrcYAR42us7NCIiIqOi8x39P/7xj1Cr1fjTn/6ElJQUTJo0CQMHDgQAaDQafP/994iMjOz2QInIeIhFQjzziB+WviiHQAB8sCUHO34s4jScRERE3UjnO/oDBw7E7t27kZOTAxsbGwwbNky77+bNm5g1axaioqK6NUgiMk4DPezwzpzh2PbDGezOuICTxZWYO2Ew3GXW+g6NiIioz9O50AcAe3t7jB07ts12Ozs7zJo1q8tBEZHpsDATY/aTgxA20BmJe07j3cQjeG60Hx4b6gGhQKDv8IiIiPqsByr0AeDixYs4ePAgLl26BADw9PTEuHHj4OXl1W3BEZHpiPCXYUB/OyTuzsfXB8/g+NkKvPzUIDjamus7NCIioj7pgQr9tWvX4rPPPmszu86qVaswb948LFy4sFuCIyLTYmclxR+fC8XPx0vx9cGzeCshCzPHByJqsKu+QyMiIupzdC70d+zYgU8//RQRERF45ZVX4O/vDwA4c+YMEhIS8Omnn8LT0xPPPPNMtwdLRMZPIBDg0XB3BHk7YOOuPPy/b07h+NkKvPhEAKzMJfoOj4iIqM/QudDfunUrwsLCkJSUBLH49+ZeXl549NFH8eKLL+LLL79koU9EXeLqYIklMyLxXfoFfPOf8yi4dAMvPzUIg30c9R0aERFRn6Dz9JpFRUWIjY1tVeS3EIvFiI2NRVFRUbcER0SmTSQU4umHffFmvBxmEhFWf30MXx88A1UjF+UjIiK6H50LfYlEgtra2g7319TUQCLh1+tE1H183Wzx9pxhGBvpjv2/XcKyxCO4ePWWvsMiIiIyaDoX+iEhIdi2bRsqKira7KusrMT27dsRFhbWLcEREbUwk4gw44lALJoahup6Fd774gh2Z1yAWq3Rd2hEREQGSecx+gsWLMDs2bMRGxuLZ599Vrsq7tmzZ5GSkoKamhqsXr26U++lVCrx8ccfIy0tDTdv3kRQUBAWLVqE6Ojoe7bLzc1FSkoKcnNzUVhYCJVKhYKCgnaPVavVSEhIwFdffQWFQgEfHx/84Q9/QGxsbJtji4qKsHz5cuTk5EAikWDMmDFYvHgxHB05JpjIUIQMcMJ7L0fhi72nsePHIuSercArcYPhbG+h79CIiIgMis6F/rBhw7Bu3Tq89957+Pzzz1vt69+/Pz744AMMHTq0U++1ZMkS7N+/H/Hx8fD29kZqairmzp2LpKQkREREdNjup59+QnJyMgIDA+Hp6Yni4uIOj/3oo4+wYcMGPP/88wgODsbBgwexaNEiCIVCxMTEaI+7cuUKXnzxRdja2mLRokWora3Fpk2bUFhYiO3bt3M4EpEBsbaQYMGkYPx68gq2HCjEW5uy8OLjARgR3A8CLrJFREQEABBoNJoH+t5brVbj5MmTKCkpAdC8YNaQIUOwfft2bN68Gbt3775n+9zcXEyZMgVLly7F7NmzAQANDQ2Ii4uDi4sLtmzZ0mHbiooKWFtbw9zcHO+//z42b97c7h39q1evYty4cZg2bRrefPNNAIBGo8GMGTNQVlaG77//HkJh8+ild955B2lpadi7dy9cXZvn7P71118xZ84cvP/++3juued0zlFlZXWvDyuQyWygUHDscmcxX7oztJxV3KjDxm/zUFhSBXmgDPHjA2FjKdV3WFqGli9Dx3zphvnSDfOlG+ZLN/rKl1AogJOTdfv7HvxNhQgNDUVsbCxiY2MREhICoVCI69ev49y5c/dtv3fvXkgkEkyZMkW7zczMDM899xyys7NRXl7eYVtnZ2eYm99/tczvv/8eKpUK06dP124TCASYNm0aLl++jNzcXO32/fv3Y+zYsdoiHwBGjBgBHx8f7Nmz577nIiL9cLa3wF+mR2LKaD8cO1OBtxKykFtUqe+wiIiI9O6BC/2uys/Ph6+vL6ysrFptDw0NhUajQX5+frecw9raGr6+vm3OAQB5eXkAmu/8V1ZWIjg4uM17hIaGdkssRNRzhEIBnnzIG3+bNRTWFhKsTT6OpP0FaFBxGk4iIjJdeiv0FQoFXFxc2myXyWQAcM87+rqcw9nZ+b7naPmzZfvdx1ZWVqKpiQUDkaHzcrXBW7OH4olhnjiUcxnvfP4bzpXd1HdYREREeqHzw7jdpb6+vt0HXM3MzAA0j9fvjnNIpW3H6t59jpY/73VsfX19m28f7qej8VI9TSaz0ct5+yrmS3eGnrP/fiESj8g9sfbro3g/KRsvPB6IqeP8IRLp596GoefL0DBfumG+dMN86Yb50o2h5Utvhb65uTlUKlWb7S1Fd0uB3dVzKJXK+56j5c97HduZZwLuxodxDR/zpbu+krP+9uZ4Z/ZQfHmgEFv3nUbGiVLMjRsMV0fLXo2jr+TLUDBfumG+dMN86Yb50o0hPozbqUL/7mk07yUnJ6dTx8lksnaH5ygUCgBod1iPrmQyGY4cOXLfc7T82bL97mOdnJwgEom6HA8R9S5LcwlenTAE4QOdsXlvAd7+PAsvjPPHo2H9OQ0nEREZvU4V+h988IFOb9qZX6BBQUFISkpCTU1NqyExx48f1+7vqkGDBiE5ORnnzp1r9UBuyzkGDRoEAHB1dYWjoyNOnjzZ5j1yc3O1xxFR3zR8kCsGutsh4bt8bN5bgONnKjA7dhDsrAxnGk4iIqLu1qlCf/Pmzd1+4piYGGzatAnJycnaefSVSiVSUlIQGRmpneaytLQUdXV18PPz0/kc48aNw4oVK7B169ZW8+h//fXX6N+/P8LCwrTHPvHEE/jmm29w9epV7bnT09Nx/vx5vPLKK138tESkb4625vjzC+E4eKQEyT8W4W8bMzHnySBEBLR9CJ+IiMgYdKrQHz58eLefOCwsDDExMVi9ejUUCgW8vLyQmpqK0tJSrFixQnvc4sWLkZWV1WpBrMuXLyMtLQ0AcOLECQDA+vXrATR/EzB27FgAQL9+/RAfH49NmzahoaEBISEh+P7773HkyBF89NFH2sWyAGD+/PnYu3cv4uPjMWPGDNTW1iIhIQFBQUGYOHFit39+Iup9QoEAjw/zxGBfR3y26xTWpZzAqFA3vDDOHxZmentkiYiIqEfo9TfbypUrsXbtWqSlpaGqqgqBgYHYsGED5HL5PduVlJTg448/brWt5fXkyZO1hT4AvP7667Czs8O2bduQkpICX19frFmzBrGxsa3au7m54csvv8Tf//53rFmzBhKJBKNHj8bSpUvbnY2HiPoud2cr/DV+KNL+cw67My7g9MXrmBs3BAM97PQdGhERUbcRaDSa3p0WxoRw1h3Dx3zpzthyVnjpBjZ+m4fKm/WIfcgbE0f6QtyN03AaW756GvOlG+ZLN8yXbpgv3RjirDt6WzCLiMgQBHja492XhuPhEDd8l34B72/ORmlFjb7DIiIi6jIW+kRk8izMxHgpdhBemxyCypv1eDfxNxw4cglqfuFJRER9GJ8+IyK6TR4ow0B3W3y+5zS++v4Mcs9W4KWnBsPBpusL+BEREfU23tEnIrqDnbUZFj4XivjxgThzuQpvJWQiK/+qvsMiIiLSGQt9IqK7CAQCjI5wxztzhsPFwRKfpp3CZ7tOobZepe/QiIiIOo2FPhFRB/o5WuKNmZGYONIXmXnleGtTFk5fuK7vsIiIiDqFhT4R0T2IhEJMHOmLN2bKIREJseqro9j2wxmoGpv0HRoREdE9sdAnIuqEAf1t8c6c4Rgd4Y59WZfw3hdHcKm8Wt9hERERdYiFPhFRJ5lJRZg5PhB/mhKKm7UqvPfFb9iTeaHXF8YjIiLqDBb6REQ6CvVzxrKXhyPUzxnJh4qw6qujqKiq03dYRERErbDQJyJ6ALaWUrw2ORgvxQ7Chau38PamLPx6sgwaLrJFREQGgoU+EdEDEggEGBnqhndfGg4PmTU2fpuPf6WdQnUdp+EkIiL9Y6FPRNRFMnsLLJ4eiWcfHYCjhQr8LSETJ4sr9R0WERGZOBb6RETdQCgU4KloH/w1fiiszCX4cPtxbNlfiHplo75DIyIiE8VCn4ioG3n3s8Fbs4bi8aGeOJhTgkUf/YTzV27qOywiIjJBLPSJiLqZVCLCtMf88ecXwlHX0Ij3N2dj1+FzaFKr9R0aERGZEBb6REQ9ZIiPIz55fQzkgTKk/nIOf9+Sg/LrtfoOi4iITAQLfSKiHmRtKcX8icF49enBKK2oxdubfsPPx0s5DScREfU4FvpERL3gocH98N7LwzGgvy0S95zGun+fwM0apb7DIiIiI8ZCn4iolzjamuPPL4TjhbEDcfLcNfwtIRPHzlToOywiIjJSLPSJiHqRUCDAE8O98NbsobC3NsM//p2LxD2nOQ0nERF1Oxb6RER64CGzxl/jh+LJh7zwy/FSvLPpN5y9XKXvsIiIyIiw0Cci0hOJWIgpowdi8YuRaFJrsOLLbKT8XIzGJk7DSUREXcdCn4hIzwI87bHs5eEYMaQfvv31PN5PykZZZY2+wyIioj6OhT4RkQGwMBPj5bjBWDApGJVV9Xjn899wMLuE03ASEdEDE+s7ACIi+t3QIBcM9LDDpt352HKgEMfPVmBO7CA42JjpOzQiIupj9HpHX6lUYtWqVRg5ciRCQ0MxdepUpKend6rt1atXsXDhQgwdOhSRkZFYsGABLl261OqYlJQUBAYGdvjfN998oz123bp17R7z8MMPd+tnJiK6H3trMyyaEoYZTwSg8NINvJWQiSOny/UdFhER9TF6vaO/ZMkS7N+/H/Hx8fD29kZqairmzp2LpKQkREREdNiupqYG8fHxqKmpwfz58yEWi5GYmIj4+Hjs3LkTdnZ2AIBhw4Zh5cqVbdp/8cUXOH36NKKjo9vsW7ZsGczNzbWv7/yZiKi3CAQCjI30wCBvB2z8Ng/rd57EiOB+mP5YACzN+WUsERHdn95+W+Tm5uK7777D0qVLMXv2bADApEmTEBcXh9WrV2PLli0dtt26dSsuXLiAlJQUDB48GAAwatQoTJgwAYmJiVi4cCEAwNPTE56enq3a1tfX491338VDDz0EmUzW5r2ffPJJ2NradtOnJCLqGjcnKyydIce3v57Ht79eQMHFG3glbhACvRz0HRoRERk4vQ3d2bt3LyQSCaZMmaLdZmZmhueeew7Z2dkoL+/4a+p9+/YhPDxcW+QDgJ+fH6Kjo7Fnz557nveHH35ATU0NJkyY0O5+jUaD6upqPgBHRAZDLBJi0qgBWDojEiKRACu3HsX2Q2ehauQ0nERE1DG9Ffr5+fnw9fWFlZVVq+2hoaHQaDTIz89vt51arUZBQQGCg4Pb7AsJCcH58+dRV1fX4Xl37doFc3NzPP744+3uHz16NORyOeRyOZYuXYobN27o8KmIiHqOn7sd3pkzDI+E98fezIt474sjKCmv1ndYRERkoPQ2dEehUMDV1bXN9pbhNB3d0b9x4waUSmW7w25kMhk0Gg0UCgW8vLzabfvLL7/gscceg7W1dat9tra2mDlzJsLCwiCRSJCRkYFt27YhLy8PycnJkEqlD/IxiYi6lblUjFkxQQgb6IzE3flY9sVvePZRPzw+zBNCgUDf4RERkQHRW6FfX18PiUTSZruZWfMUcg0NDe22a9neXuHd0ra+vr7dtvv27YNKpWp32M6sWbNavY6JiYG/vz+WLVuGnTt3YurUqff4NO1zcrK+/0E9QCaz0ct5+yrmS3fMmW56Il+Py2wwLLg/Pkk+hm0/nEX+xRtY+EIEXBwsu/1cvY39SzfMl26YL90wX7oxtHzprdA3NzeHSqVqs72lkG8p2u/Wsl2pVHbYtqOZcnbt2gV7e3s88sgjnYpx2rRpWLVqFdLT0x+o0K+srIZa3btj/WUyGygUt3r1nH0Z86U75kw3PZ2vV+MGYZCXPb76/gz+a9UhzHgiAA8NdoWgj97dZ//SDfOlG+ZLN8yXbvSVL6FQ0OHNZb2N0ZfJZO0Oz1EoFAAAFxeXdtvZ29tDKpVqj7u7rUAgaHdYT2lpKY4cOYLx48e3+01Ce4RCIVxdXVFVVdWp44mIeptAIMAjYf3x7kvD4O5shc925eH/fXMK1XVtb6QQEZFp0VuhHxQUhHPnzqGmpqbV9uPHj2v3t0coFCIgIAAnT55ssy83Nxfe3t6wsLBos+/bb7+FRqPB008/3ekYVSoVysrK4ODAaeyIyLC5OFhiyYuReOaRAcguUOCthEycOndN32EREZEe6a3Qj4mJgUqlQnJysnabUqlESkoKIiMjtQ/qlpaWoqioqFXb8ePH49ixY8jLy9NuKy4uRkZGBmJiYto937fffov+/ftDLpe3u//atba/EBMSEtDQ0IBRo0bp/PmIiHqbUChA3Agf/DV+KCzMxFiz7Ri2HiiEUtWk79CIiEgP9DZGPywsDDExMVi9erV2lpzU1FSUlpZixYoV2uMWL16MrKwsFBQUaLdNnz4dycnJePXVVzFnzhyIRCIkJiZCJpNpF9+6U2FhIQoKCvDqq692OG51zJgxiI2NRUBAAKRSKTIzM7Fv3z7I5XLExcV1++cnIuop3v1s8PbsYUj+sQjfZ5fg1PlreHXCEHj3M6yHxIiIqGfpdR31lStXYu3atUhLS0NVVRUCAwOxYcOGDu+6t7C2tkZSUhKWL1+O9evXQ61WIyoqCm+++Wa7w2x27doFAPcs2CdMmICcnBzs3bsXKpUK7u7uWLBgAebNmwexmMvNE1HfIpWI8OLjAQgb6IRN3+Xj/zYfwaRRvngyyhtCYd98UJeIiHQj0HAJ2B7DWXcMH/OlO+ZMN4bXAkYYAAAgAElEQVSQr+o6FTbvK8CR0+UY6GGHV+IGw8W+7bNMhsAQ8tWXMF+6Yb50w3zphrPuEBFRr7O2kOAPE4dg7oTBuKyowdubsvDL8VLwPg8RkXFjoU9EZAIEAgGih/TDspeGw7efDT7fcxqfpJzAzdq2a5IQEZFxYKFPRGRCnOzM8fq0CEwdMxAniivx1sZMHD9boe+wiIioB7DQJyIyMUKBADFRXnhr1jDYWknx8Y5cbN57Gg1KTsNJRGRMWOgTEZkoDxdr/G3WMMQM98JPx0rx9udZKCrlSuBERMaChT4RkQmTiIWYOnYg/ndaBJqa1FiRlIOdvxSjsUmt79CIiKiLWOgTERGCvB3w7ktRiBrsim8On8eKL7NRVlmj77CIiKgLWOgTEREAwNJcjLkTBuMPk4JRfr0O737+Gw7llHAaTiKiPoqFPhERtTIsyAXLXo6Cv6c9kvYXYm1yLm5UN+g7LCIi0hELfSIiasPBxgz/MzUMLz4egNMXr+OthCxkF5TrOywiItIBC30iImqXQCDAOLkH3pkzDE525vhn6kkkfJeHuoZGfYdGRESdwEKfiIjuyc3JCm/OlCNuhDd+PXkFb2/KQuGlG/oOi4iI7oOFPhER3ZdYJMQzj/hh6YtyCATAB1tysOPHIk7DSURkwFjoExFRpw30sMO7Lw3HqDA37M64gPe+OILLimp9h0VERO1goU9ERDoxl4ox+8lB+O9nQ3CjugHvJh7B/t8uQc1pOImIDIpY3wEQEVHfFOEvw4D+dkjcnY+vD57B8bMVePmpQXC0Ndd3aEREBN7RJyKiLrCzkuKPz4ViVkwgiktv4q2ELGTkXdF3WEREBBb6RETURQKBAI+Gu+Odl4bBzckSG77Jw//75hRq6lX6Do2IyKSx0Cciom7h6mCJJTMiMXmUL46cLsdbCVnIO39N32EREZksFvpERNRtREIhJjzsizdmymEmEWH118fw1fdnoFQ16Ts0IiKTw0KfiIi6na+bLd6eMwxjI91x4MglLPviCC5evaXvsIiITAoLfSIi6hFmEhFmPBGIRVPDUFOvwntfHMHujAtQqzkNJxFRb2ChT0REPSpkgBPeezkK4f7O2PFjEVZuzUHFjTp9h0VEZPRY6BMRUY+ztpBgwaRgvPzUIFwsr8Zbm7Lwn9wyaLjIFhFRj2GhT0REvUIgEODhEDcse2k4vFxtsGl3Pv6ZehK3apX6Do2IyChxZVwiIupVzvYW+Mu0COz77SJSfirG3xKqMGKIK347XY5rNxvgaGuGZx71Q/SQfvoOlYioT9PrHX2lUolVq1Zh5MiRCA0NxdSpU5Gent6ptlevXsXChQsxdOhQREZGYsGCBbh06VKb4wIDA9v976uvvnrg9yQioq4RCgV4Msobf5s1FEIhsDfrEipvNkADoPJmA77Ycxrpp7jCLhFRV+j1jv6SJUuwf/9+xMfHw9vbG6mpqZg7dy6SkpIQERHRYbuamhrEx8ejpqYG8+fPh1gsRmJiIuLj47Fz507Y2dm1On7kyJF4+umnW20LCwvr0nsSEVHXebnaQCgQtNmubFRjx49FvKtPRNQFeiv0c3Nz8d1332Hp0qWYPXs2AGDSpEmIi4vD6tWrsWXLlg7bbt26FRcuXEBKSgoGDx4MABg1ahQmTJiAxMRELFy4sNXxAwYMwMSJE+8Zj67vSURE3ePazYZ2t1+/1YAVX2ZDHiBDZIAMzvYWvRwZEVHfprehO3v37oVEIsGUKVO028zMzPDcc88hOzsb5eXlHbbdt28fwsPDtQU5APj5+SE6Ohp79uxpt019fT0aGtr/ZfKg70lERF3nZGvW7nYLMxHqlU34+oez+Mun6Xj389+w69fzKK2o6eUIiYj6Jr0V+vn5+fD19YWVlVWr7aGhodBoNMjPz2+3nVqtRkFBAYKDg9vsCwkJwfnz51FX13p+5h07diA8PByhoaGYMGECDhw40OX3JCKi7vHMo36Qilv/OpKKhZjxRCDefWk4/j7vIUwdMxBisQCpPxfjrxsz8eZnGfj3T0U4f+Ump+gkIuqA3obuKBQKuLq6ttkuk8kAoMM7+jdu3IBSqdQed3dbjUYDhUIBLy8vAEBERARiY2Ph4eGBsrIybN68Gf/1X/+FNWvWIC4u7oHes7OcnKx1Or67yGQ2ejlvX8V86Y450w3zdW9Pj7aBrY05Nu/JR8X1Ojg7WCD+yUEYLfcE0Jy/IQGumIkhqKyqQ8aJMvx6ogx7Mi/iu/QLcHGwQHRIf0SHuCHIxxEiYdsx/8aM/Us3zJdumC/dGFq+9Fbo19fXQyKRtNluZtb8FW5Hw2xatkul0g7b1tfXa7d9/fXXrY6ZPHky4uLisGrVKjz11FMQCAQ6v2dnVVZW9/pS7zKZDRSKW716zr6M+dIdc6Yb5qtzhnjZ44N50a3y1VHehgfKMDxQhlu1Shw7W4GcAgW+O1yMtJ+LYGslRaS/MyIDZQjycoBYZNzLxbB/6Yb50g3zpRt95UsoFHR4c1lvhb65uTlUKlWb7S1Fd0uBfbeW7Upl2wVWWtqam5t3eF5LS0u88MILWLNmDYqLi+Hn59fl9yQiot5nYynFqND+GBXaH3UNjThRXInsAgXST13Fj8dKYWkmRthAZ8gDZRji6wgziUjfIRMR9Sq9Ffoymazd4TkKhQIA4OLi0m47e3t7SKVS7XF3txUIBO0OwbmTm5sbAKCqqqrb3pOIiPTHwkyM4YNcMXyQK5SqJuSdv47swnIcO1OB9FNXIJUIETLACfIAGUL9nGFpzvUiicj46e1fuqCgICQlJaGmpqbVA7nHjx/X7m+PUChEQEAATp482WZfbm4uvL29YWFx7ynYWhbBcnR07Lb3JCIiwyCViBDu74xwf2c0NqlRcOkGcgoUyClUILtAAZFQgME+jpAHyhDu7wxby7bDNomIjIHeBi/GxMRApVIhOTlZu02pVCIlJQWRkZHaB3VLS0tRVFTUqu348eNx7Ngx5OXlabcVFxcjIyMDMTEx2m3Xrl1rc97r169j69at8PDwgI+Pj87vSUREfYdYJMQQH0fMHB+INf/1MN6YIcdjQz1QVlmDxD2nsWjdf7Byaw6+P3IJ127q/iwWEZEhE2j0OC/ZwoULcfDgQcyaNQteXl5ITU3FyZMn8cUXX0AulwMAZs6ciaysLBQUFGjbVVdXY/Lkyairq8OcOXMgEomQmJgIjUaDnTt3wsHBAQCwbt06HDx4EKNHj0b//v1x9epVbNu2DdeuXcM///lPjBkzRuf31AUfxjV8zJfumDPdMF+66a18aTQaXCqvRvbtO/2Xb8/N7+tmC3mgDPIAGVwdLXs8jq5i/9IN86Ub5ks3fBj3LitXrsTatWuRlpaGqqoqBAYGYsOGDdoivyPW1tZISkrC8uXLsX79eqjVakRFReHNN99sVZBHREQgJycHycnJqKqqgqWlJcLDwzFv3rw25+jsexIRUd8nEAjg5WoDL1cbTH5kAMoqa5BT2Fz07/ixCDt+LIK7zEq7Kq+nizUEAtOatpOI+j693tE3dryjb/iYL90xZ7phvnRjCPmqrKpHzhkFcgoUKCy5AY0GkNmbQx7ggshAGQb0t4XQQIp+Q8hXX8J86Yb50g3v6BMRERk4JztzPD7UE48P9cTNGiWOnlEgu1CBA0cuYW/WRdhZSxEZ0Dy8J9DLHiKhcc/VT0R9Fwt9IiKiDthaSfFouDseDXdHbb0Kx4sqkVOgwOHcMhzKuQwrczEi/GWIDJRhiI8DJGLO1U9EhoOFPhERUSdYmksQPaQfoof0Q4OqCSeLryGnsBzZhQr850QZzKQihPk5ITJAhpABTrAw469YItIv/itERESkIzOJqHl2nkAZGpvUOH3hOrILFThaqEBWfjnEIiGCfR0RGdA8V7+1hUTfIRORCWKhT0RE1AVikRDBA5wQPMAJM58IxNnLVben7SzHsbMVEAoECPSyhzxQhgh/GRxszPQdMhGZCBb6RERE3UQoFCDA0x4BnvZ4YdxAnL9yCzmFChwpUODL/YX4cn8h/NxttTP4uNhz1XUi6jks9ImIiHqAQCCAr5stfN1s8cwjA1BaWYucguYx/dsPncX2Q2fh5WKNyNsLdPV3tuJc/UTUrVjoExER9TCBQAB3Zyu4O/tiwsO+UNyoQ05h87Sdab+cw85fzsHV0RLygOZx/z79bFj0E1GXsdAnIiLqZTJ7C4wf7oXxw71wo7oBR89UIKegHHszL2J3xgU42poh0r+56Pf3sIdQyKKfiHTHQp+IiEiP7K3NMCbCHWMi3FFdp8LxsxXIKVTgp+Ol+D67BDaWEkT4OyMywAWDvB0gEXOBLiLqHBb6REREBsLaQoKHQ9zwcIgb6pWNOFF8DdkF5cjML8fPx8tgYSZC2EBnyANkCPZ10ne4RGTgWOgTEREZIHOpGMOCXDAsyAWqxibknW+eq//YmQpknLoKqVgI+SBXBHs7IGygEyzNOVc/EbXGQp+IiMjAScTNd/LDBjqjSa1G4aUq5BQocPRsBdJPlEEkFGCQtwMib8/Vb2cl1XfIRGQAWOgTERH1ISKhEIO8HTDI2wF/nBaJrBOXkVOgQHaBApv3FiBpbwH8PewQGeiCyABnONtxrn4iU8VCn4iIqI8SCgXw628Hv/52eG60Hy4rapBd2Fz0f33wDL4+eAbe/Wy003a6OVnpO2Qi6kUs9ImIiIyAQCCAh4s1PFysMXGkL65er22+01+oQMrPxUj5uRhuTpaQB7pAHiCDl6s15+onMnIs9ImIiIyQq4MlnnzIG08+5I1rN+tx9EwFsgvK8V36eXz763k425kj8vadfj93OwhZ9BMZHRb6RERERs7R1hzj5B4YJ/fArVoljp2pQHahAj/klGD/b5dgZyVFRIAM8gAZAr3sIRZxrn4iY8BCn4iIyITYWEoxKqw/RoX1R11DI3KLKpFdqED6ySv48ehlWJmLtXP1D/F1hFQi0nfIRPSAWOgTERGZKAszMaIGuyJqsCuUqiacOn8N2QXNc/X/evIKzCQihAxwhDzQBaF+TrAwY9lA1JfwbywRERFBKhEhwr95Hv7GJjUKLt5AdqECOYUKHClQQCwSYLCPI+QBMoT7O8PGknP1Exk6FvpERETUilgkxBBfRwzxdcSMxwNQVFqF7ILmoj+3qBKCvUCgpz3kgS6I8HeGo625vkMmonaw0CciIqIOCYUC+HvYw9/DHs+PHYiLV6u1d/q3HCjElgOFGNDfFvIAGSIDZXB1sNR3yER0Gwt9IiIi6hSBQADvfjbw7meDZx4ZgLLKGuTcXqAr+cciJP9YBA+Z1e1pO13gIbPiXP1EesRCn4iIiB6Im5MVnoq2wlPRPqioqkNOYQVyCsqx6/B5fHP4PFzsLRAZ2DxXv6+bLefqJ+plLPSJiIioy5ztLPDEME88McwTVTVKHD2jQE6BAgd+u4S9mRfhYGOGSP/m4T0BnnYQCTlXP1FP02uhr1Qq8fHHHyMtLQ03b95EUFAQFi1ahOjo6Pu2vXr1KpYvX47Dhw9DrVbjoYcewtKlS+Hp6ak9pqysDDt27MBPP/2ECxcuQCgUIiAgAAsWLGhzjnXr1uGTTz5pcx5nZ2ccPny46x+WiIjIRNhZSTE63B2jw91RW6/C8bPNc/X/kluKgzklsLaQINy/ea7+wT6OkIhZ9BP1BL0W+kuWLMH+/fsRHx8Pb29vpKamYu7cuUhKSkJERESH7WpqahAfH4+amhrMnz8fYrEYiYmJiI+Px86dO2FnZwcAOHjwIDZu3IjHHnsMkydPRmNjI9LS0jB79mx88MEHmDRpUpv3XrZsGczNf5894M6fiYiISDeW5hJEB/dDdHA/NCibcPJcc9GfXVCO/+SWwVwqQqifE+SBLggZ4AhzKQcbEHUXvf1tys3NxXfffYelS5di9uzZAIBJkyYhLi4Oq1evxpYtWzpsu3XrVly4cAEpKSkYPHgwAGDUqFGYMGECEhMTsXDhQgBAVFQUDh06BEdHR23badOmYeLEifjHP/7RbqH/5JNPwtbWths/KREREQGAmVQEeaAL5IEuaGxSI//CdWQXKHD0jAJZ+eUQi4QI9nWEPFCGsIHOsLaQ6Dtkoj5Nb4X+3r17IZFIMGXKFO02MzMzPPfcc/joo49QXl4OFxeXdtvu27cP4eHh2iIfAPz8/BAdHY09e/ZoC31/f/82baVSKR599FF8/vnnqK+vb3PHXqPRoLq6GlZWnCmAiIiop4hFQoQMcELIACfEjw/EmZIbyC5QILtQgWNnKyASChDkZY/I23P121ub6Ttkoj5Hb4V+fn4+fH19YWVl1Wp7aGgoNBoN8vPz2y301Wo1CgoK8Pzzz7fZFxISgsOHD6Ourg4WFhYdnluhUMDS0hJmZm3/0Rg9ejRqa2thZWWF8ePHY/HixbC3t3+AT0hERESdIRQKEOjlgEAvB0x7zB/nr9xqLvoLypG0rwBf7iuAn4dd81z9ATLI7Dv+HU9Ev9Nboa9QKODq6tpmu0wmAwCUl5e32+7GjRtQKpXa4+5uq9FooFAo4OXl1W77Cxcu4MCBA3jqqada3bG3tbXFzJkzERYWBolEgoyMDGzbtg15eXlITk6GVKr7Ut9OTtY6t+kOMpmNXs7bVzFfumPOdMN86Yb50o0x5svFxRbDQ92h0Whw8eotpJ8oQ3puGbb9cBbbfjiLAe52GBHihugQN3i62uj0Dbwx5qsnMV+6MbR86a3Qr6+vh0TSduxdy132hoaGdtu1bG+v8G5pW19f327buro6LFy4EBYWFli0aFGrfbNmzWr1OiYmBv7+/li2bBl27tyJqVOn3ucTtVVZWQ21WqNzu66QyWygUNzq1XP2ZcyX7pgz3TBfumG+dGMK+bIUCTAuvD/GhfdH+Y065BQ0r8r75d7T+HLvafRztIQ8sPlOv0+/exf9ppCv7sR86UZf+RIKBR3eXNZboW9ubg6VStVme0sh396wmju3K5XKDtu2N1NOU1MTFi1ahKKiIiQkJHQ4/v9O06ZNw6pVq5Cenv5AhT4RERF1Hxd7C8REeSEmygvXbzXg2JnmMf17Mi7iu/QLcLI1Q0SADPIAGfw97CEUNhf96aeuIOWnIly72QBHWzM886gfoof00/OnIep5eiv0ZTJZu8NzFAoFAHRYiNvb20MqlWqPu7utQCBod1jPX//6V/z0009Ys2YNhg8f3qkYhUIhXF1dUVVV1anjiYiIqHc42JhhTKQHxkR6oLpOheNnK5BdoMCPR0vx/ZES2FpKEBEgg6WZCAezL0PZqAYAVN5swBd7TgMAi30yenor9IOCgpCUlISamppWD+QeP35cu789LYtenTx5ss2+3NxceHt7t3kQ94MPPkBKSgr++te/IjY2ttMxqlQqlJWVITg4uNNtiIiIqHdZW0jwcIgbHg5xQ11DI04UVyKnUIGMvKtoUDa1OV7ZqMbXB8/Axd4C5mZiWEhFsDATw0wqgpAz7pER0VuhHxMTg02bNiE5OVk7j75SqURKSgoiIyO1D+qWlpairq4Ofn5+2rbjx4/Hhx9+iLy8PO0Um8XFxcjIyMDcuXNbnWfjxo3YtGkT5s+fj5kzZ3YYz7Vr11rNtw8ACQkJaGhowKhRo7rjIxMREVEPszATY/ggVwwf5ApVYxPmrf6p3eNu1arwflJ2m+1mUpG28DeXimF++2cLqQjmZh28loqbjzdr/tlcKoJELOQ03aR3eiv0w8LCEBMTg9WrV2tnyUlNTUVpaSlWrFihPW7x4sXIyspCQUGBdtv06dORnJyMV199FXPmzIFIJEJiYiJkMpn2ogEADhw4gFWrVsHHxwcDBgxAWlpaqxgef/xxWFpaAgDGjBmD2NhYBAQEQCqVIjMzE/v27YNcLkdcXFzPJoOIiIi6nUQsgpOtGSpvtp3gw9ZKgpdiB6Ne2Yi6hkbUK5va/qlsRH1DE27W1qJeu68Jas39J9oQCQXaiwLz2xcFzRcEoubXty8O2l5ANF8w3NlWJBT2RHrIBOh1nemVK1di7dq1SEtLQ1VVFQIDA7FhwwbI5fJ7trO2tkZSUhKWL1+O9evXQ61WIyoqCm+++SYcHBy0x50+3TwG7/z58/jLX/7S5n0OHjyoLfQnTJiAnJwc7N27FyqVCu7u7liwYAHmzZsHsZjLcRMREfVFzzzqhy/2nNaO0QcAqViI58f6I9TPSef302g0UDaqfy/8lY2oa2i663Xzz/UNrV/fqlVCceP3C4gGVdthRe2RSoTNFwbaC4aOLiDu9Q2EGFIJv2UwNQKNphOXpfRAOL2m4WO+dMec6Yb50g3zpRvmq3MMddYdtVrTfEFw+2Kg7vbP9Q1Nv79u9wKied+d30A0daLeEAhw+5sE0R3fHNx5AfH7hYG5mQiuztZQNahaX0DcvngQi/gtw904vSYRERFRL4se0g/RQ/oZ3IWRUCiApbkYluZdL8dUjerb3xT8XvzX3XFRUH/HNw91yjsuGBoace1mvfaCo76hCZ25RSkWCX+/YLj7mwbtswvtX0Dc+ZoPQPcsFvpEREREfZxELIRELIWtZdsFRXWh1mjQoGxCvbIJFlZmKL1ys8MLiDufY6hraMSNaiXKrtVqLy5UdwyXupdWzzLc+Y1Dy4VCmwuKO4YqmYm0r8Ui/QxNMtRvjAAW+kRERER0m1Ag0A7RkclsYN6FETqNTep2hxpphyo13P4W4c4LiNsXDlU1ty8YGpovOnR/APr3i4E7/2x9AXF72NJdFwzmUrF2sbX7ST91pdUzIIa2TgMLfSIiIiLqdmKRENYWQlhbSLr0Pnc+AN3RMKQ7n1e48wLiVq0S5Td+v4DQ5QHo5ucYWi4G2r+A2JN5sdWD3kDzOg0pPxWx0CciIiIiuheBQAAziQhmEhHsuvhezQ9AdzAMqdVzDW0vICqq6jv9AHR7U7rqAwt9IiIiIjIJzQ9AS2Bp3rVvGYDmB6CX/L90XL/Vtqh3sjXr8vt3B86NRERERESkI4lYiOdG+0Eqbl1OS8VCPPOon56iao139ImIiIiIHkDLOHzOukNEREREZGQMdZ0GgEN3iIiIiIiMEgt9IiIiIiIjxEKfiIiIiMgIsdAnIiIiIjJCLPSJiIiIiIwQC30iIiIiIiPEQp+IiIiIyAix0CciIiIiMkIs9ImIiIiIjBBXxu1BQqHApM7bVzFfumPOdMN86Yb50g3zpRvmSzfMl270ka97nVOg0Wg0vRgLERERERH1Ag7dISIiIiIyQiz0iYiIiIiMEAt9IiIiIiIjxEKfiIiIiMgIsdAnIiIiIjJCLPSJiIiIiIwQC30iIiIiIiPEQp+IiIiIyAix0CciIiIiMkIs9ImIiIiIjJBY3wHQ/ZWXl2Pz5s04fvw4Tp48idraWmzevBlRUVGdal9UVITly5cjJycHEokEY8aMweLFi+Ho6NjDketHV/K1ZMkSpKamttkeFhaG7du390S4epebm4vU1FRkZmaitLQU9vb2iIiIwJ/+9Cd4e3vft/3Vq1exfPlyHD58GGq1Gg899BCWLl0KT0/PXoi+93UlX+vWrcMnn3zSZruzszMOHz7cUyHr1YkTJ/Dpp58iLy8PlZWVsLGxQVBQEF577TVERkbet72p9a+u5MsU+1d7PvvsM6xevRpBQUFIS0u77/Gm1sfupku+TK2PZWZmIj4+vt19u3fvhp+f3z3bG0LfYqHfB5w7dw6fffYZvL29ERgYiKNHj3a67ZUrV/Diiy/C1tYWixYtQm1tLTZt2oTCwkJs374dEomkByPXj67kCwAsLCzw7rvvttpmrBdFALBx40bk5OQgJiYGgYGBUCgU2LJlCyZNmoQdO3bc8x+ympoaxMfHo6amBvPnz4dYLEZiYiLi4+Oxc+dO2NnZ9eIn6R1dyVeLZcuWwdzcXPv6zp+NzaVLl9DU1IQpU6ZAJpPh1q1b2LVrF2bMmIHPPvsMDz/8cIdtTbF/dSVfLUypf91NoVDgX//6FywtLTt1vCn2sTvpmq8WptbHZs2ahSFDhrTa5urqes82BtO3NGTwbt26pbl27ZpGo9FoDhw4oAkICNBkZGR0qu3bb7+tCQ8P11y5ckW77fDhw5qAgABNcnJyj8Srb13J1+LFizVyubwnwzM42dnZmoaGhlbbzp07pwkODtYsXrz4nm03bNigCQwM1Jw6dUq77ezZs5pBgwZp1q5d2yPx6ltX8vWPf/xDExAQoKmqqurJEA1ebW2tZsSIEZpXX331nseZYv9qT2fzxf7V/G/4zJkzNTNmzNA8/fTT9z3e1PuYrvkytT6WkZGhCQgI0Bw4cEDntobStzhGvw+wtraGg4PDA7Xdv38/xo4d2+rKc8SIEfDx8cGePXu6K0SD0pV8tWhqakJ1dXU3RWTYIiMjIZVKW23z8fGBv78/ioqK7tl23759CA8Px+DBg7Xb/Pz8EB0dbbT9qyv5aqHRaFBdXQ2NRtMTIRo8CwsLODo64ubNm/c8zhT7V3s6m68Wptq/cnNz8c0332Dp0qWdbmPKfexB8tXCFPtYdXU1GhsbO328ofQtFvpG7OrVq6isrERwcHCbfaGhocjPz9dDVIavpqYGcrkccrkcUVFRWLFiBRoaGvQdVq/SaDSoqKi45wWTWq1GQUFBu/0rJCQE58+fR11dXU+GaTA6k687jR49WtvHli5dihs3bvRwhPpXXV2Na9euobi4GB9++CEKCwsRHR3d4fGm3r90zdedTLF/aTQavPfee5g0aRIGDRrUqTam3MceJF93MrU+9r//+7+Qy+UICwvDSy+9hIKCgnseb0h9i2P0jVh5eTkAQCaTtdknk8lQWVmJpqYmiESi3g7NYMlkMrzyyisYNGgQ1Go1Dh06hMTERBQVFWHjxo36Dq/XfPPNN7h69SoWLVrU4TE3btyAUqnssH9pNBooFAp4eXn1ZKgGoTP5AgBbW1vMnDkTYf5O1GoAAAsrSURBVGFhkEgkyMjIwLZt25CXl4fk5OQ23xQYkzfeeAP79u0DAEgkErzwwguYP39+h8ebev/SNV+AafevnTt34uzZs/jnP//Z6Tam3MceJF+A6fUxiUSC8ePH45FHHoGDgwMKCgqwadMmTJ8+HTt27ICvr2+77Qypb7HQN2Itd6Hb+4tnZmYGAKivr4eVlVWvxmXI/vznP7d6HRcXB1dXVyQkJODw4cOdehCurysqKsKyZcsgl8sxceLEDo/rbP8ydp3NF9D8QNedYmJi4O/vj2XLlmHnzp2YOnVqT4aqV6+99hqef/55XLlyBWlpaVAqlVCpVB0WBqbev3TNF2C6/au6uhpr1qzBq6++ChcXl063M9U+9qD5Akyvj0VGRraa7WrcuHEYO3Ysnn32WXzyySdYs2ZNu+0MqW9x6I4Ra+lMSqWyzb6WTmjsT8p3h5deegkAkJ6erudIep5CocC8efNgZ2eHjz/+GEJhx/9EsH/plq+OTJs2DRYWFkbfvwIDA/Hwww/j2WefRUJCAk6dOnXPscGm3r90zVdHTKF//etf/4JEIsGcOXN0ameqfexB89URU+hjdwoKCkJ0dDQyMjI6PMaQ+hYLfSPWcqWuUCja7FMoFHBycuKwnU5wdnaGRCJBVVWVvkPpUbdu3cLcuXNx69YtbNy4sd2vHO9kb28PqVTaYf8SCAT3fY++TNd8dUQoFMLV1dXo+9edJBIJxo0bh/3793d4V8vU+9edOpOvjhh7/yovL8cXX3yB6dOno6KiAiUlJSgpKUFDQwNUKhVKSko6/Oym2Me6kq+OGHsfa4+bm9s9P68h9S0O3TFirq6ucHR0xMmTJ9vsy83NfaAHcEzRlStXoFKpjHou/YaGBsyfPx/nz59HYmIiBgwYcN82QqEQAQEBHfYvb29vWFhY9ES4evcg+eqISqVCWVlZuw9tGbP6+npoNBrU1NS0e2fLlPtXe+6Xr44Ye/+qrKyESqXC6tWrsXr16jb7x40bh7lz5+L1119vs88U+1hX8tURY+9j7bl06dI9J18wpL7FQt+IXLx4EQBaPdzxxBNPaB8UbJliMz09HefPn8crr7yilzgNxd35armjYW1t3eq49evXAwBGjhzZuwH2kqamJvzpT3/CsWPHsH79eoSHh7d7XGlpKerq6lotCDV+/Hh8+OGHyMvL004hVlxcjIyMDMydO7dX4u9tXcnXtWvX2lwwJiQkoKGhAaNGjerRuPWlvc9cXV2Nffv2wc3NDU5OTgDYv1p0JV+m2L88PDzafaB07dq1qK2txRtvvAEfHx8A7GNA1/Nlan2svc975MgRZGZmYtKkSdpthty3BBpTmgS1D2spNouKivDtt9/i2WefhYeHB2xtbTFjxgwAwNixYwEAP/zwg7ZdWVkZJk2aBHt7e8yYMQO1tbVISEiAm5ubUT4h3+JB8lVSUoLJkycjLi4OAwYM0M66k56ejtjYWHz00Uf6+TA97P3338fmzZsxZswYPPnkk632WVlZ4bHHHgMAzJw5E1lZWa2mFauursbkyZNRV1eHOXPmQCQSITExERqNBjt37uzyegaGqCv5CgsLQ2xsLAICAiCVSpGZmYl9+/ZBLpdj8+bNEIuN795LfHw8zMzMEBERAZlMhrKyMqSkpODKlSv48MMPERsbC4D9q0VX8mWK/asjM2fOxM2bN5GWltZqG/tY+zqbL1PrY/Hx8bCwsEBERAQcHBxw5swZbNu2DTY2NtixYwf69+8PwLD7lnH9HzFiH3/8cavX//73vwEA7u7u2sK1PW5ubvjyyy/x97//HWvWrIFEIsHo0aOxdOlSoy3ygQfLl62tLUaPHo3Dhw8jNTUVarUaPj4+WLJkCeLj43s8Zn05ffo0AODQoUM4dOhQq33u7u7awrU91tbWSEpKwvLly7F+/Xqo1WpERUXhzTffNNpfkF3J14QJE5CTk4O9e/dCpVLB3d0dCxYswLx584zuF2SLp59+GmlpaUhKSsLNmzdhY2OD8PBwrFy5EsOHD79nW1PsX13Jlyn2r64yxT7WFabWxx577DHs2rULn3/+Oaqrq+Ho6Ii4uDj893//t7bI74ih9C3e0SciIiIiMkKcdYeIiIiIyAix0CciIiIiMkIs9ImIiIiIjBALfSIiIiIiI8RCn4iIiIjICLHQJyIiIiIyQiz0iYiIiIiMEAt9IiIyKjNnztSufE1EZMqMbxkzIiLqdpmZmfdcIVokEiEvL68XIyIiovthoU9ERJ0WFxeHRx55pM12oZBfEBMRGRoW+kRE1GmDBw/GxIkT9R0GERF1Am/BEBFRtykpKUFgYCDWrVuHb7/9FhMmTEBISAhGjx6NdevWobGxsU2b06dP47XXXkNUVBRCQkIQGxuLzz77DE1NTW2OVSgU+L//+z+MGzcOwcHBiI6Oxpw5c3D48OE2x169ehX/8z//g2HDhiEsLAwvv/wyzp079//buWOQKP84juPvM6klQjRb6hKr4dAi3VIxIhMaAhuCo04JKocOg4KcwsEhGqolazCcWnKoQLghsjyweNaQyES0KI+GwHJSdPAaogfvf/H/35D/6un92n7f5/vc83tu+vDc97l1uW9J+h35RF+SVLKlpSU+f/5cVN+4cSObN28O12NjY8zNzZFKpdi6dStjY2Pcvn2bjx8/cu3atbDv1atXdHV1UV5eHvZms1lu3LjB1NQUN2/eDHtzuRwnT55kfn6ejo4O9u7dy9LSEhMTEwRBQEtLS9i7uLhIZ2cn+/fv59KlS+RyOe7du0c6nSaTybBhw4Z1+oYk6fdh0JcklWxgYICBgYGi+qFDhxgcHAzXU1NTPHjwgPr6egA6Ozvp6enh0aNHJJNJGhoaALh69SorKysMDw+TSCTC3osXL5LJZDhx4gRNTU0A9Pf38+nTJ4aGhmhtbS24/urqasH6y5cvnD17lu7u7rBWWVnJ9evXCYKg6HxJiiKDviSpZMlkkqNHjxbVKysrC9bNzc1hyAeIxWKcO3eOp0+fMjo6SkNDA/Pz87x8+ZL29vYw5H/vPX/+PI8fP2Z0dJSmpiYWFhZ4/vw5ra2tPwzp/3wZuKysrOhfgg4cOADA+/fvDfqS/goGfUlSyWpqamhubv7Pvt27dxfV9uzZA8Dc3BzwbRRnbX2tXbt2UVZWFvZ++PCBfD5PXV1dSfvctm0bmzZtKqhVVFQAsLCwUNJnSNKfzpdxJUmR828z+Pl8/n/ciST9OgZ9SdJPNzs7W1SbmZkBIB6PA7Bjx46C+lpv375ldXU17N25cyexWIw3b96s15YlKXIM+pKkny4IAl6/fh2u8/k8Q0NDABw5cgSAqqoqGhsbyWazTE9PF/TevXsXgPb2duDb2M3BgwcZHx8nCIKi6/mUXpKKOaMvSSrZ5OQkIyMjPzz2PcADJBIJTp8+TSqVorq6mmfPnhEEAR0dHTQ2NoZ9V65coauri1QqxalTp6iuriabzfLixQuOHTsW/uMOQF9fH5OTk3R3d3P8+HHq6+tZXl5mYmKC7du309vbu343Lkl/IIO+JKlkmUyGTCbzw2NPnjwJZ+MPHz5MbW0tg4ODvHv3jqqqKtLpNOl0uuCcffv2MTw8zK1bt7h//z6Li4vE43EuX77MmTNnCnrj8TgPHz7kzp07jI+PMzIywpYtW0gkEiSTyfW5YUn6g8Xy/t4pSfpJcrkcbW1t9PT0cOHChV+9HUn6qzmjL0mSJEWQQV+SJEmKIIO+JEmSFEHO6EuSJEkR5BN9SZIkKYIM+pIkSVIEGfQlSZKkCDLoS5IkSRFk0JckSZIiyKAvSZIkRdBXABpid7KAQ5EAAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"L9zXX5Pdvw9I","colab_type":"code","colab":{}},"source":["# make sure to save the model performance statistics and the associated model configuration. \n","# that is save the df_stats to csv file with a file name, say experiment 1\n","df_stats.to_csv(os.path.join(dir, 'label_experiment_health_stats.csv'))\n","# save the key hyper-parameters of this training experiment, say experiment 1\n","label_experiment_health = {\n","    \"epochs\": epochs,\n","    \"train_batch_size\" : train_batch,\n","    \"valid_batch_size\" : valid_batch,\n","    \"initial_learning_rate\": learning_rate,\n","     \"max_sentence_length\": max_length,\n","     \"loss_fucntion\": criterion,\n","     \"optimizer\": optimizer,\n","     # you need to manually type-in the following info\n","     \"BERT output\": \"mean value of [cls] embeddings of non-padded token from the second to the last layer\",\n","     \"activation function\": \"relu\",\n","     \"dropout rate of BERT output\": model_amazon.l2,\n","     \"# of fully connected linear layer\": 1,\n","     \"dataset\": \"Amazon Old Reviews Dataset\",\n","     \"comment\": \"The model seems to be working accordingly.\"\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odvnYYhghsH5","colab_type":"code","colab":{}},"source":["# save the experiment configurate assocaited with this experiment\n","# note that if you click the file icon (the third vertical one on the far left)\n","# you will see the save files, double click on them, you can see them.\n","import csv\n","with open(os.path.join(dir, 'label_experiment_health_config.csv'), 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key, value in label_experiment_health.items():\n","       writer.writerow([key, value])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WinIsU6zMpWt","colab_type":"text"},"source":["## Evaluate the Model Performance"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p9MQQ6yU9kLo","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1596149682697,"user_tz":420,"elapsed":1883,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"a387e494-4332-470a-8ca8-85917c1852d4"},"source":["# apply the trained model to the validation dataset\n","# get the model predictions and compare the comparisons to the true labels\n","model_amazon.eval()\n","predictions, labels = [], []\n","for step, batch in enumerate(valid_loader):\n","  input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n","  attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n","  label = batch['label'].to('cpu').numpy()\n","  \n","  with torch.no_grad():\n","    prediction = model_amazon(input_ids, attention_mask)\n","\n","  prediction = prediction.detach().cpu().numpy()\n","  predictions.append(prediction)\n","  labels.append(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tA38tbL6Qkv7","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596149684933,"user_tz":420,"elapsed":935,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"8806d1e6-1183-4d1d-f2e7-20fca26ae255"},"source":["# call the helper function-- pred_accuacy to compute the prediction accuracy in each batch\n","ac = []\n","for i in range(len(predictions)):\n","  ac_i = pred_accuracy(predictions[i], labels[i])\n","  ac.append(ac_i)\n","ac"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"]},"metadata":{"tags":[]},"execution_count":157}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QaL7PHMQOvjZ","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1596149689258,"user_tz":420,"elapsed":1049,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"7f3e1477-1d60-443c-cba2-b2cc5df9c112"},"source":["# transfer the outcomes into np\n","predictions = np.asarray(predictions)\n","labels = np.asarray(labels)\n","predictions[0]\n","# note that now the outcomes are still stored in batches"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.00561837],\n","       [0.00536927],\n","       [0.00552698],\n","       [0.00548297],\n","       [0.00534314],\n","       [0.00598945],\n","       [0.0053527 ],\n","       [0.00595799],\n","       [0.0058663 ],\n","       [0.00554708],\n","       [0.00544025],\n","       [0.00543119],\n","       [0.98453474],\n","       [0.00543794],\n","       [0.00543362],\n","       [0.00550991],\n","       [0.00541646],\n","       [0.00545827],\n","       [0.00561792],\n","       [0.00551827],\n","       [0.00543936],\n","       [0.00547449],\n","       [0.00553366],\n","       [0.00559984],\n","       [0.00538461],\n","       [0.0055438 ],\n","       [0.00560541],\n","       [0.00543569],\n","       [0.00549313],\n","       [0.00569603],\n","       [0.00568539],\n","       [0.00561495]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":158}]},{"cell_type":"code","metadata":{"id":"bWiqZYkAhsID","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596149695603,"user_tz":420,"elapsed":1036,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"b3c3e9fb-71bd-4b40-b4c7-d495455ec125"},"source":["# convert predictions stored in the batches into a long vector\n","pred = np.concatenate(predictions, axis=0 )\n","pred = np.concatenate(pred, axis=0 )\n","pred = pred.reshape(len(pred),1)\n","print(pred.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(166, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z5kkRWD0hsIE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596149698389,"user_tz":420,"elapsed":995,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"75e2b0ea-6098-411b-8ad9-3415b3c445ba"},"source":["# convert the true labels batches into a long vector\n","true_label = np.concatenate(labels, axis=0 )\n","true_label = true_label.reshape(len(true_label), 1)\n","print(true_label.shape)\n","type(true_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(166, 1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":160}]},{"cell_type":"code","metadata":{"id":"xXEasNQvhsIF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1596149700488,"user_tz":420,"elapsed":1059,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"ffe2c49a-fa8e-457b-bfeb-e1e6d62a0d68"},"source":["# put the predictions and labels into the same dataset\n","df = np.concatenate([pred, true_label], axis = 1)\n","df = pd.DataFrame(data=df, columns=[\"preds\", \"labels\"])\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.005618</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.005369</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.005527</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.005483</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.005343</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>0.983066</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>0.005974</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>163</th>\n","      <td>0.005419</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>0.005438</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>165</th>\n","      <td>0.005713</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>166 rows × 2 columns</p>\n","</div>"],"text/plain":["        preds  labels\n","0    0.005618     0.0\n","1    0.005369     0.0\n","2    0.005527     0.0\n","3    0.005483     0.0\n","4    0.005343     0.0\n","..        ...     ...\n","161  0.983066     1.0\n","162  0.005974     0.0\n","163  0.005419     0.0\n","164  0.005438     0.0\n","165  0.005713     0.0\n","\n","[166 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":161}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pjqBh76onyd-","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596149705940,"user_tz":420,"elapsed":1283,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"e0f30e31-8460-44d0-c0a9-a2cfe5ac0a03"},"source":["# see the total prediction accuracy\n","sum((df[\"preds\"]>=0.5) == df[\"labels\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["166"]},"metadata":{"tags":[]},"execution_count":162}]},{"cell_type":"code","metadata":{"id":"9r7T9I_yhsIJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1596149710017,"user_tz":420,"elapsed":1673,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"66f4f9db-29c1-46b0-96ea-3af4f6bf333a"},"source":["# find the index of the review that has the lowest predicted probabilty(of being a positive review) in true_label == 1 group. \n","df.loc[df.loc[df['labels'] == 1, :].idxmin()]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49</th>\n","      <td>0.982054</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.984535</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       preds  labels\n","49  0.982054     1.0\n","12  0.984535     1.0"]},"metadata":{"tags":[]},"execution_count":163}]},{"cell_type":"code","metadata":{"id":"3VurVKLthsIK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596149715526,"user_tz":420,"elapsed":822,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"0a0c0ea4-abb9-45af-d398-dd047deab166"},"source":["# see that review\n","valid_raw.iloc[1,0]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Just got it today can't believe the great sound. Took it out of the box in my car paired it unbelievable .<br />Haven't had it long enough to rate the battery's\""]},"metadata":{"tags":[]},"execution_count":164}]},{"cell_type":"code","metadata":{"id":"J9PDrrPNhsIN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1596149720571,"user_tz":420,"elapsed":1421,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"7877b92f-b7dd-4cc1-d001-e1deecb1e08d"},"source":["# alternatively, for all the reviews that have true_label == 1, \n","# let's sort their predicted probabilities\n","df.loc[df['labels'] == 1, :].sort_values('preds')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49</th>\n","      <td>0.982054</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>0.982081</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>0.983066</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>0.983174</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>0.983486</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>0.983582</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.984535</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        preds  labels\n","49   0.982054     1.0\n","62   0.982081     1.0\n","161  0.983066     1.0\n","80   0.983174     1.0\n","125  0.983486     1.0\n","96   0.983582     1.0\n","12   0.984535     1.0"]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"1FZooOSNTGDl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1596149741058,"user_tz":420,"elapsed":1259,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"7d329409-3bca-4228-cf77-2020e56ccf41"},"source":["df[df['labels']==1].preds.sort_values()[0:20]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["49     0.982054\n","62     0.982081\n","161    0.983066\n","80     0.983174\n","125    0.983486\n","96     0.983582\n","12     0.984535\n","Name: preds, dtype: float32"]},"metadata":{"tags":[]},"execution_count":166}]},{"cell_type":"code","metadata":{"id":"EBZsoNgG8S3h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1596149831634,"user_tz":420,"elapsed":815,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"cd9d75f1-13c3-4bed-a419-c5862830fda0"},"source":["valid_raw.iloc[49,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"I tried many diets pills before from almost every company. All the pills seem to give me the headache and heart racing affect. Best slim gave me best result, within first week I lost 5 pounds and within this first month I lost over 15 pounds. Even though this might not be the real deal, but since been taking this I lost the weight I don't need. I just got 10 more pounds to lose. Best slim is the way to lose weight with no weird feeling affect.\""]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"code","metadata":{"id":"wslamubJhsIQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596067942140,"user_tz":420,"elapsed":1233,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"9663d56c-2c60-4623-f6e4-0e789cc6a21e"},"source":["# see the reviews\n","valid_raw.iloc[158,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Bought this for my twins for meds for thrush. They were 3 months. It is a great idea however it is hard to hold because of the size'"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"huutjrb5EN2f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1596068008862,"user_tz":420,"elapsed":674,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"7ec3c4fb-5226-4260-94f8-f689993403e2"},"source":["valid_raw.iloc[137,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Other than the sizing that is bigger than the usual (as is Carhartt tradition), the jacket is just what I wanted. It is medium/heavy warmth, coated with durable sandstone duck, and well constructed. I'm looking forward to wearing this in more, and the sherpa isn't itchy (in case you were wondering). I'll update this review over time with anything major that changes, but for now this is another great Carhartt!\""]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"otzAxck1hsIR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1596149754713,"user_tz":420,"elapsed":1143,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"ad74598d-2e33-4c7c-b061-2befbd6a17a4"},"source":["# on the other way around, for all the reviews whose label == 0, \n","# let's sort their predicted probablities in descending order\n","df[df['labels'] == 0].sort_values('preds', ascending = False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>73</th>\n","      <td>0.013619</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>0.011661</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>0.010588</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>0.009841</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>0.007770</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.005350</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>0.005349</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.005343</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>0.005340</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>0.005336</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>159 rows × 2 columns</p>\n","</div>"],"text/plain":["        preds  labels\n","73   0.013619     0.0\n","110  0.011661     0.0\n","155  0.010588     0.0\n","137  0.009841     0.0\n","98   0.007770     0.0\n","..        ...     ...\n","34   0.005350     0.0\n","77   0.005349     0.0\n","4    0.005343     0.0\n","56   0.005340     0.0\n","74   0.005336     0.0\n","\n","[159 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":167}]},{"cell_type":"code","metadata":{"id":"jjDkJr_VhsIU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596068091344,"user_tz":420,"elapsed":1264,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"2084582c-5873-4daa-e12b-54fd50642fff"},"source":["# see the reviews\n","# after learning some examples, it seems that our model will give a high score as long as the food is good\n","# even though the service is not. \n","valid_raw.iloc[43,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'These are 20 miu of hcg sensitivity. First Response claims to be 15 miu. So these are pretty good. Also no evap lines. I confirmed with a first response after my positive result and these were correct.'"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"caar7ThkEoDA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1596068128171,"user_tz":420,"elapsed":1272,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"b1c082dc-9f5c-4ed2-98f5-3b1a644e7850"},"source":["valid_raw.iloc[30,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"I was excited to get these drops, but when they came in I saw that nowhere in the box or bottle does it say HCG. So I don't know if they are real or fake. I read online that if you pay less than $80 for a bottle claiming that it's HCG then their probably fake and what your taking is a water and alcohol which would suck because these drops do taste like alcohol. I don't know if their real or not im just rating them a 3 because my drops came in and I'm hoping that their real.\""]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"zl87LcO4EwKs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596068174854,"user_tz":420,"elapsed":1296,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"eba1b9ac-9ff4-49f2-f53d-38bba4639768"},"source":["valid_raw.iloc[45,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"i like how this is natural and vegan. I got this when i was pregnant and i'm still taking it now.\""]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"Za3QWpwDCvi7","colab_type":"text"},"source":["# **Second Test - Augmentation(performance decreased)**"]},{"cell_type":"code","metadata":{"id":"JWS2Jcn_C03H","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFIT6ml3Dex5","colab_type":"code","colab":{}},"source":["url='data_old_amazon_reviews.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKvIioBdDyp6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":893},"executionInfo":{"status":"ok","timestamp":1595954620550,"user_tz":420,"elapsed":737,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"ac85f1b4-481c-43e0-cd72-cee10ca4f659"},"source":["raw_review=pd.read_csv(url)\n","raw_review"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_title</th>\n","      <th>product_category</th>\n","      <th>star_rating</th>\n","      <th>helpful_votes</th>\n","      <th>total_votes</th>\n","      <th>vine</th>\n","      <th>verified_purchase</th>\n","      <th>review_headline</th>\n","      <th>review_body</th>\n","      <th>review_date</th>\n","      <th>social connectedness</th>\n","      <th>environment</th>\n","      <th>self_sufficiency</th>\n","      <th>transparency_authenticity</th>\n","      <th>tradition</th>\n","      <th>individuality</th>\n","      <th>diversity_equality</th>\n","      <th>privacy</th>\n","      <th>status</th>\n","      <th>thrift_value</th>\n","      <th>innovation</th>\n","      <th>fun_adventure</th>\n","      <th>health</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BOSS HUGO BOSS Men's Starfish Swim Trunk</td>\n","      <td>Apparel</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Good quality</td>\n","      <td>The quality is good, fits good but I didnt pay...</td>\n","      <td>6/23/2014</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Vedette Megane Firm Compression Sensual Corset...</td>\n","      <td>Apparel</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>I like this bodyshaper.</td>\n","      <td>This body shaper does what it says. It makes y...</td>\n","      <td>9/1/2013</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Adult Stilinski 24 Beacon Hills Lacrosse 2-Sid...</td>\n","      <td>Apparel</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Nice hoodie</td>\n","      <td>It looks well made. I bought it for my grandda...</td>\n","      <td>8/3/2015</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Carhartt Men's Sherpa Lined Sandstone Hooded M...</td>\n","      <td>Apparel</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Size Small Means Medium</td>\n","      <td>Other than the sizing that is bigger than the ...</td>\n","      <td>10/2/2014</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Roxy Juniors Gallery Backpack</td>\n","      <td>Apparel</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Five Stars</td>\n","      <td>Love my backpack.</td>\n","      <td>9/15/2014</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1656</th>\n","      <td>Virus Removal Service - Jupiter Support</td>\n","      <td>Software</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>IE issue</td>\n","      <td>i just got done with jupiter on i script prob ...</td>\n","      <td>4/26/2014</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1657</th>\n","      <td>Family Tree Maker 2011 Deluxe [Old Version]</td>\n","      <td>Software</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>Not for use on a netbook</td>\n","      <td>I used this software on my netbook and it divi...</td>\n","      <td>9/23/2011</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1658</th>\n","      <td>Learn Italian: Fluenz Italian 1 for Mac, PC, i...</td>\n","      <td>Software</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>awesome program</td>\n","      <td>hi, Just want to say it what a great company! ...</td>\n","      <td>4/30/2010</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1659</th>\n","      <td>Kaspersky Internet Security 2009 (3 User)</td>\n","      <td>Software</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Great product</td>\n","      <td>Great internet security product. I guess the b...</td>\n","      <td>12/22/2008</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1660</th>\n","      <td>Norton 360 2013 - 1 User / 3 PC</td>\n","      <td>Software</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Disapointing right out of the box</td>\n","      <td>If you are allergic to the chocolate and you a...</td>\n","      <td>12/9/2013</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1661 rows × 23 columns</p>\n","</div>"],"text/plain":["                                          product_title  ... health\n","0              BOSS HUGO BOSS Men's Starfish Swim Trunk  ...      0\n","1     Vedette Megane Firm Compression Sensual Corset...  ...      1\n","2     Adult Stilinski 24 Beacon Hills Lacrosse 2-Sid...  ...      0\n","3     Carhartt Men's Sherpa Lined Sandstone Hooded M...  ...      1\n","4                         Roxy Juniors Gallery Backpack  ...      0\n","...                                                 ...  ...    ...\n","1656            Virus Removal Service - Jupiter Support  ...      0\n","1657        Family Tree Maker 2011 Deluxe [Old Version]  ...      0\n","1658  Learn Italian: Fluenz Italian 1 for Mac, PC, i...  ...      0\n","1659          Kaspersky Internet Security 2009 (3 User)  ...      0\n","1660                    Norton 360 2013 - 1 User / 3 PC  ...      0\n","\n","[1661 rows x 23 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"g4ZXij0PEJ4Y","colab_type":"code","colab":{}},"source":["train_review = pd.DataFrame(None)\n","\n","train_review[['text','label']] = raw_review[['review_body','health']].iloc[0:1661,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UE3tiGDPEQgC","colab_type":"code","colab":{}},"source":["train_review=train_review.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10Ac0OiPEUpU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"ok","timestamp":1595954625896,"user_tz":420,"elapsed":538,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"944208ec-e32b-459e-a605-103dd97c3242"},"source":["train_review.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1660.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.068675</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.252976</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             label\n","count  1660.000000\n","mean      0.068675\n","std       0.252976\n","min       0.000000\n","25%       0.000000\n","50%       0.000000\n","75%       0.000000\n","max       1.000000"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"5Axw7hXXElV5","colab_type":"text"},"source":["## Define a Customized Dataset Class and Setup the Dataloader"]},{"cell_type":"code","metadata":{"id":"bnA-gucOEhNu","colab_type":"code","colab":{}},"source":["max_length = 128\n","train_batch = 32\n","valid_batch = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfyquibLEkCk","colab_type":"code","colab":{}},"source":["import numpy as np\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Li_ZR0DAEzA9","colab_type":"code","colab":{}},"source":["class AmazonDataset(Dataset):\n","\n","  def __init__(self, dataset, tokenizer, max_len):\n","    self.tokenizer = tokenizer\n","    self.data = dataset\n","    self.text = dataset.text\n","    self.label = dataset.label\n","    self.max_len = max_len\n","  \n","\n","  def __len__(self):\n","    return len(self.text)\n","\n","\n","  def __getitem__(self, index):\n","    text = self.text.iloc[index]\n","\n","    outputs = self.tokenizer.encode_plus(\n","        text,\n","        max_length = self.max_len,\n","        padding = \"max_length\",\n","        truncation = \"longest_first\",\n","        add_special_tokens = True,\n","        return_tensors = 'pt'\n","    )\n","\n","    input_ids = outputs['input_ids']\n","    attention_mask = outputs['attention_mask']\n","    \n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype = torch.long),\n","        'attention_mask': torch.tensor(attention_mask, dtype = torch.long),\n","        'label': torch.tensor(self.label.iloc[index], dtype = torch.float) \n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrDoP1b_FFat","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","train_raw, valid_raw = train_test_split(train_review, test_size = 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3DbN00BG1eA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1595954634518,"user_tz":420,"elapsed":640,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"b91d2c29-4379-43c4-b94e-94c470cfcc0a"},"source":["train_raw"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>222</th>\n","      <td>Beautiful nightgown, love the colored flower d...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1188</th>\n","      <td>Easy Install, looks great!</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1286</th>\n","      <td>When I received my order, another type of oil ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>438</th>\n","      <td>So far, so good. The battery fit fine and conn...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>I am not an expert by any means. I just listen...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>Fine</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>Terrible...Chinese knock off....does not work ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1569</th>\n","      <td>I bought this from Amazon for about $19 incl s...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>The product was ordered and 3 day later I had ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>972</th>\n","      <td>Seals out the dark, but does let a little ligh...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1494 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","222   Beautiful nightgown, love the colored flower d...      0\n","1188                         Easy Install, looks great!      0\n","1286  When I received my order, another type of oil ...      0\n","438   So far, so good. The battery fit fine and conn...      0\n","507   I am not an expert by any means. I just listen...      0\n","...                                                 ...    ...\n","164                                                Fine      0\n","608   Terrible...Chinese knock off....does not work ...      0\n","1569  I bought this from Amazon for about $19 incl s...      0\n","415   The product was ordered and 3 day later I had ...      0\n","972   Seals out the dark, but does let a little ligh...      0\n","\n","[1494 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"IoCtA8BIFZY9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1595954655028,"user_tz":420,"elapsed":743,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"289a5899-d499-4caa-ba24-b9931d0aa306"},"source":["health = pd.read_csv('health_augmented.csv')\n","health"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>these multis have been working for me for coup...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>these have working for me for a couple of now ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>these multis dose have been working for me for...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>need multis have been working for me for a cou...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>these multis have been working for me for a tw...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1012</th>\n","      <td>i really adenine wanted to maine like this bra...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1013</th>\n","      <td>i really wanted to like this constitute bra th...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1014</th>\n","      <td>i really wanted to wrinkled this while irritat...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1015</th>\n","      <td>i truly wanted to similar this bra the stain j...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1016</th>\n","      <td>i really wanted to like this bra the spot jacq...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1017 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","0     these multis have been working for me for coup...      1\n","1     these have working for me for a couple of now ...      1\n","2     these multis dose have been working for me for...      1\n","3     need multis have been working for me for a cou...      1\n","4     these multis have been working for me for a tw...      1\n","...                                                 ...    ...\n","1012  i really adenine wanted to maine like this bra...      1\n","1013  i really wanted to like this constitute bra th...      1\n","1014  i really wanted to wrinkled this while irritat...      1\n","1015  i truly wanted to similar this bra the stain j...      1\n","1016  i really wanted to like this bra the spot jacq...      1\n","\n","[1017 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"J_idClS6F3Ws","colab_type":"code","colab":{}},"source":["frames=[train_raw,health]\n","train_raw = pd.concat(frames)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kfPKXTccHYVE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595954658553,"user_tz":420,"elapsed":532,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"0c3e262c-9c4a-4832-8ecc-9cbcd86bd20e"},"source":["train_raw.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2511, 2)"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"OrMjzZgmHXvj","colab_type":"code","colab":{}},"source":["train_processed = AmazonDataset(train_raw, tokenizer, max_length)\n","valid_processed = AmazonDataset(valid_raw, tokenizer, max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0njFaD2Hddh","colab_type":"code","colab":{}},"source":["train_sampler = RandomSampler(train_processed)\n","train_loader = DataLoader(train_processed, batch_size = train_batch, num_workers = 0)\n","valid_sampler = SequentialSampler(valid_processed)\n","valid_loader = DataLoader(valid_processed, batch_size = valid_batch, num_workers = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"44UbOumrHoTO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1595954664005,"user_tz":420,"elapsed":976,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"2ec43da6-d987-4a9d-eab0-46b86e3bb4cf"},"source":["print(len(train_loader))\n","print(len(valid_loader))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["79\n","6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MiJaigYmHp4p","colab_type":"text"},"source":["## Define a Customized Neural Network with the First Hidden Layer as NLP Encoding Layer"]},{"cell_type":"code","metadata":{"id":"tA_vONo-H0cq","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7V-szjmrH4Pb","colab_type":"code","colab":{}},"source":["class AmazonBERT(torch.nn.Module):\n","\n","  def __init__(self):\n","    super(AmazonBERT, self).__init__()\n","\n","    self.l1 = model\n","\n","    self.l2 = torch.nn.Dropout(0.3) \n","\n","    self.l3 = torch.nn.Linear(768, 1)\n","\n","\n","  def forward(self, input_ids, attention_mask):\n","\n","    last, pooler = self.l1(input_ids = input_ids, attention_mask = attention_mask)\n","   \n","    output = last[:, 0 : attention_mask.sum(), :].mean(dim = 1)\n","    output = F.relu(output.squeeze())\n","    output = F.relu(self.l2(output))\n","    output = self.l3(output)\n","\n","    return torch.sigmoid(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"db7n920mILTe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1595954727347,"user_tz":420,"elapsed":684,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"9ce67c9f-2e27-4688-db9a-807df69bbd0c"},"source":["l1 = model\n","l1.to(device)\n","input_ids = train_processed.__getitem__(10)['input_ids'].to(device)\n","attention_mask = train_processed.__getitem__(10)['attention_mask'].to(device)\n","last, pooler = l1(input_ids = input_ids, attention_mask = attention_mask)\n","print(last.shape)\n","print(last.squeeze().shape)\n","print(pooler.shape)\n","print(pooler.squeeze().shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([1, 128, 768])\n","torch.Size([128, 768])\n","torch.Size([1, 768])\n","torch.Size([768])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Nvbw-KKpIXiO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1595954731855,"user_tz":420,"elapsed":699,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"c8587da4-dd3b-4165-bc9e-6be248e180e2"},"source":["output = last[:, 1 : attention_mask.sum(), :].mean(dim = 1)\n","output = output.squeeze()\n","output.shape\n","l2 = torch.nn.Dropout(0.3)   \n","l2.to(device)\n","l3 = torch.nn.Linear(768, 1)\n","l3.to(device)\n","output.to(device)\n","l3(l2(torch.tensor(output)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["tensor([-0.9102], device='cuda:0', grad_fn=<AddBackward0>)"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"markdown","metadata":{"id":"ydUL1X--I5sD","colab_type":"text"},"source":["## Create a BERT + NN Model as an Instance of the Customized Model Classs Defined Above and Setup the Loss Function and Optimizer"]},{"cell_type":"code","metadata":{"id":"7TQ-8n3vIdoD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595954734626,"user_tz":420,"elapsed":668,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"c5521117-2a01-4e45-cb74-397a6a31ca69"},"source":["model_amazon = AmazonBERT()\n","model_amazon.to(device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AmazonBERT(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"hXtpwgFtIfr_","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qEA_1w1AJALx","colab_type":"code","colab":{}},"source":["criterion = nn.BCELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHKD3Q0fJC3g","colab_type":"code","colab":{}},"source":["learning_rate = 10e-05"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9w_phWqJGZa","colab_type":"code","colab":{}},"source":["epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tfuLrV9mJKMP","colab_type":"code","colab":{}},"source":["from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","optimizer = AdamW(model_amazon.parameters(),lr = learning_rate,eps = 1e-8)\n","                  \n","total_steps = len(train_loader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SI3jZQTJPUy","colab_type":"code","colab":{}},"source":["import numpy as np\n","def pred_accuracy (prediction, label):\n","  pred_flat = np.around(prediction).flatten()\n","  label_flat = label.flatten()\n","  return np.sum(pred_flat == label_flat) / len(label_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeG5xtpyJVdP","colab_type":"text"},"source":["## Train the BERT + NN Model and Evaluate the Performance"]},{"cell_type":"code","metadata":{"id":"KJ-l3Gd8JS4x","colab_type":"code","colab":{}},"source":["import random\n","seed_val = 45\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xU_ixogKJaB8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595954749258,"user_tz":420,"elapsed":706,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"40c34562-e982-412f-d101-0b4ec262712c"},"source":["model_amazon = AmazonBERT()\n","model_amazon.to(device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AmazonBERT(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EegMfPr1oQ38","colab":{}},"source":["# set up the directory for storing the trained model\n","import os\n","# save to Google Drive\n","dir = \"/content/drive/My Drive\"\n","# save to local file\n","# dir = \"E://OneDrive - lmu.edu//Python Projects//BERT and ML\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5UlEEebkoTLa","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595955793315,"user_tz":420,"elapsed":1038936,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"d7723007-94fb-451f-91d8-16b57f07203f"},"source":["# Very Important: Each Time When You Train a Neural Network Again, \n","# Plase recreate the nural network, the dataloader, and the optimizer and its scheduler.\n","\n","\n","# train the model \n","# store the total loss and accuracy values of each epoch\n","training_stats = []\n","\n","# the epoch loop, number of rounds specified by epochs\n","for epoch_i in range(0, epochs):\n","  print('======== Epoch {:} / {:} =========='.format(epoch_i + 1, epochs))\n","  # zero the values of total loss and accuracy of the epoch\n","  total_loss = 0\n","  total_accuracy = 0\n","  # in the training stage, set the model into train mode\n","  model_amazon.train()\n","\n","  # the training step loop\n","  # recall that train_loader feed data into the NN in batchs to save memory and improve efficiency\n","  # then the # of total steps is about (# of samples/batch size)\n","  print(\"training\")\n","  for step, batch in enumerate(train_loader, 0):\n","    # feed the data into GPU using .to(device) method\n","    # note that the input_ids for one raw input is in the shape of (1, max_length)\n","    # after be processed into batch, the input_ids become (batch_size, 1, max_length)\n","    # however, BERT only takes input_ids in the shape of (batch_size, max_length),\n","    # (see here: https://huggingface.co/transformers/model_doc/bert.html#bertmodel)\n","    # so we need to do \"batch['input_ids'].squeeze()\" inestead of \"batch['input_ids']\"\n","    # to remove the unnecessy axis of \"1\". \n","    # same operation for attention_mask\n","    input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n","    attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n","    label = batch['label'].to(device, dtype = torch.float)\n","\n","    # at each step, before the NN does the feed forward, let's set the gradient to 0\n","    # as pytorch nn.Module automatically cumulates gradient from previous rounds\n","    # this is good for RNN training, but not necessy for us here. Thus, we turn it off.   \n","    optimizer.zero_grad()\n","    \n","    # for each raw input, the feed forward calculation give us two scalar, \n","    # representing the score/probability of the sample being 0/bad review class or 1/good review class  \n","    # note that since we feed the inputs/raw samples in batch, \n","    # the prediciton should be in the shape of (batch_size, # of classes)\n","    prediction = model_amazon(input_ids, attention_mask)\n","    prediction = prediction.squeeze()\n","\n","    # criterion is defined as a cross entropy loss function\n","    # it takes (prediction, ground truth) as input arugments\n","    # the former should be in the shape of (batch_size, # of classes), \n","    # the latter should be in the sahpe of (batch_szie, 1), \"1\" dimension records the true class id of the input\n","    # https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html   \n","    loss = criterion(prediction, label)\n","\n","    # with the loss, we can do back propagation to calculate the gradient\n","    # very easy, just one line of code  \n","    loss.backward()\n","\n","    # with the gradient, we can update the model paramters. \n","    # recall how we define the optimizer in the above cell  \n","    optimizer.step()\n","    \n","    # update the learning rate\n","    scheduler.step()\n","\n","    # to keep tracking on the model performance, we accumulate the total loss in every epoch  \n","    total_loss += loss.item()\n","      \n","    # for every 10 steps, we print out the epoce # and loss\n","    # again, the max_length of raw text input is 256, relatively long than usual, thus it will take longer to train. \n","    if step%10 == 0 and step != 0:\n","      print(f'Epoch:{epoch_i + 1}, Total_Loss:{total_loss}, Average_Loss:{total_loss/step}')\n","  \n","  # calcualte and store the average training loss of each batch in the current epoch\n","  avg_train_loss = total_loss / len(train_loader)\n","\n","  \n","\n","  # now let's set up the validation loop, meaning the trained model above will be used to evaluate the sample in validation dataset\n","  # note that this validation loop is in the same \"indent\" level as the training loop, and they both under the epoches loop\n","  print(\"validating\")\n","  # set the model now in the evaluation mode\n","  model_amazon.eval()\n","  # zero the values of total loss and accuracy\n","  total_loss = 0\n","  #total_accuracy = 0\n","\n","  # validation loop\n","  for step, batch in enumerate(valid_loader, 0):\n","    input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n","    attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n","    label = batch['label'].to(device, dtype = torch.float)\n","\n","    with torch.no_grad():\n","        prediction = model_amazon(input_ids, attention_mask)\n","        prediction = prediction.squeeze()\n","        loss = criterion(prediction, label)\n","\n","    total_loss += loss.item()\n","\n","    if step%10 == 0 and step != 0:\n","      print(f'Epoch:{epoch_i + 1}, Total_Loss:{total_loss}, Average_Loss:{total_loss/step}')\n","\n","  # calcualte and store the average training loss of each batch in the current epoch\n","  avg_valid_loss = total_loss / len(valid_loader)\n","\n","  training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_valid_loss\n","        }\n","    )\n","  \n","\n","\n","  # lastly, at the end of each epoch, let's save the model for later use\n","  # note that dir is defined before as \"./content/drive/My Drive\"  \n","  torch.save(model_amazon.state_dict(), os.path.join(dir, 'exper-epoch-{}.pt'.format(epoch_i)))\n","\n","print(\"training complete!\")\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["======== Epoch 1 / 10 ==========\n","training\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch:1, Total_Loss:1.8312144801020622, Average_Loss:0.18312144801020622\n","Epoch:1, Total_Loss:4.3267835304141045, Average_Loss:0.21633917652070522\n","Epoch:1, Total_Loss:7.417190380394459, Average_Loss:0.24723967934648197\n","Epoch:1, Total_Loss:9.180097313597798, Average_Loss:0.22950243283994495\n","Epoch:1, Total_Loss:12.475992860272527, Average_Loss:0.24951985720545053\n","Epoch:1, Total_Loss:12.781140619888902, Average_Loss:0.21301901033148168\n","Epoch:1, Total_Loss:12.923435324802995, Average_Loss:0.1846205046400428\n","validating\n","======== Epoch 2 / 10 ==========\n","training\n","Epoch:2, Total_Loss:21.337087228894234, Average_Loss:2.1337087228894234\n","Epoch:2, Total_Loss:23.799394447356462, Average_Loss:1.1899697223678232\n","Epoch:2, Total_Loss:27.29811381176114, Average_Loss:0.9099371270587047\n","Epoch:2, Total_Loss:29.742653850466013, Average_Loss:0.7435663462616503\n","Epoch:2, Total_Loss:42.41599662974477, Average_Loss:0.8483199325948954\n","Epoch:2, Total_Loss:52.915363881736994, Average_Loss:0.8819227313622833\n","Epoch:2, Total_Loss:53.60992370173335, Average_Loss:0.7658560528819051\n","validating\n","======== Epoch 3 / 10 ==========\n","training\n","Epoch:3, Total_Loss:15.820836290717125, Average_Loss:1.5820836290717124\n","Epoch:3, Total_Loss:19.1433028280735, Average_Loss:0.957165141403675\n","Epoch:3, Total_Loss:22.30899065732956, Average_Loss:0.7436330219109853\n","Epoch:3, Total_Loss:24.835158467292786, Average_Loss:0.6208789616823196\n","Epoch:3, Total_Loss:37.188136488199234, Average_Loss:0.7437627297639847\n","Epoch:3, Total_Loss:51.22462686896324, Average_Loss:0.8537437811493873\n","Epoch:3, Total_Loss:53.433650463819504, Average_Loss:0.76333786376885\n","validating\n","======== Epoch 4 / 10 ==========\n","training\n","Epoch:4, Total_Loss:7.556285858154297, Average_Loss:0.7556285858154297\n","Epoch:4, Total_Loss:10.093537226319313, Average_Loss:0.5046768613159657\n","Epoch:4, Total_Loss:13.359603896737099, Average_Loss:0.44532012989123665\n","Epoch:4, Total_Loss:15.802772633731365, Average_Loss:0.39506931584328414\n","Epoch:4, Total_Loss:25.933387003839016, Average_Loss:0.5186677400767803\n","Epoch:4, Total_Loss:32.06771349161863, Average_Loss:0.5344618915269772\n","Epoch:4, Total_Loss:34.87774809449911, Average_Loss:0.49825354420713014\n","validating\n","======== Epoch 5 / 10 ==========\n","training\n","Epoch:5, Total_Loss:19.27992570400238, Average_Loss:1.927992570400238\n","Epoch:5, Total_Loss:32.64383924007416, Average_Loss:1.632191962003708\n","Epoch:5, Total_Loss:41.76762396097183, Average_Loss:1.3922541320323945\n","Epoch:5, Total_Loss:48.392300724983215, Average_Loss:1.2098075181245804\n","Epoch:5, Total_Loss:55.91438889503479, Average_Loss:1.118287777900696\n","Epoch:5, Total_Loss:65.65864378213882, Average_Loss:1.0943107297023138\n","Epoch:5, Total_Loss:73.6019943356514, Average_Loss:1.0514570619378771\n","validating\n","======== Epoch 6 / 10 ==========\n","training\n","Epoch:6, Total_Loss:9.133087873458862, Average_Loss:0.9133087873458863\n","Epoch:6, Total_Loss:16.954470992088318, Average_Loss:0.8477235496044159\n","Epoch:6, Total_Loss:23.869884490966797, Average_Loss:0.7956628163655599\n","Epoch:6, Total_Loss:29.944589853286743, Average_Loss:0.7486147463321686\n","Epoch:6, Total_Loss:37.09935587644577, Average_Loss:0.7419871175289154\n","Epoch:6, Total_Loss:46.19669598340988, Average_Loss:0.7699449330568313\n","Epoch:6, Total_Loss:54.45159864425659, Average_Loss:0.7778799806322371\n","validating\n","======== Epoch 7 / 10 ==========\n","training\n","Epoch:7, Total_Loss:7.767831265926361, Average_Loss:0.7767831265926362\n","Epoch:7, Total_Loss:14.657934367656708, Average_Loss:0.7328967183828354\n","Epoch:7, Total_Loss:21.15345287322998, Average_Loss:0.7051150957743327\n","Epoch:7, Total_Loss:27.144927442073822, Average_Loss:0.6786231860518456\n","Epoch:7, Total_Loss:34.213411927223206, Average_Loss:0.6842682385444641\n","Epoch:7, Total_Loss:43.02415829896927, Average_Loss:0.7170693049828212\n","Epoch:7, Total_Loss:51.26751458644867, Average_Loss:0.7323930655206953\n","validating\n","======== Epoch 8 / 10 ==========\n","training\n","Epoch:8, Total_Loss:7.408687889575958, Average_Loss:0.7408687889575958\n","Epoch:8, Total_Loss:14.098451733589172, Average_Loss:0.7049225866794586\n","Epoch:8, Total_Loss:20.523304104804993, Average_Loss:0.6841101368268331\n","Epoch:8, Total_Loss:26.61087602376938, Average_Loss:0.6652719005942345\n","Epoch:8, Total_Loss:33.63998430967331, Average_Loss:0.6727996861934662\n","Epoch:8, Total_Loss:42.110275864601135, Average_Loss:0.7018379310766856\n","Epoch:8, Total_Loss:50.254263401031494, Average_Loss:0.7179180485861641\n","validating\n","======== Epoch 9 / 10 ==========\n","training\n","Epoch:9, Total_Loss:7.161908686161041, Average_Loss:0.7161908686161041\n","Epoch:9, Total_Loss:13.644784092903137, Average_Loss:0.6822392046451569\n","Epoch:9, Total_Loss:19.98850256204605, Average_Loss:0.6662834187348684\n","Epoch:9, Total_Loss:26.119173228740692, Average_Loss:0.6529793307185173\n","Epoch:9, Total_Loss:33.088373959064484, Average_Loss:0.6617674791812896\n","Epoch:9, Total_Loss:41.351561069488525, Average_Loss:0.6891926844914754\n","Epoch:9, Total_Loss:49.400763154029846, Average_Loss:0.7057251879147121\n","validating\n","======== Epoch 10 / 10 ==========\n","training\n","Epoch:10, Total_Loss:6.921451091766357, Average_Loss:0.6921451091766357\n","Epoch:10, Total_Loss:13.198904991149902, Average_Loss:0.6599452495574951\n","Epoch:10, Total_Loss:19.499535858631134, Average_Loss:0.6499845286210378\n","Epoch:10, Total_Loss:25.68259447813034, Average_Loss:0.6420648619532585\n","Epoch:10, Total_Loss:32.612997174263, Average_Loss:0.6522599434852601\n","Epoch:10, Total_Loss:40.63484460115433, Average_Loss:0.6772474100192388\n","Epoch:10, Total_Loss:48.56271451711655, Average_Loss:0.6937530645302363\n","validating\n","training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9_VJQU2WoZ06","colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"status":"ok","timestamp":1595956388153,"user_tz":420,"elapsed":1194,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"566b5c20-6432-46ba-e1e5-5205a5bb696c"},"source":["# plot the train statistics stored in training_stats\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","sns.set(style = \"darkgrid\")\n","\n","sns.set(font_scale = 1.5)\n","plt.rcParams['figure.figsize'] = [12, 6]\n","\n","df_stats = pd.DataFrame(data = training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f1ce85116d8>"]},"metadata":{"tags":[]},"execution_count":91},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAtUAAAGaCAYAAADAVb9PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeUBU5cIG8Gd2lhkYZBEEBFnEjdUV9w1F3HetzMxKSytvt7t17/1u+23RsqzspmZmmiuuoai4lGXuSy6IgrIoICLboMLAzPeHOUWAsgy8w/D8/uOcM+c86MkeXt5zXonRaDSCiIiIiIjqTCo6ABERERFRU8dSTURERERUTyzVRERERET1xFJNRERERFRPLNVERERERPXEUk1EREREVE8s1UREFiIjIwNBQUFYtGhRnc/x97//HUFBQWZMVTdBQUH4+9//LjoGEVGjkYsOQERkqWpTThMSEuDl5dWAaYiIyJJJuPgLEVHVtmzZUuHr48ePY+3atZg8eTI6d+5cYV9UVBTs7OzqdT2j0YjS0lLIZDLI5XUb89Dr9TAYDFCpVPXKUl9BQUEYO3Ys3nnnHaE5iIgaC0eqiYiqMXr06Apfl5eXY+3atQgLC6u07490Oh3UanWtrieRSOpdhhUKRb0+T0REdcM51URE9TRw4EBMmzYN58+fx8yZM9G5c2eMGjUKwL1y/eGHH2LixIno3r07OnXqhKioKMyfPx937typcJ6q5lT/ftu+ffswfvx4BAcHo3fv3nj33XdRVlZW4RxVzam+v62oqAj/+c9/EBkZieDgYEyZMgWnT5+u9P3k5eXhH//4B7p3747w8HA8/vjjOH/+PKZNm4aBAwfW689q/fr1GDt2LEJCQtC5c2c8+eSTOHbsWKXj9u/fj8ceewzdu3dHSEgI+vfvj7lz5+LKlSumYzIzM/GPf/wDAwYMQKdOnRAZGYkpU6Zg06ZN9cpIRFQXHKkmIjKD69evY/r06YiOjsaQIUNw+/ZtAEB2djY2bNiAIUOGYMSIEZDL5Thy5AiWLl2KCxcuYNmyZTU6/4EDB7B69WpMmTIF48ePR0JCAr788ks4Ojpi9uzZNTrHzJkz0aJFC8yZMwf5+flYvnw5nnnmGSQkJJhG1UtLSzFjxgxcuHAB48aNQ3BwMC5evIgZM2bA0dGxbn84v3r//fexdOlShISE4KWXXoJOp8O6deswffp0fPbZZ+jXrx8A4MiRI3j22WcRGBiIWbNmQaPR4MaNGzh06BDS0tLQpk0blJWVYcaMGcjOzsYjjzwCX19f6HQ6XLx4EceOHcPYsWPrlZWIqLZYqomIzCAjIwNvvvkmJk6cWGG7t7c39u/fX2FaxqOPPoqFCxdi8eLFOHPmDEJCQh56/suXL2P79u2mhyGnTp2KkSNH4ptvvqlxqe7QoQNeffVV09f+/v6YN28etm/fjilTpgC4N5J84cIFzJs3D88++6zp2LZt2+L111+Hp6dnja71RykpKVi2bBkiIiKwYsUKKJVKAMDEiRMxfPhwvPbaa9i9ezdkMhkSEhJgMBiwfPlyODs7m84xZ86cCn8eV65cwcsvv4ynn366TpmIiMyJ0z+IiMxAq9Vi3LhxlbYrlUpToS4rK0NBQQFu3bqFnj17AkCV0y+qMmjQoApvF5FIJOjevTtycnJQXFxco3M88cQTFb7u0aMHACA1NdW0bd++fZDJZHj88ccrHDtx4kRoNJoaXacqCQkJMBqNeOqpp0yFGgBatmyJcePG4dq1azh//jwAmK4THx9faXrLffePOXz4MHJzc+uci4jIXDhSTURkBt7e3pDJZFXuW7VqFdasWYPLly/DYDBU2FdQUFDj8/+RVqsFAOTn58Pe3r7W53BycjJ9/r6MjAy4ublVOp9SqYSXlxcKCwtrlPePMjIyAACBgYGV9t3flp6ejuDgYDz66KNISEjAa6+9hvnz56Nz587o06cPRowYgRYtWgAAPD09MXv2bHzxxRfo3bs32rdvjx49eiA6OrpGI/9ERObGkWoiIjOwtbWtcvvy5cvx+uuvw83NDa+//jq++OILLF++3PSquZq+1bS6wm6Oc1jam1WdnJywYcMGfP3115g2bRqKi4vx3//+F0OHDsXJkydNx/3pT3/Crl278Morr8Db2xsbNmzAxIkT8f777wtMT0TNFUeqiYga0JYtW+Dp6YklS5ZAKv1tHOP7778XmKp6np6eOHToEIqLiyuMVuv1emRkZMDBwaFO570/Sn7p0iW0bt26wr7Lly9XOAa49wNA9+7d0b17dwBAYmIixo8fj8WLF+OLL76ocN5p06Zh2rRpKCkpwcyZM7F06VI8+eSTFeZjExE1NI5UExE1IKlUColEUmE0uKysDEuWLBGYqnoDBw5EeXk5vv766wrb161bh6KionqdVyKRYNmyZdDr9abtN27cQGxsLDw9PdGhQwcAwK1btyp93s/PDyqVyjRdpqioqMJ5AEClUsHPzw9AzafVEBGZC0eqiYgaUHR0NBYsWICnn34aUVFR0Ol02L59e51XTGxoEydOxJo1a7Bw4UKkpaWZXqm3c+dO+Pj4VPvg4MP4+fmZRpEfe+wxDBs2DMXFxVi3bh1u376N+fPnm6an/Pvf/0ZWVhZ69+6NVq1a4e7du9ixYweKi4tNi+4cPnwY//73vzFkyBC0adMG9vb2OHv2LDZs2IDQ0FBTuSYiaiyW+a86EZGVmDlzJoxGIzZs2IC33noLrq6uGDZsGMaPH4+YmBjR8SpRKpVYsWIF3nvvPSQkJGDHjh0ICQnBV199hX/+85+4e/dunc/9l7/8BT4+Pli9ejUWLFgAhUKB0NBQLFiwAF26dDEdN3r0aMTGxmLTpk24desW1Go1AgIC8PHHH2Po0KEA7i2DHhUVhSNHjmDbtm0wGAzw8PDArFmz8OSTT9b7z4GIqLYkRkt7QoWIiCxOeXk5evTogZCQkBovWENE1JxwTjUREVVQ1Wj0mjVrUFhYiF69eglIRERk+Tj9g4iIKvjXv/6F0tJShIeHQ6lU4uTJk9i+fTt8fHwwadIk0fGIiCwSp38QEVEFmzdvxqpVq3D16lXcvn0bzs7O6NevH1588UW4uLiIjkdEZJFYqomIiIiI6olzqomIiIiI6omlmoiIiIionqzmQcW8vGIYDJzJIpKzsxq5uTrRMchC8f6g6vDeoOrw3qDqiLo3pFIJnJzsq9xnNaXaYDCyVFsA/h3Qg/D+oOrw3qDq8N6g6ljavcHpH0RERERE9cRSTURERERUTyzVRERERET1xFJNRERERFRPLNVERERERPVkNW//ICIiIqrKnTvF0OkKUF6uFx2FzOTGDSkMBoPZzieVyqBS2cLe3gFyuaJO52CpJiIiIqul15eiqCgPWq0LFAoVJBKJ6EhkBnK5FGVl5inVRqMR5eXluHu3GLduZaNFi5Z1Ktac/kFERERWq6goH2q1I5RKGxZqqpJEIoFcLoda7Qg7Ow2KiwvrdB6WaiIiIrJaZWWlUKlsRcegJsLGxh4lJXfq9FlO/6ijI1knsDV5J/JK8uGk0mKUfzS6uUeIjkVERES/YzCUQyqViY5BTYRMJoPBUF6nz7JU18GRrBNYnbgResO9Bx7ySvKxOnEjALBYExERWRhO+6Caqs+9wukfdbA1eaepUN+nN+ixNXmnoEREREREJBJLdR3kleTXajsRERFRUzN37jOYO/eZRv9sU8XpH3XgpNJWWaAlALalxGOAV2+olfaNH4yIiIisXu/eXWp03Pr1W+Hh0aqB09B9EqPRaBQdwhxyc3UwGBrnW/njnGoAkEvlaGXvjrSiDChlSvTx7IFB3v3gqNI0SiZL4OqqQU5OkegYZKF4f1B1eG9Qdcxxb2RlpcLd3cdMiSxDfHxcha/XrfsW2dmZeP75lyps79t3AGxt6/7mE73+Xs9RKGr/zub6fLYmzPme6j960D0jlUrg7KyuOlODpLFy9x9GrOrtH9d1WYhP3Yu9aT/g+4yf0LNVd0S17gcnG63g1ERERGQNhg6NqfD1/v0JKCjIr7T9j+7evQsbG5saX6c+hbihyrQlY6muo27uEVW+6aOV2h0zOj6C4W2isCt1P364dggHr/2MHh6dMcRnAFxsnQWkJSIiouZk7txnoNPp8Ne/voJFiz7ExYuJePTRxzFz5iz88MN+bN26CUlJF1FYWABXVzfExIzEtGkzIJPJKpwDAD755AsAwIkTx/DCC7Px1lvv4cqVFGzevBGFhQUIDg7FX/7yCry8vM3yWQDYuHEd1qxZhdzcm/D398fcuX/CkiWLK5zT0rBUNxA3O1c81n4ihvkOxu60/Th0/QgOZR5D15bhGOIzAO72bqIjEhERUR0cOpeF2APJyC0sgbODCuP6+SOyo7voWJXk5+fhr3/9E4YMiUZ09HC0bHkvY1zcdtja2mHy5EdhZ2eL48ePYenSz1FcXIw5c1586HlXrFgGqVSGRx55HEVFhfj225V47bV/YcmSFWb57KZNG/Dhh+8hLCwCkydPRWZmJv7xj5eh0Wjg6mq5/YmluoE52zphStBYRPsORELa9/jh2s84knUC4W7BiPYdBE+1h+iIREREVEOHzmVhxY5ElP46nze3sAQrdiQCgMUV65s3c/D3v/8bI0aMrrD91VffhEr12zSQMWMm4P3338amTevx9NPPQqlUPvC8ZWVl+PLLFZDL79VIBwdHfPTRfKSkXIafX0C9PqvX67F06WJ07BiMhQs/Mx0XEBCIt956laWaAK3KEeMDR2KIzwDsTb833/rEjTMIdumAYb6D4OPg/fCTEBERkVn8+EsmDp7JrPXnkq8XoKy84osRSssMWB53Ad+ful7r8/UO8UCv4IYZYLOxsUF09PBK239fqG/fLkZpqR6hoeHYsiUWqalXERjY9oHnHT58lKnsAkBoaBgA4Pr1aw8t1Q/7bGLieRQUFOC558ZWOC4qKhoff/zBA88tGkt1I9Mo1RjtPwyDW/fD/owfsS/9IN47tgjtW7RFtO8gBGjbiI5IRERE1fhjoX7YdpFcXd0qFNP7UlKSsWTJYpw4cRTFxcUV9hUX6x563vvTSO7TaBwAAEVFD39Ty8M+m5V17wedP86xlsvl8PCw7N/us1QLYq+ww/A2URjo3Qc/XDuEhLTv8eGJxQjU+iHadxCCnAK4rCoREVED6RVctxHiv3z2I3ILSyptd3ZQ4W+PVn6BgUi/H5G+r6ioCM8//wzs7NSYOXM2PD29oFQqkZSUiMWLF8FgePhr6qRSWZXba/KW5vp81tKxVAtmK7fBEJ8B6O/VCwevH8ae1ANYdGoJ2ji0RrTvIHR0bsdyTUREZCHG9fOvMKcaAJRyKcb18xeYquZOnjyOgoICvPXW+wgL++2HgMzM2k9daQju7vd+0MnISEdoaLhpe1lZGTIzM+Hv/+DpJSJxmXILoZQpMdC7D16L/BumBI1FQWkRFp9ZjnePfoRTN36BwdgwLzgnIiKimovs6I7pw9rB2UEF4N4I9fRh7SzuIcXqSKX3qt/vR4b1ej02bVovKlIF7dp1gKOjI7Zu3YSysjLT9t27d6KoqFBgsofjSLWFUcgU6OMZiZ4e3XAk6wTiU/diydmVcLdviWifgYhwC4Gsml+dEBERUcOL7OjeZEr0HwUHh0CjccBbb72KCRMmQyKRID4+DpYy+0KhUODJJ5/Bhx++j3nznsOAAYOQmZmJHTu2wdPTy6J/e8+Ragslk8oQ2aor/q/HXzCjw1RIAHx1/lu8cXg+frp+FOWGctERiYiIqIlxdNTivfc+hLOzC5YsWYxvv/0GXbp0x3PPvSA6msn48ZMxb97LyMrKxKeffoTTp0/inXc+gFqtgVKpEh2vWhKjNcwMB5Cbq4PBYBXfSpUMRgPO3DyPnVf2IF13HU4qLYb4DECkRxcoZJaxFKirqwY5OQ9/8peaJ94fVB3eG1Qdc9wbWVmpcHf3MVMiEsVgMGDEiCj06zcAf/vbvyCXS1FW1jBTYx90z0ilEjg7q6vcx+kfTYRUIkWYayeEunTEudxE7LyagLVJm7Dz6h4Mbt0PvTx7QCV78MvaiYiIiCxdSUkJVKqKI9I7d36HwsIChId3FpTq4ViqmxiJRIJOLu3R0bkdkvKSsfNqAjZe3o741H0Y5N0XfbwiYSuv/AodIiIioqbgzJlTWLx4Efr3HwgHB0ckJSXiu++2ws/PHwMGDBYdr1os1U2URCJBUIsABLUIQHL+Vey8moAtKTuwK20/Bnj1Qn/v3rBX2ImOSURERFQrrVp5wsXFFRs2rEVhYQEcHBwRHT0cs2fPhUJhGVNeq8I51VYktTAd8Vf34vTNc7CRqdDXqycGeveBRln13B9z47xIehDeH1Qd3htUHc6ppupwTjU1KB8HbzwTMh3XdJmIv7oXu1P3Y1/6QfT27I7BrftBq3IUHZGIiIjIKrFUWyFPtQee7PQohhdHIT51Hw5k/IQfMg6hR6uuGNK6P5xtW4iOSERERGRVWKqtWEt7NzzeYTJi2kRhd+o+HLp+FD9dP4Ju7hEY6jMAbnauoiMSERERWQWW6mbAxbYFprYbj2jfQdiTdgA/Xj+Mw5nH0bllKIb6DEQrddNcFYqIiIjIUrBUNyNONlpMbDsaQ30HYm/aDzhw7Sccyz6FMNdOGOo7EK01XqIjEhERETVJLNXNkINSgzEBMRjs0w/70w9if8aPOJVzFh2d2yHadxD8HPmUNBEREVFtsFQ3Y2qFPUb4DcWg1n1xIOMQ9qZ/jwXHP0VbpwAM8x2EQK0fJBKJ6JhEREREFk8qOgCJZyu3RbTvQLzR8xWMCxiBrOJsfHTyf/jgxGKcy70IK3mVOREREVUhLm4bevfugszM66ZtEyaMxFtvvVqnz9bXiRPH0Lt3F5w4ccxs52wMLNVkopIpMah1X7wW+XdMajsGeXfz8dnpZXjv2CKczjkHg7FhXrJORERENffXv/4Jgwf3xp07d6o95qWX5mLo0H4oKSlpxGS1s2dPPNatWy06htlw+gdVopQp0M+rJ3q16oYjWScQn7oPX/yyAq3s3RHtOxDhbiGQSvjzGBERkQhRUUPx008/4ODBA4iKiq60Py/vFo4fP4ohQ4ZBpVLV6RqrV2+EVNqw/69PSNiFS5eSMGnSIxW2h4VFICHhR4tekrwqbEZULblUjp6tuuH/ur+M6R2mwGA04Mtzq/HG4fn4OfMYyg3loiMSERE1O3369IetrR327Imvcv/evXtQXl6OIUMqF+6aUiqVkMvFjL1KpVKoVKoGL/XmxpFqeiiZVIZu7hHo0jIMp3LOYufVBKy8sA5xV/ZgiE9/yKQyfJeyG/kl+dCqtBjlH41u7hGiYxMREVklGxsb9OnTD/v27UFhYSEcHBwq7N+zJx7Ozs7w9vbB/Pnv4PjxI8jOzoaNjQ0iIrpgzpwX4eHR6oHXmDBhJMLDO+Of/3zVtC0lJRkLF76Ps2d/gaOjI0aPHgcXl8oLyf3ww35s3boJSUkXUVhYAFdXN8TEjMS0aTMgk8kAAHPnPoNTp04AAHr37gIAcHf3wIYN23DixDG88MJsfPzx54iI6GI6b0LCLnzzzVdITb0Ke3t79OzZB88++wK0Wq3pmLlzn4FOp8P//d/r+OCD93DhwjloNA6YOHEKHn10eu3+oGuJpZpqTCqRIsItBOGuwTibewE7ribg24uxFY7JK8nH6sSNAMBiTUREVulI1glsTd6JvJJ8OAkaTIqKisauXTuwf38CRo0aa9qelZWJs2fPYMKEKbhw4RzOnj2DwYOHwtXVDZmZ17F580Y8//wsfPPNetjY2NT4erm5N/HCC7NhMBjw2GPTYWNji61bN1U5vSQubjtsbe0wefKjsLOzxfHjx7B06ecoLi7GnDkvAgCmT38Sd+7cQXZ2Jp5//iUAgK2tXbXXj4vbhrfffg0dOwbj2WdfwM2b2Vi/fi0uXDiHJUu+rpCjsLAAf/7zCxgwYBAGDRqCffv2YPHiRfDzC0BkZK8af8+1ZVGlesmSJZg/fz7atWuHLVu2iI5D1ZBIJAh26YBOzu3xj4NvoEivq7Bfb9Bja/JOlmoiIrI6R7JOYHXiRugNegDiBpO6du0OrdYJe/bEVyjVe/bEw2g0IipqKPz9AzBgwOAKn+vVqy9mz56B/fsTEB09vMbXW7VqBQoK8rF06UoEBbUDAAwbNgJTp46tdOyrr74Jleq3wj5mzAS8//7b2LRpPZ5++lkolUp07doDsbHrUVCQj6FDYx547bKyMixevAgBAW2xaNH/fp2aIkVgYDu8+uo/sW3bJkyYMMV0/I0b2fjPf940zTcfMWI0JkwYge++29I8SnVOTg4WL14MO7vqf0ohyyKRSCoV6vvySvJhMBr4QCMREVmkw5nHcSjzaK0/d6UgDWXGsgrb9AY9Vl3YgJ+uH6n1+SI9uqK7R+daf04ul2PgwMHYvHkjbt68CRcXFwDAnj274OXljQ4dOlU4vqysDMXFOnh5eUOt1iApKbFWpfrQoR8RHBxqKtQA4OTkhKioYdi0aX2FY39fqG/fLkZpqR6hoeHYsiUWqalXERjYtlbfa2LieeTl3TIV8vsGDozCp59+hJ9++rFCqVar1Rg8eKjpa4VCgfbtO+L69Wu1um5tWUypXrBgATp16gSj0YjCwkLRcaiGnFRa5JXkV7nvv0cWYpR/NDo5t+ciMkREZBX+WKgftr0hRUVFIzZ2Pfbu3YVJkx7B1atXcPlyEmbMeBoAUFJyFytXfoW4uG3IyblRYd0Jna7qQbHqZGdnITg4tNL21q0rr8KckpKMJUsW48SJoyguLq6wr7i4dtcF7k1pqepaUqkUXl7eyM7OrLDdza1lpd6h0TggOflyra9dGxZRqs+cOYOtW7di48aNePvtt0XHoVoY5R9d4ddgAKCQKtDTowsu3LqEz898BT9HH4zyG4ZAJz+BSYmIiH7T3aNznUaI//Xj21UOJjmptJgXMdsc0WosODgUHh6e2L17JyZNegS7d+8EANO0hw8/fB9xcdswceJUdOoUDLVaDUCCV199pcEWdisqKsLzzz8DOzs1Zs6cDU9PLyiVSiQlJWLx4kUwGBp+zQupVFbl9oZezE54qTYajXjjjTcwZswYtG/fXnQcqqX788e2Ju+s9PaPckM5fs48hu+u7MbCk5+jg3MQRvkNg7fmwU8cExERWarqBpNG+df99XX1MXjwEKxcuRwZGelISNiFoKD2phHd+/Omn3/+T6bjS0pKaj1KDQAtW7ojIyO90va0tNQKX588eRwFBQV46633ERb22xzzqldcrNlvsd3dPUzX+v05jUYjMjLS0aaNf43O09CET3jdvHkzLl++jHnz5omOQnXUzT0Cb/Z6BWsnL8abvV4xFW2ZVIZent3xauTfMMY/BlcL0vDO0YX48uwq3LidIzg1ERFR7XVzj8Aj7cbDSXXvNW5OKi0eaTde2MP5Q4YMAwB88smHyMhIr/Bu6qpGbDduXIvy8tqvMxEZ2Qu//HIaFy8mmrbl5eVh9+4dFY67/27p348K6/X6SvOuAcDW1rZGBb9duw5wcmqBzZs3QK//7YeZffsSkJNzAz17NtzDh7UhdKRap9NhwYIFeOaZZ+Dm5lavczk7q82UiurD1VVT5fZH3EdidMggbLu4G99d3IuTOb9goF8vTOgYgxa22io/Q9anuvuDiPcGVae+98aNG1LI5eYdQ+zp1QU9vbo8/MBGEBgYgMDAtjh48HtIpVIMHRpt+n579+6D+Pg4aDRqtGnjh19+OYOjR4/A0VELiURiOk4qvTdiLJNV/LP6/TGPP/4E4uN34KWX5mLSpCmwsbHB5s2xcHf3wOXLl0yfDQ8Pg4ODA95661VMmjQVEgmwY0ec6Zy/v0b79u2xa9cOfPLJh+jQoSNsbW3Rp08/yGTSCsfK5UrMmfMC3nzzVbzwwixERUUjOzsL69evgb9/AMaOHW86p0QigUSCSn/n9+dY1+RekEqldbrvhJbqxYsXQ6FQYMaMGfU+V26uDgZDw86VoQdzddUgJ6fogccMch+ILk5dEZ+agH0pP+HAlUPo79UbUT79Ya/gm1+sWU3uD2qeeG9QdcxxbxgMBpSVNfw8XpGioqJx6VISwsM7Q6t1Nn2/zz//ZwASxMfvQElJKYKDQ7Fw4ad46aXnYTQaTcfd70/l5RX/rH5/jFbrjI8//hwffvgeVqxYXmHxl3feecP0WXt7B7z77of45JOF+N//PoVG44AhQ4ahS5dueOmluRWuMXLkOCQmXsB3323DmjWr4O7ugcjIPigvN1TKEx09AnK5AqtWrcCiRR/C3t4eUVHRmD37echkCtNxRqMRRiMq/Z3fHzmvyb1gMBiqve+kUkm1A7kSY0PP2q7GjRs3MHDgQLz44osYNmyYaftLL70EnU6HL774AhqNBo6OjjU6H0u1eLX9x+/mnVv47souHM06CRu5CoNb98cA795QyZQP/zA1OSxOVB3eG1Qdc9wbWVmpcHev/IYKatrkcmmD/bD0oHvGIkv1hQsXMGbMmAce8/TTT+Pll1+u0flYqsWr6z9+13SZ2JYSj19unodGqcYw38Ho1aob5FLhz9GSGbE4UXV4b1B1WKqpOpZYqoW1Fi8vL3z66aeVti9cuBC3b9/GK6+8Al9f38YPRo3OU+2B2SFPIKUgFVuS47AuaTMS0r7HCL8h6NIyjAvIEBERkcUTVqo1Gg0GDx5cafuKFSsgk8mq3EfWzc/RB/PCZ+P8rSRsS96BFefXYHfqfi4gQ0RERBaPv18niyKRSNDROQjtWwTi5I0z2J6yiwvIEBERkcWzuFK9cuVK0RHIAkglUnRuGYYw12AcyjyKuCt7uIAMERERWSyLK9VEvyeTytDbswe6uXfGgYwfsSt1H945uhCd3UIxwm8I3OxcRUckIiIiYqmmpkEpUyDKpz96teqOhLQD2Jv+A07m/IKeHl0xrM1gaFU1e/UiERERUUNgqaYmxU5hi5H+0ejr1QvxqQk4eO0wDmcd5wIyRERULaPRyIfdqUbq86ZplmpqkhxVGkxqOwYDvfviuyu7sCftAA5e/5kLyBARUQUymRx6fSmUSpXoKJpR7zsAACAASURBVNQE6PUlkMsVdfosXwBMTZqLbQtM7zAF/+g2DwFaP2xL2Yn/HHoHBzJ+QpmhTHQ8IiISTK3WIj8/B6WlJfUahSTrZTQaUV5ehuLiIuTn34S9fd2mlApbUdHcuKKieJawKlpKwVVsSd6By/lX4GzTggvIWBBLuD/IMvHeoOqY6964c6cYOl0+yss52GItpFIpDAbzragolcqgUCihVmuhUFT/226LXKbc3FiqxbOU/zEajUbTAjLpuutoZe/OBWQsgKXcH2R5eG9QdXhvUHVE3RsWuUw5UUPhAjJERETU2FiqyWpxARkiIiJqLCzVZPUevIDMULjZuYiOSERERE0cSzU1G1xAhoiIiBoKSzU1O1xAhoiIiMyNpZqaLS4gQ0RERObCUk3N3v0FZAa37odtKTuxLWUn9mccxDDfwejVqhvkUv5nQkRERA/GtkD0K0+1B2aHzDAtILMuaTMS0r7nAjJERET0UGwJRH/g5+iLeeGz8VzoTNjKbbDi/Br898hC/HLzPJe4JSIioipxpJqoCn9cQGZbSjwXkCEiIqJqsVQTPQAXkCEiIqKaYKkmqgEuIENEREQPwlJNVAu/X0BmT9oB7OMCMkRERASWaqI6sVPYYpR/NPp59cLOqwn48fphHM46gf5eveBs2wLxV/ciryQfTiotRvlHo5t7hOjIRERE1IBYqonqwVGlweSgMRjUug+2p+zG7rT9FfbnleRjdeJGAGCxJiIismJ8pR6RGbjYOuOJjlPgoNRU2qc36LE1eaeAVERERNRYWKqJzKiwtKjK7Xkl+Y2chIiIiBoTSzWRGTmptLXaTkRERNaBpZrIjEb5R0MhVVTYJpVIMco/WlAiIiIiagx8UJHIjO4/jLg1eSfySvKhkqlQUl4CV1tnwcmIiIioIbFUE5lZN/cIU7m+W3YXbxxegG8vxuJvXV6ATCoTnI6IiIgaAqd/EDUgG7kNJgaOwjVdJvZn/Cg6DhERETUQlmqiBhbq2gmdnNth+5VdyLvLt4AQERFZI5ZqogYmkUgwse0YGI1GrL+0VXQcIiIiagAs1USNwMW2BWJ8B+N0zln8cvO86DhERERkZizVRI1kUOu+8LBvibUXN6OkvFR0HCIiIjIjlmqiRiKTyjAlaBzySvKx48oe0XGIiIjIjFiqiRpRgLYNIj26IiH9e1zTZYqOQ0RERGbCUk3UyMb4x8BWboM1FzfBYDSIjkNERERmwFJN1MjUSnuMDRiBlIKrOJR5VHQcIiIiMgOWaiIBerh3RoC2DTZfjkNRqU50HCIiIqonlmoiASQSCaYEjUNJeSk2Xf5OdBwiIiKqJ5ZqIkE87FticOt+OJx1HEl5yaLjEBERUT2wVBMJFO07EM42LbDmYiz0hjLRcYiIiKiOWKqJBFLKlJjUdjSyb+cgIe2A6DhERERURyzVRIJ1cmmPcNdg7LyagJzbuaLjEBERUR2wVBNZgAltR0EmkWFt0iYYjUbRcYiIiKiWWKqJLIBW5YgRfkNx4VYSTtw4IzoOERER1RJLNZGF6OsZCW+NJzZe2oo7ZXdExyEiIqJaYKkmshAyqQxTg8ahsFSHbSnxouMQERFRLbBUE1kQHwdv9PWKxPcZh5BamC46DhEREdUQSzWRhRnpNxQapRrfXoyFwWgQHYeIiIhqgKWayMLYym0xIXAk0ouu4fuMQ6LjEBERUQ2wVBNZoAi3ULRv0RbbUnYiv6RAdBwiIiJ6CJZqIgskkUgwue1YlBnLseHSNtFxiIiI6CFYqokslKudM6J9BuHkjTM4l5soOg4RERE9gLBS/csvv2DOnDkYMGAAQkJC0KtXL8ycORMnTpwQFYnI4gz26YeWdq5Ye3EzSsv1ouMQERFRNYSV6vT0dJSXl2PixIn497//jZkzZ+LWrVt47LHH8OOPP4qKRWRRFFI5pgSNQ+7dW9h5NUF0HCIiIqqGXNSFY2JiEBMTU2Hb1KlTMXjwYHz99dfo1auXoGRElqWtkz+6u3fGnrQD6OoeDg/7lqIjERER0R9Y1JxqW1tbtGjRAoWFhaKjEFmUsQHDoZIpseZiLIxGo+g4RERE9AfCS7VOp8OtW7eQkpKCDz74AElJSYiMjBQdi8iiaJRqjPGPweX8K/g567joOERERPQHwqZ/3PfKK68gPj4eAKBQKDBlyhTMnj1bcCoiyxPZqit+zjqGTZe3I9ilPdQKe9GRiIiI6FcSo+DfJV+8eBE3b95EVlYWtmzZAk9PT/zrX/+CvT0LA9EfpeVfw193vY3+vj0wu9s00XGIiIjoV8JL9e/p9XqMHz8evr6++Pjjj2v12dxcHQwGi/lWmiVXVw1ycopEx7B6my5/hz1pB/CniGcRoG0jOk6N8f6g6vDeoOrw3qDqiLo3pFIJnJ3VVe9r5CwPpFAoMGjQIOzatQt3794VHYfIIsW0iYKTSos1F2NRZigTHYeIiIhgYaUaAO7evQuj0Yji4mLRUYgskkqmxOSgMcgszsbe9B9ExyEiIiIILNW3bt2qtE2n0yE+Ph4eHh5wdnYWkIqoaQh26YBQl46Iu7IHuXcq/7dEREREjUvY2z/mzZsHlUqF8PBwuLq6IjMzE7GxscjKysIHH3wgKhZRkzGx7Wi8fng+1iVtxuyQGZBIJKIjERERNVvCSvWoUaOwZcsWrFy5EoWFhdBoNAgLC8N7772Hbt26iYpF1GQ42Wgxos0QxF7ejtM5ZxHmFiw6EhERUbMlrFRPmDABEyZMEHV5IqvQ36sXDmcdx/pLW9GuRSBs5DaiIxERETVLFvegIhHVnEwqw9SgcSgoKcR3V3aLjkNERNRssVQTNXFtHH3Qq1U37Es/iPSia6LjEBERNUss1URWYLT/MKgV9vg2MRYGo0F0HCIiomaHpZrICtgp7DAucARSi9Jx8Nph0XGIiIiaHZZqIivRtWU4gpwCsDVlBwpKuKwvERFRY2KpJrISEokEk4PGQl+uR+zlbaLjEBERNSss1URWpKWdK4b4DMCx7FO4cCtJdBwiIqJmg6WayMoM8RkAV1tnrL24Cfpyveg4REREzQJLNZGVUcgUmBI0Djl3chGfuk90HCIiomaBpZrICrVrEYguLcOwO3UfsotviI5DRERk9ViqiazUuICRUMgUWJO0GUajUXQcIiIiq8ZSTWSlHFUajPIbhqS8yziafVJ0HCIiIqvGUk1kxXp7doePgzdiL23Hbf1t0XGIiIisFks1kRWTSqSYGjQeOn0xtiTvEB2HiIjIarFUE1k5b00rDPDujYPXDyOlIFV0HCIiIqvEUk3UDAxvEwWtyhFrLsai3FAuOg4REZHVYakmagZs5DaY2HY0rukysS/joOg4REREVoelmqiZCHXpiE7O7fHdld24dTdPdBwiIiKrwlJN1ExIJBJMajsaRqMRG5K2io5DRERkVcxSqsvKyhAfH49169YhJyfHHKckogbgbNsCMW0G4/TNcziTc050HCIiIqshr+0H3nvvPRw+fBgbN24EABiNRsyYMQPHjh2D0WiEVqvFunXr0Lp1a7OHJaL6G+TdF0eyTmBd0ha0dQqAjVwlOhIREVGTV+uR6h9++AFdunQxfb13714cPXoUM2fOxIIFCwAAX3zxhfkSEpFZyaQyTAkah7ySfOy4ukd0HCIiIqtQ65HqrKws+Pj4mL7et28fvLy88PLLLwMALl26hG3btpkvIRGZXYC2DXp6dMXe9B/QzT0CnmoP0ZGIiIiatFqPVOv1esjlv3Xxw4cPo2fPnqavvb29Oa+aqAkYHRADO7ktvk2MhcFoEB2HiIioSat1qXZ3d8fJkycB3BuVTk9PR9euXU37c3NzYWdnZ76ERNQg1Ap7jA0YjiuFqTh0/ajoOERERE1arad/DB8+HJ999hlu3bqFS5cuQa1Wo1+/fqb9Fy5c4EOKRE1Ed/fO+DnzGDYnxyHEtSM0SrXoSERERE1SrUeqZ82ahbFjx+LUqVOQSCR499134eDgAAAoKirC3r17ERkZafagRGR+EokEU4LGoqS8FLGXt4uOQ0RE1GTVeqRaqVTi7bffrnKfvb09Dh48CBsbm3oHI6LG4W7fElGt+2Fn6l5EenRBW6cA0ZGIiIiaHLOuqFhWVgaNRgOFQmHO0xJRAxvqOwguNi2w5uIm6A1louMQERE1ObUu1QcOHMCiRYsqbFu1ahUiIiIQFhaGP//5z9Dr9WYLSEQNTylTYFLQWGTfzsGe1AOi4xARETU5tS7Vy5YtQ0pKiunr5ORkvP3223Bzc0PPnj0RFxeHVatWmTUkETW8js5BCHcLwc7UBNy4fVN0HCIioial1qU6JSUFnTp1Mn0dFxcHlUqFDRs2YOnSpYiJicHmzZvNGpKIGseEwJGQS2RYl7QZRqNRdBwiIqImo9aluqCgAE5OTqavf/rpJ/To0QNq9b1XcXXr1g0ZGRnmS0hEjUarcsRIv2hcuJWEEzdOi45DRETUZNS6VDs5OeH69esAAJ1Oh19++QVdunQx7S8rK0N5ebn5EhJRo+rrFYnWGk9suLQNd8ruiI5DRETUJNS6VIeFhWHNmjXYuXMn3n77bZSXl6Nv376m/ampqXBzczNrSCJqPFKJFFOCxqGoVIetyfGi4xARETUJtS7VL7zwAgwGA+bNm4fY2FiMGTMGAQH33mtrNBqxZ88eREREmD0oETUeHwdv9PXqiR+uHUJqYbroOERERBav1ou/BAQEIC4uDidOnIBGo0HXrl1N+woLCzF9+nR0797drCGJqPGN9BuCUzfO4NvEjfhLl+chk8pERyIiIrJYdVr8RavVYuDAgRUKNQA4Ojpi+vTpaNeunVnCEZE4tnJbjA8chXTddXx/7ZDoOERERBat1iPV96WlpSEhIQHp6fd+Nezt7Y1BgwahdevWZgtHRGJFuIXg58xj2JayE+FuwdCqHEVHIiIiskh1KtULFy7EkiVLKr3l4/3338esWbPw4osvmiUcEYklkUgwqe0YvHVkATYkbcVTwdNERyIiIrJItS7VGzZswOeff47w8HA89dRTCAwMBABcunQJy5Ytw+effw5vb2+MGzfO7GGJqPG52jkj2ncQtqXE4+zNC+jk0l50JCIiIotT61K9evVqhIaGYuXKlZDLf/t469at0a9fPzz66KP45ptvWKqJrMig1v1wJOsk1iVtRlsnfyhlStGRiIiILEqtH1RMTk5GTExMhUJ9n1wuR0xMDJKTk80Sjogsg0Iqx9Sgsci9m4cdVxNExyEiIrI4tS7VCoUCt2/frnZ/cXExFApFvUIRkeUJdPJHd/fO2JN2ANd1WaLjEBERWZRal+rg4GCsXbsWN2/erLQvNzcX69atQ2hoqFnCEZFlGRswHDYyFdZc3ASD0SA6DhERkcWo9Zzq5557Dk888QRiYmIwfvx402qKly9fRmxsLIqLizF//nyzByUi8TRKNcYExGB14kYczjyOyFZdH/4hIiKiZqDWpbpr165YtGgR3njjDSxfvrzCvlatWuHdd99Fly5dzBaQiCxLpEdX/Jx5HJuSv0OwSweolfaiIxEREQlXp/dUDxw4EP3798fZs2eRkZEB4N7iLx07dsS6desQExODuLg4swYlIssglUgxJWgs3jn6ETYnx+Gx9hNFRyIiIhKuzisqSqVShISEICQkpML2vLw8XLlypd7BiMhyeao9MMi7L3an7UcPjy4I0LYRHYmIiEioWj+oSEQEAMPaDEYLGyd8ezEWZYYy0XGIiIiEYqkmojpRyZSY1HY0soqzsTftB9FxiIiIhGKpJqI6C3bpgFDXToi7ugc379wSHYeIiEgYlmoiqpeJgaMglUiwLmkzjEaj6DhERERC1OhBxT++Ou9BTpw4UecwRNT0ONloMaLNEGy8vB2ncs4i3C1YdCQiIqJGV6NS/e6779bqpBKJ5KHHnDlzBps2bcLhw4dx/fp1aLVahIeHY968efDx8anV9YhIrH5evfBz1nGsT9qC9i0CYSO3ER2JiIioUdWoVH/99ddmv/DSpUtx4sQJREdHIygoCDk5OVi1ahXGjBmDDRs2wN/f3+zXJKKGIZPKMDVoPBYc/xTbU3ZhQttRoiMRERE1qhqV6m7dupn9wk888QTmz58PpVJp2hYTE4ORI0diyZIleOedd8x+TSJqOG0cW6OXZ3fsz/gR3Twi0FrjJToSERFRoxH2oGJERESFQg0Avr6+CAwMRHJysqBURFQfo/2GQa2wx5rETTAYDaLjEBERNRqLevuH0WjEzZs34eTkJDoKEdWBncIW4wNHIrUoHQev/Sw6DhERUaOxqFK9detWZGdnY9iwYaKjEFEddWkZhnZOgdiSvBMFJYWi4xARETUKidFCXiybnJyMSZMmISgoCN988w2kUovq+0RUC5lFN/DyzjfQ1SsM8yJnio5DRETU4Gr0oGJDy8nJwaxZs+Do6IiPPvqoToU6N1cHg8Eifj5otlxdNcjJKRIdgyyAHLaI8hmAuCu7EeEUhvbObXl/ULV4b1B1eG9QdUTdG1KpBM7O6ir3CS/VRUVFePrpp1FUVIRvv/0Wrq6uoiMRkRkMad0fx7JO4qvz30IhVSC/JB9alRaj/KPRzT1CdDwiIiKzEjrHoqSkBLNnz8bVq1fxv//9D35+fiLjEJEZKWQKhLkGQ6cvRl5JPowA8krysTpxI45kceVVIiKyLsJKdXl5OebNm4dTp07ho48+QlhYmKgoRNRAjmafrLRNb9Bja/JOAWmIiIgajrDpH++88w727t2LAQMGID8/H1u2bDHts7e3x+DBg0VFIyIzySvJr9V2IiKipkpYqU5MTAQA7Nu3D/v27auwz9PTk6WayAo4qbRVFmgnlVZAGiIiooYjrFSvXLlS1KWJqJGM8o/G6sSN0Bv0pm0SSDDMlz80ExGRdeHLoImowXRzj8Aj7cbDSaWFBIBaYQ8jjDiZcwZlhjLR8YiIiMxG+Cv1iMi6dXOPQDf3CNM7RX+6fhSrEtdj5YV1mN5hCqQS/mxPRERNH0s1ETWqnq26oqi0CFtTdkKjVGN8wEhIJBLRsYiIiOqFpZqIGt0QnwEoLC3CvvSDcFQ6IMqnv+hIRERE9cJSTUSNTiKRYHzgSBSV6rA5OQ5qpRqRHl1ExyIiIqozlmoiEkIqkWJah8ko1t/G6sQN0Cjs0cmlvehYREREdcInhIhIGIVUjqeDp8FL7YGlZ79BSkGq6EhERER1wlJNRELZyG3wXOhMaFUOWHz6S2QWZ4uOREREVGss1UQknEapxtywpyCTyvDJqaXIu8tlzImIqGlhqSYii+Bi64w5oU/hbtldfHJ6GYr1t0VHIiIiqjGWaiKyGN6aVpgVMh03b9/E52eWo7S8VHQkIiKiGmGpJiKL0tYpANM7TsWVgjQsO7sK5YZy0ZGIiIgeiqWaiCxOhFsIJrUdg7O5F7D64kYYjUbRkYiIiB6I76kmIovU1ysShaVF2HF1DxyUGoz2HyY6EhERUbVYqonIYg1vE4Wi0iLsSt0HjVKNgd59REciIiKqEks1EVksiUSCyUFjodMXY+OlbXBQqNHFPVx0LCIioko4p5qILJpUIsUTHaYiQNsGX19Yhwu5SaIjERERVcJSTUQWTyFTYFbwE3C3d8MXZ79GamG66EhEREQVsFQTUZNgp7DFc6FPQqOwx2env0T27RzRkYiIiExYqomoydCqHDEn7CkAwKenlqKgpFBwIiIiontYqomoSWlp54rnQp9Ekb4Yn55ehjtld0RHIiIiYqkmoqbHx8Ebz3R6HJnF2fjfmRXQl+tFRyIiomaOpZqImqT2zm3xePvJuJSfgq/OfwuD0SA6EhERNWMs1UTUZHV1D8f4wJE4lXMWay9u4nLmREQkDBd/IaImbaB3HxSWFGF32n44qBwwvE2U6EhERNQMsVQTUZM32n8YCkuLEHdlNxyUavTxjBQdiYiImhmWaiJq8iQSCR5tNwHF+mKsvbgZaoUa4W7BomMREVEzwjnVRGQVZFIZZnZ6DL4OrfHVudVIyksWHYmIiJoRlmoishpKmRLPhs6Ai60z/ndmBdKLrouOREREzQRLNRFZFXuFHeaGPQUbuQqfnV6Gm3dyRUciIqJmgKWaiKyOk40Wc8OeQpmhDJ+cWoqiUp3oSEREZOVYqonIKnnYt8SzoU8iv6QQn51ehrtld0VHIiIiK8ZSTURWy8/RBzM7PYoMXSaW/LISZYYy0ZGIiMhKsVQTkVULdumAR9pNQGLeJXx9fi2XMyciogbB91QTkdWL9OiCotIibEneAY1SjQmBoyCRSETHIiIiK8JSTUTNQlTr/igsLcK+9INwVDpgiO8A0ZGIiMiKsFQTUbMgkUgwLmAEikp12JJyb8Q6slVX0bGIiMhKsFQTUbMhlUgxrf0k6EqLsfriRqiV9gh26SA6FhERWQE+qEhEzYpcKsfTwdPgpW6FZWe/QUrBVdGRiIjICrBUE1GzYyO3wXOhT8JJpcXi08txXZclOhIRETVxLNVE1CxplGrMDXsKCqkcn55ehlt380RHIiKiJoylmoiaLWfbFpgT9hTulpXgk1PLoNMXi45ERERNFEs1ETVrnmoPzA6Zjty7t7D49HKUlJeKjkRERE0QSzURNXuBTv6Y0WEqUgvTsezsNyg3lIuORERETQxLNRERgDC3YEwOGotzuYlYlbgBRqNRdCQiImpC+J5qIqJf9fHsgaLSInx3ZTcclBqMCYgRHYmIiJoIlmoiot8Z5jsYhaU67E7bD41SjUGt+4qORERETQBLNRHR70gkEkxqOxpFpTrEXt4OjVKNbu4RomMREZGF45xqIqI/kEqkeKLDFARq/bDywjqcz70oOhIREVk4lmoioiooZArMCpkOD/uWWHJ2Ja4WpomOREREFoylmoioGrZyW8wJnQmNQo3Fp5cju/iG6EhERGShWKqJiB7AUeWAuWEzAQCfnF6G/JICwYmIiMgSsVQTET2Em50r5oTORLG+GJ+eWobb+juiIxERkYURWqpv3LiB+fPnY9q0aQgPD0dQUBAOHz4sMhIRUZVaO3jhmeDpyL6dg8/PfIXScr3oSEREZEGEluorV65gyZIlyM7ORlBQkMgoREQP1a5FIKZ3mIyUgqv46txqLmdOREQmQkt1x44d8fPPP2PXrl146qmnREYhIqqRzi3DMCFwFE7fPIe1SZu4nDkREQEQvPiLWq0WeXkiojrp790LhaVFiE/dCwelBiP8htboc4fOZSH2QDJyC0vg7KDCuH7+iOzo3sBpiYioMXBFRSKiOhjpNxSFpUXYcTUBGqUG/bx6PvD4Q+eysGJHIkrLDACA3MISrNiRCAAs1kREVoBv/yAiqgOJRIKpQeMQ7NIe65O24MSNMw88PvZAsqlQ31daZkDsgeSGjElERI3EakaqnZ05lcQSuLpqREcgC2aN98dfnWfjzQMfY8X5NfB0cUanlu2qPC63sKTa7QfPZaNDmxbw89RCIW+eYx3WeG+QefDeoOpY2r1hNaU6N1cHg4EPDInk6qpBTk6R6Bhkoaz5/pjZfho+PLEY7/3wOeZFzIa3xtO0r/B2Kbb/dLXaz0olEny57RwAQCGXws/DAQFejgj00iLA0wF2NoqGji+cNd8bVD+8N6g6ou4NqVRS7UCu1ZRqIiJR7BV2mBM6EwuOf4ZPTy/DnyPmQCN3xK4j6dh5JA2legOCvLVIySyE/ndTQJRyKaYPa4cOPk64lFGASxkFuHwtHzt+TsN3xlRIAHi62iPAS4tAL0cEejrC2dEGEolE3DdLRERVYqkmIjIDJxst5obNxILji/H+kc9Rcq47ioqk6BzkinF9/eDhbP/At390aeeGLu3cAAAlpeVIySzEpYx8XM4owM/nsrD/5LV719GoEODpeK9ke2nh5WYPmbR5ThkhIrIkLNVERGZgMBpx9aoRxpQuKPY8CFXAUbzcYSY6eLuZjons6F6jN32olDK093FCex+ne+c2GJGRo/t1NDsflzIKcDTxhulY/1YOCPx1NNuvlQNslPynnYiosQn/l/ezzz4DACQn33sCfsuWLTh+/DgcHBzw2GOPiYxGRPRQRqMRZ6/cwsb9yUi7oYO3mxv6e4xDfE4s9tzcjEDPJ6GQ1u+fWqlUgtYtNWjdUoNBnb0AALkFd3Hp2r2CfTmjAFsPXoER9+Zoe7dUI9DT0TQ320mjMsN3SkREDyIxCl4OrLrlyT09PbF3794an4cPKorHB0roQazx/ki+XoCN+5ORmJYPV60NxvbxQ7cOLSGVSHA48zi+vrAWEW4hmNHxEUglDTtF4/bdMqRcL0BSRgEuZ+Qj5Xqh6RV+Lo42CPRyNM3NbuViD6kFzcu2xnuDzIP3BlWHDypW4eLFi6IjEBHVSmZuMWIPpOB4Ug4c7BR4NKot+oW1glz2W3Hu7tEZhaVF2JwcB41SjYmBoxv0AUM7Gzk6+Tmjk58zAKCs3ID0GzpcSs/HpWsFOHc1D4fOZd87ViX/dRTbEQGejmjj4QClQtZg2YiImgPhpZqIqKnIKyrBloMpOHgmCwqFFGN6t8GQbt7VzmGO8umPolIdEtK/h4NSg2jfQY2WVS6Too2HA9p4OGAI7k1TuZF/B5d/Ny/7THIuAEAmlcDXXXPvNX5e96aNONgpGy0rEZE1YKkmInqI4rt6xP2cij3HMmAwGDGwsydG9PStUfEcExCDwlIdtqXEQ6NUo1er7o2QuDKJRIKWTnZo6WSHXsEeAADdHf1vJftaAfYcv/cKQABo2cLO9Bq/QG8tWjrZ8lV+REQPwFJNRFSNUn05Eo5n4LtDqbhTUoYeHd0xtk8buGhta3wOqUSKae0nolhfjNWJG7E1eSd0+mI4qbQY5R+Nbu4RDfgdPJjaVoGwQBeEBboAAPRl5biaVWR6+PFkUg4OnskEAGjsFL++yu/evGwfd02F6S5ERM0dSzUR0R+UGww4eCYThLh3MQAAIABJREFUWw5eQb6uFCH+zhjfzx/eblU/nPIwMqkMYa7BuHArCTr9/7d339FRnPf6wJ+Z3dWq9wYSAknIAkQR2FTTTLNMN8bBpjhxMI4NjltsHyfEv3uccu0Tw40TXA7lj4sTl1xjqggY04swhF5lQEICSaj3tm3m98cW7Uq7FJWdlfR8zvHZ3XdmZ7+SR8szM++8bx0AoEJXia8yvwMARYO1PY1aZQnNwQDMwwQWltXbxsu+nleFs9dLLeuau5ckWfpmJ8YEwa8bzP5IROQKQzURkYUsyzhzrQTfHcpGYXk9EmMC8dKcgXioV3Cbt70rZy9kOI5QZJAM+PLqJlyryEKYdyjCfEJsj4FeAR0+Ysi9iIKAnuF+6Bnuhwmp5qnXq2p1TmZ/NP9cMRF+5u4ilr7Z4Zz9kYi6EYZqIiIAmbkV2HQoC9kF1egZ7odfzxuE1KTwdguFFbpKp+1G2YjLZZmo1jsODaUW1Qj1DjaHbO+msB3mE4ow71D4a/wUCaxB/tq7z/54pQgHzxUAAIL9vWzD+D3kZPZH6wyT5dU6hDabYZKIqLNhqCaibu1WUQ02HcrCpexyhARo8fz0fnh0YA+IYvsG1hBtsNNgHaINxp8e/R30JgPKGytQ1liOsgbLY2MFyhrKcasmD3WGeof3eam8LGHbHLRDvUMQ7h1qCd0h8NX4tmv9rtxt9scb+eabIE9ZZ3/UqJDQ09xlxGiS8MOpPBgsY2mXVeuwcVcmADBYE1GnpPjkL+2Fk78oj4P009142v5RXNmArYez8eOVIvh5qzFjdB9MGhbTYeM1nyw8g68yv4NBMtjaNKIGC/s9dV99qhuNjShrrEB5YwVKG8pR1liO8oYKlFpCeKOp0WF9H7W3Q9AO9Q5BuOUxzDsU3mr3zbJonf3R2i87r7gWrr6tvb1UeGxYDLRqFbw0KnhpRHipmz1qVPBSOz5qNSLUKpHdTboYT/veIM/hiZO/MFRTu+GXH92Np+wfVXV6pB/LwcFz+VCJAqYO74UnRsbB1w032Z0sPIPtWbtRoats99E/6g31KLUL2uWWs9yljRUobyiH3i7MA4CfxtfSpaRZ9xJvc/D2UnXc76O+0YhXPj7scrlaJcBoevDvcwGAxhK+tbbwrYJGI0JrDeEaFTRq0RLaRcfgrrZ7bQ3slvW0du/VqMV2n5HS2hWmrFqHMHaFYdcguidPDNXs/kFE3UKDzojvT97C9ydvw2CUMH5ID8x6NB4hAe47YzsieliHjfThq/FFnMYXcQGxLZbJsoxaQ52la4lj95L82gJcLLkMo2xyeE+gV0CLmyfN/btDEeodDJXY+jP6vt5qhAVqUVata7EsLFCLj5Y/CkmSoTeaoDdI0BtM0BklGOxfGyTojSYYjBJ0BhP0Bssyowl6o9T02mB+3WgwobreYHttfbR2P3lQ9gFco1bZhfb7O7PupTEHe41GxPXbldh94jYMpqauMP+7KxMNOiNG9I+CIJhvGhUFAaJoHnNcFAWPmmq+PR2/XIiNuzKhZ9cgGx50dQ48U03txlPORJJnUmr/MBglHDybjx0ZOahtMOCRfpGYNz4B0aHu6XPcGUiyhGp9TVPYtj2ag3eFrhKS3BQ+BQgI1gbZBe2QpjPePqEI1gbdc+SS45cL8cWP+4CeP0HwaoSs9wYKkvHcqMluDQuSLMNgkKAzmmCwhnKDOagbjNZA3xTQbSHePrgb7/FoWb8j2AK32BS6RUEwB28BEKztdstEsWm5KAhN61gDu3WZrV2wbNN+fbvl1mX2rx0+y/6gwPG9LeoUBWw+lIW6RmOLn9XfR4PnHk922Kbg7Gd28rktaheab8P5e5t/jvX3407NDzIA80Hdz5/o1y2DtdJXMdj9gzqU0ju4p+EZBefcHaolScaPVwqx9chNlFY1on/vEMyfmIj4HoFuq6GrMEkmVOqqHYK2ffiu0lU7DBcoCiJCtcEOQdvapzvMOxQBXv44VXQO/7yyCSY0hScV1Fg8YL7HjNvdnmRZNod0a1C3hXYJ//3P0y7ft3BKEmTZHP4lWYYkyZBkQJZkW5ssw9IuQ5Ka1pUt6zY9t7yWmrZlv23b+pLddm2fad62LDt/r2T3Xts69nVa6uoqXIVt56G+abnrUG+3juB4QHL9dpXtKoY9L7WI1KRwJwcUjtty2G7zAxL7WiwHW82XNz/wcX7AIUBA0/Ydfh+iABHODliabav5wV7z7QvA6Wsl+L/9NxyuMLn7AIPdP6jDOLtMZ71s+UhypMLVud+pn4rxL7s/eF62dD9ZlnEhqwzfHcpCXkkdekcF4Odp/ZASH6p0aZ2WSlRZhvMLAUISWyw3SEZUNFY2u3nS3K/7YtlV1OhrHdZXi2pIsgQJjkHBBCP+79o21BnqoRbVUAsqqESV3XM1NKIKKkENtaVdJaigFlWWR7XluflR6XG+7QmCYOvTDR/H/uphgVpUqm9C3eua7ay98fZDCDbGY8ojvRSquGO0COS2EN4U5v/wv6dQWduya1CQnxfeXJBqF+ybQr7sEOjhJNjbt9mvDydtjuvfu73lz3X3z7c8d1i/5e/DaJLMV1KcBGoA0Bsl5BbV2g5cHD/b8TNkOPl9WR47O71RwuZDWR7xbyxDNbXJ5kNZLS5rGowS/rnnGv6555pCVXkWvVHCN3uvY0DvEAT5u6//bnd0I78Kmw7cwLW8KkSG+OClOSl4pF9kl+176ik0ohqRvuGI9A13ulxv0ttGLSlvNIfufbec36jYYGzApuvb26UuURCbwrY1oFtem59bQrhleVN78zCvgkZw/p7m69kfAKgt6zu+z64GQQVBEDB0hB5HKy5BUJm/SwVtIzTxlzA0JKZdfg+eRBQEiKq7/z0+/Vii0+4OP5vUt9WzmnZmb392zOX9Bx+8OKpN25Zl8zUmW/h2Errtr2I0PzBwdsDhePXDSdCX7T7LSdB3dsBi3e4X3//k9Odw9vtRAkM1tdpPtyruuiMvnvaQG6vxDK4OJGoaDHjjk2MID/JGQs9AJPY0T+scF+UPtcpzzqZ1Vvmlddh8KAtnr5ci0M8LS6Y9hHFDevJ36yG8VF6I9otCtF+Ure1M0QUX43YH4d0Rr8MoGWGSTDDKJvOjZLQ8N8IomWCUjc3azes2ve9+1zM/10k623tMDuta2mSTQ7/y9qISVDDJJgjN7vsUVBJ+rNmD/FOXoRJU0DQL/CrBcta+2QFDi2DvLPhbg75D6Hd2IGBe391n/EenRONmw1VklB2CpG6AaPTBmLCJHnEmUgnzJjg/yJg3oeVVowclCJZuG/c40PEUO4/nuDzA8AQM1fTAsgqqsPVwNi7nVEAQ4PTyUVigFpOGtRyFoKvb9WOu0z/4QD8vTB8ZhxsF1biRX4WTV82TYahVInpH+yOxZxASegaib0wQQgK0HGv3PpVXN2LrkZs4dukOvL1UeHJ8AqY90gtar44Za5raz+zENKfjds9OfAL+Gj8FK3NNkiVLwLYEdskIk2xy+tx2AOAkwDd/z57cA04/zySb4KP2hlEyQi/pYTSaLO9tCvpN2zO3yS5HAG89V2f8XYXw5mfo7xbgW2xXVCO7MhcnajIga0wQAMiaBpyo/QGhN2UMjhgAlSBCFFRQiaKtNnOb+bloed5Vvkd5kNGkIw8w2gNvVKT7lltYg61HsnE+qwz+PhrMGN0bvt5qfLnnGu9Ktrjfu7QranTILqhCVn41sgqqkFNYY+uHHezvZQ7ZMeYz2n2iAzpsQhJ3as8bFWsbDNh5PAf7TucDkDFpWCxmjO6NAF+vdtk+uYd13O5KXSWC23nc7s7k98f++66zbT6IuwV/ZyHctkwywiA7nqV3esa/xZUD+6sBzddz/l5Ts+EbO4o5ZDuG7aZH0XYW3jGY2wV00W7dZu8XRedh3tYmOgZ8a7t5mcquNrt2FwcKl0ozsT17FwxS0029GlGDBQ/NxYjoYV3qAOJ+fHXqADLKDjocYCx85DG3fT5H/6A2yS+tw7Yj2Tj1Uwl8tWqkjYzDlEdi4e1lvtDB0T8ctWb0D6NJQl5JrS1kZ+dXo7iyAQCgEgXERvojsWcgEmOCkNgzEBHBPp3uS7Q9QrXOYMLeU7fx7x9voVFvxJiB0Zg7NgFhQd7tVCUpobsPx9nW2TY7G1mWm4K9LaQ3HQj8+eT/uHzv0oGLIUkmmGTJ8p+5W45kfS45tjc9Ni2Xmi03Wd8vNa0ryaaW25fs1nWy/Y7oHnS/rOHd/kCi+Zl7VbN1BIc2VYvl996Gyu5zhbts4z63bTmgENF8XZVt+fmSy9hyY6eifysM1dQqReX12HbsJk5cLoLWS4Vpw3th2vBeLmee6+7/MLa36no9sq0hu6Aa2XeqodObz/D4+2iQ2DMQCTFB6NszEH16BMJH69m9udqyfxhNEo5euINtx26iqlaP1L7heGpCAmIiut9NS10Rvzs6drbNzqY9z9y7k/mGu+ah2+65ZB/Wm55L1udS85BuXr7xyjcuP3Nm/OOQmgV7+/c7b2/+2c6W32sbnnEwYeXOfYND6tEDKa1qwI5jOTh2sRBqlYC0kXFIGxnHS+tuFujrhdSkcKQmmUdUkCQZBaV1uGE5k51VUIXzWWUAzNMzx0T4IaFnEBIt3Uaiw3w7/agXsizj1E8l2HwoC0UVDUiKDcLyuQORFBusdGlE7aojZ9vsbFz3t09TsKp7EwTB3G0DKmjg/ORTa1gPtpoL0QbjifjJ7fY5rWUeQUR2EdJNLgK7/RUA1+vLzd731U/fOa3B2e9HCQzVZFNRo8PO4zk4dK4AggBMejgGM0b15jBwHkK0dAOJjfTHxFTzUFv1jQZkF1Qjq8Acsk9lFuPw+QIAgI9WbRlpxNxtJL5HIPx92u+LvqNdySnHpoNZyCmsQUy4H159ajCG9A3rdN1eiOjBWA8u2N/ezNMPMswjiAhuGSVmV84+lwcYnoDdPwjVdXr8+8dcHDibD0mSMW5wD8wc0wehgQ/WT5WXcJUnyTKKyuuRlV9tvhGyoBp5JbW2EVqiQ31tITuhZyBiIvygEt0zXNb97h+5hTXYdPAGLudUICxQi7njEjA6JRqiyDDdVfG7g1zhvmHG7kFmnnD/AftUk1O1DQZ8f/IW9p7Kg95owpiB0Zj1aDwig31atT1++XmmBp0ROYU1DqON1NSbv5C0GhXiewTYuo0k9AxCkF/HdPO51/5RVFGPLYezcfJqMfx9NJg5ujceGxYDjbrzj3xCd8fvDnKF+wY1p/SoQQzV5KBBZ8QP/7mN7/9zC406E4b3j8ScsfHoEda2sWH55dc5yLKMkqpGZOebz2RnF1ThVlEtTJa/n/Agb9soI4kxQegV2T4T1LjaP6pqddh+LAeHzxdApRIwbXgc0kbEwdebvdO6C353kCvcN8gVpfYN3qhIAACd3oR9Z/Kw68dc1DUaMeyhCMwdG4/Ybjjta3cmCAIig30QGeyDUZah/vQGE3KLamzdRq7drsSJK0UAzBPU9IkOsN0AmdAz8IG7BjlT32jE7pO52POf2zCZZIxP7YnZY/qwDz8REXVKDNXdgMFowsGzBdh5PAfV9QYMSgjD3HHxiO8RqHRp5CG8NCokxQY7jKpRXt1ouQnS3G1k3+l8fH/yNgAgJEBrN916IHpH3f8ENQajCfvP5GPn8VzUNhgwon8knhyfgKgQ3w752YiIiNyBoboLM5okHLlwB+kZOaio0aF/7xC8Mi4BfWODlC6NOoHQQG+EBnrjkX6RAMz70+3iWmRZuo1k5Vfh9E8lAMwT1PSK9Ld1G0mICUJEkDcEQXCYHMjcpUNGXaMJKfGhmD8hEb2jAxT8KYmIiNoHQ3UXZJIkHL9UhO3HbqK0qhF9Y4Lwwoz+6N8nVOnSqBNTq0TE9whEfI9ATLG0VdXpkW2ZnCYrvwpHL9zBvtN5AIAAXw1C/LXIL62z9deuazRCADBjVByemthXmR+EiIioAzBUdyGSLOPk1SJsO5qDovJ69I4OwOJpyRiUEMqxfalDBPl5YWhSBIYmRQAwH9Dll9TZQvbxK0UtbiCWAfx4pYihmoiIuhSG6i5AlmWcuVaKrUezkV9Sh5gIP7wybxCGJoUzTJNbqUQRcVEBiIsKwMShMTh2qdDpemXVOjdXRkRE1LEYqjsxWZZxMbscW45kI7ewBlGhvvjV7BQM7x/Z6aenpq4hLFDrNECHBXKEDyIi6loYqjupqznl2HwkG1n51QgP8sbSGf0xKiXKbbPjEd2PeRMSsXFXJvRGydbmpRYxb0KiglURERG1P4bqTuZ6XiW2HM5G5q1KhARo8dzjyRg7uEe7TM5B1N5GW8bBto7+ERqoxbwJibZ2IiKiroKhupPIKazGlsM3cTG7DIF+Xnh2ShImpvbkFM7k8UanRGN0SjRnRiMioi6NodrD5RXXYsuRbJy9Xgo/bzWenpiIScNiofVimCYiIiLyFAzVHupOWR22Hb2J/1wthrdWhbnj4jH1kV7w0fJ/GREREZGnYULzMMWVDdhx9CYyLhfCS63C9NG98fiIOPj7aJQujYiIiIhcYKj2EOXVjdiRkYOjF+5AFAVMG94LT4zqjUBfL6VLIyIiIqJ7YKhWWFWtDjuP5+LguXzIMjAhtSdmjO6DkACO40tERETUWTBUK6SmXo/dJ25h3+k8GE0yxg6OxswxfRAe5KN0aURERET0gBiq3ay+0YDvT97GnlO3odebMColCrPHxiMqxFfp0oiIiIiolRiq3aRRb8TeU3nYfeIW6nVGPNIvEnPGxiMm3E/p0oiIiIiojRiqO5jeYML+M/n494+5qG0wILVvOOaOi0dcVIDSpRERERFRO2Go7iAGo4TD5wuQfjwHVbV6pMSHYu64eCT2DFK6NCIiIiJqZwzV7cxokpBxqRA7jt1EWbUOD8UG4aXZKUiOC1G6NCIiIiLqIAzVrXT8ciE2H8pCWbUOYYFaPDk+AQIEbDt6E8WVDYjvEYhfPNEfA/qEQBAEpcslIiIiog7EUN0Kxy8XYuOuTOiNEgCgrFqHDelXAQBxkf54df5gDEkMY5gmIiIi6iYYqlth86EsW6C25++jwf97fjhEhmkiIiKibkVUuoDOqKxa57S9tsHAQE1ERETUDTFUt0JYoPMpxF21ExEREVHXxlDdCvMmJMJL7fir81KLmDchUaGKiIiIiEhJ7FPdCqNTogHAYfSPeRMSbe1ERERE1L0wVLfS6JRohmgiIiIiAsDuH0REREREbaZoqNbr9fjoo48wduxYDB48GD/72c9w/PhxJUsiIiIiInpgiobqd999Fxs3bsTs2bOxcuVKiKKIZcuW4ezZs0qWRURERET0QBQL1RcuXMDOnTvx1ltv4Z133sGCBQuwceNG9OjRA6tWrVKqLCIiIiKiB6ZYqN69ezc0Gg2efvppW5tWq8X8+fNx+vRpFBcXK1UaEREREdEDUSxUX716FfHx8fDz83NoHzx4MGRZxtWrVxWqjIiIiIjowSgWqktKShAZGdmiPSIiAgB4ppqIiIiIOg3FxqlubGyERqNp0a7Vmqf61ul0D7S9sDD/dqmL2iYiIkDpEsiDcf8gV7hvkCvcN8gVT9s3FAvV3t7eMBgMLdqtYdoaru9XWVktJElul9qodSIiAlBSUqN0GeShuH+QK9w3yBXuG+SKUvuGKAouT+QqFqojIiKcdvEoKSkBAKddQ+5GFIV2qYvahv8f6G64f5Ar3DfIFe4b5IoS+8bdPlOxUN2vXz/84x//QF1dncPNiufPn7ctfxAhIX73Xok6HLvh0N1w/yBXuG+QK9w3yBVP2zcUu1ExLS0NBoMB3377ra1Nr9dj8+bNGDZsGKKiopQqjYiIiIjogSh2pnrIkCFIS0vDqlWrUFJSgri4OGzZsgUFBQX44IMPlCqLiIiIiOiBCbIsK3Z3n06nw8cff4wdO3agqqoKycnJePPNNzFmzBilSiIiIiIiemCKhmoiIiIioq5AsT7VRERERERdBUM1EREREVEbMVQTEREREbURQzURERERURsxVBMRERERtRFDNRERERFRGzFUU6tduHAB77//PqZPn47U1FRMnDgRb7zxBnJzc5UujTzQ+vXrkZycjDlz5ihdCnmICxcu4MUXX8Tw4cMxdOhQzJ49G5s3b1a6LFJYTk4OXn/9dYwfPx6pqamYPn061q1bB71er3Rp5EbFxcVYtWoVlixZgqFDhyI5ORknTpxwuu6+ffvw5JNPYtCgQZg4cSI++eQTGI1GN1es4IyK1Plt2LABZ86cQVpaGpKTk1FSUoIvv/wSc+fOxaZNm5CYmKh0ieQhSkpK8Pnnn8PX11fpUshDHDp0CCtWrMCIESPw2muvQa1WIycnB3fu3FG6NFJQUVERnn76aQQEBGDx4sUICgrCqVOnsHr1aly/fh0fffSR0iWSm9y8eRPr169H7969kZycjLNnzzpdz/pdMmrUKLz33nu4du0aPv30U1RUVOC9995za82c/IVa7cyZMxg4cCC8vLxsbTk5OZg1axZmzJiBDz/8UMHqyJO8++67KCgogCzLqK6uxrZt25QuiRRUU1ODxx9/HNOnT8fvf/97pcshD7Ju3TqsXr0a6enpSEpKsrW/+uqr2LdvH86dOweNRqNgheQutbW1MBgMCAkJwd69e7FixQp88cUXGDlypMN6M2bMgFarxbfffguVSgUA+Otf/4p169Zh165d6NOnj9tqZvcParVhw4Y5BGoA6NOnD5KSkpCVlaVQVeRpLly4gO3bt+O3v/2t0qWQh9ixYweqq6vx2muvATD/48nzOwQAdXV1AICwsDCH9vDwcKjValtooq7P398fISEhd13nxo0buHHjBhYsWOCwbyxcuBCSJGHPnj0dXaYDhmpqV7Iso7S09J5/CNQ9yLKMP/7xj5g7dy769++vdDnkIY4fP46EhAQcOnQIEyZMwMMPP4wRI0Zg1apVMJlMSpdHCho+fDgAYOXKlcjMzMSdO3ewfft2bNmyBcuWLYMoMrZQkytXrgAABg4c6NAeFRWF6Oho23J3YZ9qalfbt29HUVER3njjDaVLIQ+wdetW3LhxA59++qnSpZAHyc3NRWFhId5991288MILGDBgAA4cOID169dDp9Nh5cqVSpdIChk7dixee+01rF27Fvv377e1v/rqq1ixYoWClZEnKikpAQBERES0WBYREYHi4mK31sNQTe0mKysLf/jDH/Dwww9zhAdCbW0tVq9ejRdffBGRkZFKl0MepL6+HlVVVfjNb36DF198EQAwbdo01NfX4+uvv8bLL7+M0NBQhaskpcTGxmLEiBGYOnUqgoODcfDgQaxZswahoaF49tlnlS6PPEhjYyMAtOiKCgBarRYNDQ1urYehmtpFSUkJfvWrXyEoKAh/+9vfeImO8Pnnn0Oj0eD5559XuhTyMN7e3gCAmTNnOrTPmjULu3fvxsWLFzFhwgQlSiOF7dy5E//1X/+F3bt3IyoqCoD5gEuWZfzlL3/B9OnTERQUpHCV5Cms3yXOhlvU6XS25e7C5ENtVlNTg2XLlqGmpgYbNmxwehmGupfi4mJs3LgRCxcuRGlpKfLy8pCXlwedTgeDwYC8vDxUVVUpXSYpxPodER4e7tBufc19o/v66quvkJKSYgvUVpMmTUJ9fT0yMzMVqow8kfW7xNoNxF5JSYnbr5IyVFOb6HQ6vPTSS8jJycHatWuRkJCgdEnkAcrKymAwGLBq1SpMnjzZ9t/58+eRlZWFyZMnY/369UqXSQpJSUkBYB6T2F5hYSEAsOtHN1ZaWur0ZlWDwQAAvJGVHFhvgL906ZJDe1FREQoLC91+gzy7f1CrmUwmvP766zh37hw+++wzpKamKl0SeYjY2FinNyd+/PHHqK+vx+9+9zu3jh1KniUtLQ3r16/Hpk2bbDc1y7KMb7/9Fr6+vvwu6cbi4+Nx7Ngx3Lp1C3Fxcbb2nTt3QqVSITk5WcHqyNMkJSUhISEB//rXvzB//nzbsHpff/01RFHEtGnT3FoPQzW12ocffoj9+/fjscceQ2VlpcOEHn5+fpgyZYqC1ZGSAgICnP7/37hxI1QqFfeNbm7gwIGYO3cu1q5di7KyMgwYMACHDh3C0aNH8fbbb8Pf31/pEkkhS5cuxeHDh/Hss89i0aJFCAoKwsGDB3H48GE888wzLcavpq7ts88+AwDb3Bfbtm3D6dOnERgYiMWLFwMA3nnnHbz88stYunQppk+fjmvXruHLL7/EggULEB8f79Z6OaMitdqSJUtw8uRJp8tiYmIchkMiAsz7DGdUJMB8Y9Fnn32GrVu3orS0FLGxsfjFL36BZ555RunSSGEXLlzAmjVrcPXqVVRWViImJgZPPfUUli5dyslfuhlXVyaaZ4y9e/fik08+QVZWFkJDQ/HUU09h+fLlUKvde+6YoZqIiIiIqI14oyIRERERURsxVBMRERERtRFDNRERERFRGzFUExERERG1EUM1EREREVEbMVQTEREREbURQzURERERURsxVBMRUastWbIEkyZNUroMIiLFcZpyIiIPc+LECTz33HMul6tUKly5csWNFRER0b0wVBMReaiZM2di/PjxLdpFkRcZiYg8DUM1EZGHGjBgAObMmaN0GUREdB94uoOIqJPKy8tDcnIy1qxZg/T0dMyaNQuDBg3CxIkTsWbNGhiNxhbvyczMxIoVKzBy5EgMGjQI06dPx/r162EymVqsW1JSgj/96U+YPHkyBg4ciNGjR+P555/HsWPHWqxbVFSEN998E8OHD8eQIUOwdOlS3Lx5s0N+biIiT8Qz1UREHqqhoQHl5eUt2r28vODv7297vX//fty+fRuLFi1CeHg49u/fj08++QQFBQX44IMPbOtdvHgRS5YsgVqttq174MABrFq1CpmZmVi9erVt3by8PDz77LMoKyvDnDlzMHDgQDQ0NOD8+fPIyMjAo48+alu3vr6JucpsAAADb0lEQVQeixcvxpAhQ/DGG28gLy8PX3zxBZYvX4709HSoVKoO+g0REXkOhmoiIg+1Zs0arFmzpkX7xIkTsXbtWtvrzMxMbNq0CSkpKQCAxYsX45VXXsHmzZuxYMECpKamAgD+/Oc/Q6/X45tvvkG/fv1s677++utIT0/H/PnzMXr0aADA+++/j+LiYmzYsAHjxo1z+HxJkhxeV1RUYOnSpVi2bJmtLTQ0FB999BEyMjJavJ+IqCtiqCYi8lALFixAWlpai/bQ0FCH12PGjLEFagAQBAEvvPAC9u7dix9++AGpqakoKyvD2bNnMXXqVFugtq778ssvY/fu3fjhhx8wevRoVFZW4siRIxg3bpzTQNz8RklRFFuMVjJq1CgAQG5uLkM1EXULDNVERB6qd+/eGDNmzD3XS0xMbNHWt29fAMDt27cBmLtz2LfbS0hIgCiKtnVv3boFWZYxYMCA+6ozMjISWq3WoS04OBgAUFlZeV/bICLq7HijIhERtcnd+kzLsuzGSoiIlMNQTUTUyWVlZbVou3HjBgCgV69eAIDY2FiHdnvZ2dmQJMm2blxcHARBwNWrVzuqZCKiLoehmoiok8vIyMDly5dtr2VZxoYNGwAAU6ZMAQCEhYVh6NChOHDgAK5du+aw7rp16wAAU6dOBWDuujF+/HgcPnwYGRkZLT6PZ5+JiFpin2oiIg915coVbNu2zekya1gGgH79+uHnP/85Fi1ahIiICOzbtw8ZGRmYM2cOhg4daltv5cqVWLJkCRYtWoSFCxciIiICBw4cwNGjRzFz5kzbyB8A8N577+HKlStYtmwZ5s6di5SUFOh0Opw/fx4xMTF4++23O+4HJyLqhBiqiYg8VHp6OtLT050u27Nnj60v86RJkxAfH4+1a9fi5s2bCAsLw/Lly7F8+XKH9wwaNAjffPMN/v73v+Prr79GfX09evXqhbfeegu//OUvHdbt1asXvvvuO3z66ac4fPgwtm3bhsDAQPTr1w8LFizomB+YiKgTE2RexyMi6pTy8vIwefJkvPLKK/j1r3+tdDlERN0a+1QTEREREbURQzURERERURsxVBMRERERtRH7VBMRERERtRHPVBMRERERtRFDNRERERFRGzFUExERERG1EUM1EREREVEbMVQTEREREbURQzURERERURv9f8cQjgT2tm2vAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZUztrDgaoc0r","colab":{}},"source":["# make sure to save the model performance statistics and the associated model configuration. \n","# that is save the df_stats to csv file with a file name, say experiment 1\n","df_stats.to_csv(os.path.join(dir, 'label_experiment_health_augmented_stats.csv'))\n","# save the key hyper-parameters of this training experiment, say experiment 1\n","label_experiment_health_augmented = {\n","    \"epochs\": epochs,\n","    \"train_batch_size\" : train_batch,\n","    \"valid_batch_size\" : valid_batch,\n","    \"initial_learning_rate\": learning_rate,\n","     \"max_sentence_length\": max_length,\n","     \"loss_fucntion\": criterion,\n","     \"optimizer\": optimizer,\n","     # you need to manually type-in the following info\n","     \"BERT output\": \"mean value of [cls] embeddings of non-padded token from the second to the last layer\",\n","     \"activation function\": \"relu\",\n","     \"dropout rate of BERT output\": model_amazon.l2,\n","     \"# of fully connected linear layer\": 1,\n","     \"dataset\": \"Old Amazon Reviews + Augmentation\",\n","     \"comment\": \"Overfitting until epoch 7, when it seems to be more stable.\"\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ep0TRlPiofHE","colab":{}},"source":["# save the experiment configurate assocaited with this experiment\n","# note that if you click the file icon (the third vertical one on the far left)\n","# you will see the save files, double click on them, you can see them.\n","import csv\n","with open(os.path.join(dir, 'label_experiment_health_augmented_config.csv'), 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key, value in label_experiment_health_augmented.items():\n","       writer.writerow([key, value])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PdjjYeVrohFZ"},"source":["## Evaluate the Model Performance"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c81Rv7jGojBA","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1595956402481,"user_tz":420,"elapsed":3268,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"d3142c47-3517-4fd9-c299-bbf30b30713a"},"source":["# apply the trained model to the validation dataset\n","# get the model predictions and compare the comparisons to the true labels\n","model_amazon.eval()\n","predictions, labels = [], []\n","for step, batch in enumerate(valid_loader):\n","  input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n","  attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n","  label = batch['label'].to('cpu').numpy()\n","  \n","  with torch.no_grad():\n","    prediction = model_amazon(input_ids, attention_mask)\n","\n","  prediction = prediction.detach().cpu().numpy()\n","  predictions.append(prediction)\n","  labels.append(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qi2ssunlol1J","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595956404191,"user_tz":420,"elapsed":674,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"c03b6934-73b0-4b84-c2c2-385be6002f75"},"source":["# call the helper function-- pred_accuacy to compute the prediction accuracy in each batch\n","ac = []\n","for i in range(len(predictions)):\n","  ac_i = pred_accuracy(predictions[i], labels[i])\n","  ac.append(ac_i)\n","ac"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.9375, 0.9375, 0.96875, 0.9375, 0.9375, 1.0]"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qR1fZOFNooFp","colab":{"base_uri":"https://localhost:8080/","height":585},"executionInfo":{"status":"ok","timestamp":1595956406790,"user_tz":420,"elapsed":667,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"daed7a17-ec9a-405c-c409-90741ad95363"},"source":["# transfer the outcomes into np\n","predictions = np.asarray(predictions)\n","labels = np.asarray(labels)\n","predictions[0]\n","# note that now the outcomes are still stored in batches"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.44925356],\n","       [0.44925362],\n","       [0.44925356],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925356],\n","       [0.44925362],\n","       [0.44925356],\n","       [0.44925356],\n","       [0.44925362],\n","       [0.44925356],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925356],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925356],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925362],\n","       [0.44925356],\n","       [0.44925356],\n","       [0.44925356],\n","       [0.44925356],\n","       [0.44925356]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m8D0qZpCorU5","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595956409144,"user_tz":420,"elapsed":940,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"d76028d1-fa76-471e-c4ee-d5eed49d7271"},"source":["# convert predictions stored in the batches into a long vector\n","pred = np.concatenate(predictions, axis=0 )\n","pred = np.concatenate(pred, axis=0 )\n","pred = pred.reshape(len(pred),1)\n","print(pred.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(166, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aXrd53oAotUJ","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1595956410251,"user_tz":420,"elapsed":473,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"8819d8ac-7e82-4354-a15b-8626d22be3db"},"source":["# convert the true labels batches into a long vector\n","true_label = np.concatenate(labels, axis=0 )\n","true_label = true_label.reshape(len(true_label), 1)\n","print(true_label.shape)\n","type(true_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(166, 1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"98D4DZ2govNW","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1595956411747,"user_tz":420,"elapsed":808,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"9fa3f3e8-4bcf-418b-f141-f44b410ad990"},"source":["# put the predictions and labels into the same dataset\n","df = np.concatenate([pred, true_label], axis = 1)\n","df = pd.DataFrame(data=df, columns=[\"preds\", \"labels\"])\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>163</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>165</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>166 rows × 2 columns</p>\n","</div>"],"text/plain":["        preds  labels\n","0    0.449254     1.0\n","1    0.449254     0.0\n","2    0.449254     0.0\n","3    0.449254     0.0\n","4    0.449254     0.0\n","..        ...     ...\n","161  0.449254     0.0\n","162  0.449254     0.0\n","163  0.449254     0.0\n","164  0.449254     0.0\n","165  0.449254     0.0\n","\n","[166 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ETRo_602oyeb","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595956413625,"user_tz":420,"elapsed":626,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"b73c6f64-eb40-4e94-9cf7-81f6ae62c54f"},"source":["# see the total prediction accuracy\n","sum((df[\"preds\"]>=0.5) == df[\"labels\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["157"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KDloKGx2o1bU","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1595956414429,"user_tz":420,"elapsed":638,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"61b30155-dab0-4408-c315-39036fa0d7d8"},"source":["# find the index of the review that has the lowest predicted probabilty(of being a positive review) in true_label == 1 group. \n","df.loc[df.loc[df['labels'] == 1, :].idxmin()]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      preds  labels\n","0  0.449254     1.0\n","0  0.449254     1.0"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"trx9wVRNo3Yz","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595956415343,"user_tz":420,"elapsed":359,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"7bf93cc3-aa0b-48a2-e09f-648b003270b8"},"source":["# see that review\n","valid_raw.iloc[86,0]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'The Official Nintendo Wii Power Supply Adapter was everything it was advertised to be. It works great!'"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"utWV2ohvo5R9","colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"status":"ok","timestamp":1595956416997,"user_tz":420,"elapsed":696,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"faae472f-981c-43b7-af3b-771f56e869f4"},"source":["# alternatively, for all the reviews that have true_label == 1, \n","# let's sort their predicted probabilities\n","df.loc[df['labels'] == 1, :].sort_values('preds')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>0.449254</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        preds  labels\n","0    0.449254     1.0\n","60   0.449254     1.0\n","124  0.449254     1.0\n","12   0.449254     1.0\n","49   0.449254     1.0\n","84   0.449254     1.0\n","96   0.449254     1.0\n","142  0.449254     1.0\n","152  0.449254     1.0"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LnX5KHL9o8DI","colab":{"base_uri":"https://localhost:8080/","height":194},"executionInfo":{"status":"ok","timestamp":1595956418834,"user_tz":420,"elapsed":692,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"23ae42e1-a506-4268-93f3-15f1a304e3dd"},"source":["df[df['labels']==1].preds.sort_values()[0:20]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      0.449254\n","60     0.449254\n","124    0.449254\n","12     0.449254\n","49     0.449254\n","84     0.449254\n","96     0.449254\n","142    0.449254\n","152    0.449254\n","Name: preds, dtype: float32"]},"metadata":{"tags":[]},"execution_count":104}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"t4UdGbAFo-fw","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595956420650,"user_tz":420,"elapsed":684,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"41a53369-c83d-4625-84ec-cc390ac676f3"},"source":["# see the reviews\n","valid_raw.iloc[133,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'it fits'"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lTHtgNiHpWXW","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1595956421805,"user_tz":420,"elapsed":831,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"ab563b93-4af0-421d-fbcd-c4d300019f6d"},"source":["# on the other way around, for all the reviews whose label == 0, \n","# let's sort their predicted probablities in descending order\n","df[df['labels'] == 0].sort_values('preds', ascending = False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>0.449254</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>157 rows × 2 columns</p>\n","</div>"],"text/plain":["        preds  labels\n","1    0.449254     0.0\n","63   0.449254     0.0\n","109  0.449254     0.0\n","106  0.449254     0.0\n","104  0.449254     0.0\n","..        ...     ...\n","101  0.449254     0.0\n","99   0.449254     0.0\n","98   0.449254     0.0\n","37   0.449254     0.0\n","113  0.449254     0.0\n","\n","[157 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ce7ouajapZE6","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1595956423317,"user_tz":420,"elapsed":715,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"068ab343-5c74-4346-c6e2-e2418bfdfce9"},"source":["# see the reviews\n","# after learning some examples, it seems that our model will give a high score as long as the food is good\n","# even though the service is not. \n","valid_raw.iloc[51,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"I'm giving this five stars purely on function, it is not the best tactile experience and lacts some programming features but fills a nitch that i could not find anywhere else. If you are no longer using a cable STB and watch a majority of video content on the web (I'm using it with a Mac mini htpc) and don't want a 40 button monster remote then this is a perfect fit, Of the three functions, one is your tv which becomes the standard channel up/down volume up/down input select and mute. The next two become your audio receiver or a/v receiver and the last becomes your media device (apple tv or htpc for example). Programming is pretty standard but I could not reprogram the menu button since it is used to exit the programming mode. Other than that the only other problem I have with it is the small throw of the buttons. I could not find the programming code map on the web so if you are wondering it includes a very large tv, av receiver and audio receiver list along with a list of media devices like apple. That is it - no DVD/blue ray for example. This product is all about simplification - it's very small (half the size of a standard universal remote), goes completely black (other than the ar label) when it's not moving (it has a tilt sensor to activate the button LEDs) and limits the buttons to an absolute minimum.\""]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"markdown","metadata":{"id":"Fdy6EYFbFkAL","colab_type":"text"},"source":["# **Save and Load a Trained Model**"]},{"cell_type":"code","metadata":{"id":"exsBdFijFjfN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596593904198,"user_tz":420,"elapsed":7025,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"ad0036d7-4fb6-4388-9eee-60a9251c3f6d"},"source":["# check the tutorial here:\n","# https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch\n","\n","# if you want to save the trained model for later evaluation (not for training)\n","#dir = \"/content/drive/My Drive/\" \n","#torch.save(model_amazon.state_dict(), os.path.join(dir, 'amazon_health.pt'))\n","\n","# later if you want to load the model and use it for evaluation (not trianing), do this: \n","# the_model = TheModelClass(*args, **kwargs), in our case\n","model_amazon = AmazonBERT()\n","\n","# and the_model.load_state_dict(torch.load(PATH)), note that path is specified above\n","model_amazon.load_state_dict(torch.load('/content/drive/My Drive/amazon_health.pt'))"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Rff1OjRnF72P","colab_type":"text"},"source":["# **Prediction of New Amazon Reviews**"]},{"cell_type":"code","metadata":{"id":"GuUTu6WzGBI3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596594038212,"user_tz":420,"elapsed":748,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"CmUpp-K0wpiX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596594041086,"user_tz":420,"elapsed":1651,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["current_reviews = pd.read_csv('all_reviews_v3.0.csv')"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-VXzHLTawIx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596594041553,"user_tz":420,"elapsed":505,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"b627e1b3-f384-440a-8502-94006f0a24ae"},"source":["current_reviews.shape"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(135800, 14)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"CekWyYxmaj-b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596594044565,"user_tz":420,"elapsed":1083,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["current_reviews['health'] = np.nan"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqt1M6-Qv6CG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596594046460,"user_tz":420,"elapsed":965,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["current = pd.DataFrame(None)\n","\n","current[['text','label']] = current_reviews[['text','health']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"y10eM0wUympS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1596594048570,"user_tz":420,"elapsed":915,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"06b4fef1-b81d-496a-c1c6-8518b072ecf1"},"source":["current.head()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This Columbia jacket is a pretty good quality ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Just as expected! Perfect rain jacket for todd...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I bought this for a Birthday gift and haven't ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>This is perfect for those fall and spring days...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>good color</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  This Columbia jacket is a pretty good quality ...    NaN\n","1  Just as expected! Perfect rain jacket for todd...    NaN\n","2  I bought this for a Birthday gift and haven't ...    NaN\n","3  This is perfect for those fall and spring days...    NaN\n","4                                         good color    NaN"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"q8p3RTmMz6bm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596594054729,"user_tz":420,"elapsed":1263,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"9ab8c46c-e357-4c46-d048-cb51831d9160"},"source":["current.shape"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(135800, 2)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"ot5U7kUnCm0D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596594058207,"user_tz":420,"elapsed":1027,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"02efa4c3-f76f-4244-c029-9d387369c287"},"source":["current['text'].isnull().sum()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"Pwjf-YwQysAH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596594085781,"user_tz":420,"elapsed":1291,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["processed=AmazonDataset(current,tokenizer,max_length)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDkcl82ny3As","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596594088262,"user_tz":420,"elapsed":912,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["pred_sampler=SequentialSampler(processed)\n","pred_loader=DataLoader(processed,batch_size=valid_batch,num_workers=0)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"fAooRnMUVPwZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596594090612,"user_tz":420,"elapsed":894,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"bdf2b4a2-a18e-47eb-d239-abceebb6c195"},"source":["model_amazon.to(device)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AmazonBERT(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"6Jyc2JxBzPGB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1596596151334,"user_tz":420,"elapsed":2049845,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"a9307693-6264-4f20-aad2-d29930c358e6"},"source":["model_amazon.eval()\n","predictions_2 = []\n","for step, batch in enumerate(pred_loader):\n","  input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n","  attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n","  \n","  with torch.no_grad():\n","    prediction_2 = model_amazon(input_ids, attention_mask)\n","\n","  prediction_2 = prediction_2.detach().cpu().numpy()\n","  predictions_2.append(prediction_2)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9pP3QG1aQwUo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":585},"executionInfo":{"status":"ok","timestamp":1596596232381,"user_tz":420,"elapsed":958,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"080acdad-3e3b-482d-93b0-e84a28981b51"},"source":["predictions_2=np.asarray(predictions_2)\n","predictions_2[0]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.00586069],\n","       [0.00627835],\n","       [0.00581595],\n","       [0.0063597 ],\n","       [0.00553786],\n","       [0.01319154],\n","       [0.00575154],\n","       [0.0091722 ],\n","       [0.00681635],\n","       [0.00585504],\n","       [0.00555751],\n","       [0.00547979],\n","       [0.0058609 ],\n","       [0.00574112],\n","       [0.00561169],\n","       [0.00576321],\n","       [0.00547936],\n","       [0.00613483],\n","       [0.00624798],\n","       [0.00650673],\n","       [0.00550462],\n","       [0.00642864],\n","       [0.00598508],\n","       [0.00646051],\n","       [0.00563063],\n","       [0.00628307],\n","       [0.00609014],\n","       [0.00544106],\n","       [0.00555814],\n","       [0.00630912],\n","       [0.00539136],\n","       [0.00617186]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"3Uq0cRp60Sjo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596596243248,"user_tz":420,"elapsed":1013,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"865aea50-6c90-47c6-f3e6-ccbe114530ec"},"source":["pred_3=np.concatenate(predictions_2,axis=0)\n","pred_3=np.concatenate(pred_3,axis=0)\n","pred_3=pred_3.reshape(len(pred_3),1)\n","print(pred_3.shape)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["(135800, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zNXqgNOW00a3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1596596255972,"user_tz":420,"elapsed":947,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"b00725f6-ed08-4efb-847b-d4e2effd1c80"},"source":["df_3=pd.DataFrame(data=pred_3,columns=['preds'])\n","df_3"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.005861</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.006278</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.005816</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.006360</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.005538</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>135795</th>\n","      <td>0.005483</td>\n","    </tr>\n","    <tr>\n","      <th>135796</th>\n","      <td>0.005483</td>\n","    </tr>\n","    <tr>\n","      <th>135797</th>\n","      <td>0.005447</td>\n","    </tr>\n","    <tr>\n","      <th>135798</th>\n","      <td>0.005450</td>\n","    </tr>\n","    <tr>\n","      <th>135799</th>\n","      <td>0.005594</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>135800 rows × 1 columns</p>\n","</div>"],"text/plain":["           preds\n","0       0.005861\n","1       0.006278\n","2       0.005816\n","3       0.006360\n","4       0.005538\n","...          ...\n","135795  0.005483\n","135796  0.005483\n","135797  0.005447\n","135798  0.005450\n","135799  0.005594\n","\n","[135800 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"OYA72UKgdLSD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596596289818,"user_tz":420,"elapsed":895,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["current_reviews['health_pred'] = df_3"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"fI2LM4UldTDs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596596293574,"user_tz":420,"elapsed":939,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["current_reviews.drop(columns=['health'], inplace=True)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qN1ovmMjjua","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1596596324596,"user_tz":420,"elapsed":1089,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"442c1661-25a5-48ad-f449-104590272374"},"source":["current_reviews.iloc[:,-1]"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         0.005861\n","1         0.006278\n","2         0.005816\n","3         0.006360\n","4         0.005538\n","            ...   \n","135795    0.005483\n","135796    0.005483\n","135797    0.005447\n","135798    0.005450\n","135799    0.005594\n","Name: health_pred, Length: 135800, dtype: float32"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"YLP_bj5tlSpU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596596788984,"user_tz":420,"elapsed":1029,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"0516001b-1518-4df0-c3cf-afe74cdb61df"},"source":["current_reviews"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>asin</th>\n","      <th>productTitle</th>\n","      <th>countReviews</th>\n","      <th>date</th>\n","      <th>imageUrlList</th>\n","      <th>numberOfHelpful</th>\n","      <th>parentReviewId</th>\n","      <th>rating</th>\n","      <th>reviewId</th>\n","      <th>text</th>\n","      <th>title</th>\n","      <th>username</th>\n","      <th>category</th>\n","      <th>health_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>B07R7DSBVH</td>\n","      <td>Columbia Boys' Big Glennaker Rain Jacket, Wate...</td>\n","      <td>1571</td>\n","      <td>7/16/2020</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>R385E1LP3AE40R</td>\n","      <td>This Columbia jacket is a pretty good quality ...</td>\n","      <td>Pretty good rain jacket</td>\n","      <td>June B Furr</td>\n","      <td>apparel</td>\n","      <td>0.005861</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>B07R7DSBVH</td>\n","      <td>Columbia Boys' Big Glennaker Rain Jacket, Wate...</td>\n","      <td>1571</td>\n","      <td>7/15/2020</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>R36I6DUHDK4HIB</td>\n","      <td>Just as expected! Perfect rain jacket for todd...</td>\n","      <td>Toddler approved</td>\n","      <td>Meeko0924</td>\n","      <td>apparel</td>\n","      <td>0.006278</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>B07R7DSBVH</td>\n","      <td>Columbia Boys' Big Glennaker Rain Jacket, Wate...</td>\n","      <td>1571</td>\n","      <td>7/14/2020</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>R4YTDBV1VENF6</td>\n","      <td>I bought this for a Birthday gift and haven't ...</td>\n","      <td>Birthday gift</td>\n","      <td>Vera T.</td>\n","      <td>apparel</td>\n","      <td>0.005816</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>B07R7DSBVH</td>\n","      <td>Columbia Boys' Big Glennaker Rain Jacket, Wate...</td>\n","      <td>1571</td>\n","      <td>7/11/2020</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>RMQ5B577OTPJY</td>\n","      <td>This is perfect for those fall and spring days...</td>\n","      <td>Good jacket</td>\n","      <td>RD</td>\n","      <td>apparel</td>\n","      <td>0.006360</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>B07R7DSBVH</td>\n","      <td>Columbia Boys' Big Glennaker Rain Jacket, Wate...</td>\n","      <td>1571</td>\n","      <td>7/10/2020</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>R12IYTDMAX94FD</td>\n","      <td>good color</td>\n","      <td>very good</td>\n","      <td>ivy</td>\n","      <td>apparel</td>\n","      <td>0.005538</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>135795</th>\n","      <td>135796</td>\n","      <td>B07FV9GW8S</td>\n","      <td>Corel Paintshop Pro 2019 Ultimate - Photo with...</td>\n","      <td>128</td>\n","      <td>11/6/2018</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>R1IP5E8DS9YEP3</td>\n","      <td>UPDATE 11/23/2018: I'm dropping the rating a s...</td>\n","      <td>Excellent Value, Potential Alternative to Phot...</td>\n","      <td>Amazon Customer</td>\n","      <td>software</td>\n","      <td>0.005483</td>\n","    </tr>\n","    <tr>\n","      <th>135796</th>\n","      <td>135797</td>\n","      <td>B07FV9GW8S</td>\n","      <td>Corel Paintshop Pro 2019 Ultimate - Photo with...</td>\n","      <td>128</td>\n","      <td>11/5/2018</td>\n","      <td>NaN</td>\n","      <td>12</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>R2AVKQCZXW4IGN</td>\n","      <td>PaintShop Pro 2019 comes in a box with a DVD, ...</td>\n","      <td>A Quirky but Reasonable Application for Image ...</td>\n","      <td>Jeffrey N. Fritz</td>\n","      <td>software</td>\n","      <td>0.005483</td>\n","    </tr>\n","    <tr>\n","      <th>135797</th>\n","      <td>135798</td>\n","      <td>B07FV9GW8S</td>\n","      <td>Corel Paintshop Pro 2019 Ultimate - Photo with...</td>\n","      <td>128</td>\n","      <td>10/31/2018</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>R1YTIJIGJ4IMT7</td>\n","      <td>I see by the reviews that a LOT of folks had p...</td>\n","      <td>Some times you eat the bear and sometimes...</td>\n","      <td>enubrius</td>\n","      <td>software</td>\n","      <td>0.005447</td>\n","    </tr>\n","    <tr>\n","      <th>135798</th>\n","      <td>135799</td>\n","      <td>B07FV9GW8S</td>\n","      <td>Corel Paintshop Pro 2019 Ultimate - Photo with...</td>\n","      <td>128</td>\n","      <td>10/30/2018</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>R3FO4N6RUDI1EY</td>\n","      <td>I had the disc and still experienced installat...</td>\n","      <td>Paintshop Pro 2019 Ultimate - Photo with Multi...</td>\n","      <td>new yorker</td>\n","      <td>software</td>\n","      <td>0.005450</td>\n","    </tr>\n","    <tr>\n","      <th>135799</th>\n","      <td>135800</td>\n","      <td>B07FV9GW8S</td>\n","      <td>Corel Paintshop Pro 2019 Ultimate - Photo with...</td>\n","      <td>128</td>\n","      <td>10/2/2018</td>\n","      <td>NaN</td>\n","      <td>13</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>R15TC7MFA0X2K6</td>\n","      <td>I hate this software. It is not user friendly....</td>\n","      <td>Not user friendly</td>\n","      <td>Reginald M. Partee</td>\n","      <td>software</td>\n","      <td>0.005594</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>135800 rows × 15 columns</p>\n","</div>"],"text/plain":["         index        asin  ...  category  health_pred\n","0            1  B07R7DSBVH  ...   apparel     0.005861\n","1            2  B07R7DSBVH  ...   apparel     0.006278\n","2            3  B07R7DSBVH  ...   apparel     0.005816\n","3            4  B07R7DSBVH  ...   apparel     0.006360\n","4            5  B07R7DSBVH  ...   apparel     0.005538\n","...        ...         ...  ...       ...          ...\n","135795  135796  B07FV9GW8S  ...  software     0.005483\n","135796  135797  B07FV9GW8S  ...  software     0.005483\n","135797  135798  B07FV9GW8S  ...  software     0.005447\n","135798  135799  B07FV9GW8S  ...  software     0.005450\n","135799  135800  B07FV9GW8S  ...  software     0.005594\n","\n","[135800 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"3tZnN3TxVqBq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596596537557,"user_tz":420,"elapsed":2608,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}}},"source":["current_reviews.to_csv(r'predicted_health_reviews.csv', index = False)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjekXTv01OMx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1596404628773,"user_tz":420,"elapsed":1174,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"05ec537f-eec0-48bc-e095-815de751286a"},"source":["df_3.sort_values(by='preds',ascending=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21447</th>\n","      <td>0.984972</td>\n","    </tr>\n","    <tr>\n","      <th>22830</th>\n","      <td>0.984953</td>\n","    </tr>\n","    <tr>\n","      <th>21666</th>\n","      <td>0.984952</td>\n","    </tr>\n","    <tr>\n","      <th>21897</th>\n","      <td>0.984939</td>\n","    </tr>\n","    <tr>\n","      <th>22304</th>\n","      <td>0.984931</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19865</th>\n","      <td>0.005310</td>\n","    </tr>\n","    <tr>\n","      <th>3942</th>\n","      <td>0.005308</td>\n","    </tr>\n","    <tr>\n","      <th>20639</th>\n","      <td>0.005304</td>\n","    </tr>\n","    <tr>\n","      <th>10287</th>\n","      <td>0.005296</td>\n","    </tr>\n","    <tr>\n","      <th>10803</th>\n","      <td>0.005296</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 1 columns</p>\n","</div>"],"text/plain":["          preds\n","21447  0.984972\n","22830  0.984953\n","21666  0.984952\n","21897  0.984939\n","22304  0.984931\n","...         ...\n","19865  0.005310\n","3942   0.005308\n","20639  0.005304\n","10287  0.005296\n","10803  0.005296\n","\n","[25000 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"lB6A93B8G7AE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596404634911,"user_tz":420,"elapsed":2999,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"9e2c095e-6688-4f1d-f35a-13dc58444683"},"source":["current.iloc[4553,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Ordered Xl, too big. I wear other Cherokee xl and they fit fine, this cut is generous. No drawstring to hold up- so they fall down'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"dl7d9spYHGRU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596088565294,"user_tz":420,"elapsed":421,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"d79378e5-d3fd-4383-80f9-079564baf511"},"source":["current.iloc[2798,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'This unit keeps failing. Either shuts off all together or the alert keeps going and have to unplug to stop. Seems a pain to return but Iâ€™m considering doing so.'"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"UF92NtOsHK86","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596088584630,"user_tz":420,"elapsed":306,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"d0c650b1-33e8-4a59-84b0-a22491cd0b7c"},"source":["current.iloc[4723,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"I've tried so many hand soap and I have to say this would remain one of my favorites. It helps my hands stay clean while not hurting my sensitive skin. I have to say the fresh scent is okay. I personally like it very much but my friend would not. Also, it does not have a moisturizing feature. But this is a value purchase.\""]},"metadata":{"tags":[]},"execution_count":135}]},{"cell_type":"code","metadata":{"id":"vHR5B3LDHQbP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596088598867,"user_tz":420,"elapsed":348,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"11f9ea6e-cc53-4788-b3cc-02d1b2c19c2f"},"source":["current.iloc[2803,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Amazing microwave, quiet and has all the easy-button features we like...'"]},"metadata":{"tags":[]},"execution_count":136}]},{"cell_type":"code","metadata":{"id":"SsN2KUk5HW2n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596088610656,"user_tz":420,"elapsed":337,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"90915dea-e45c-46b4-bd0c-1203b110d29d"},"source":["current.iloc[2287,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Packaged well, shipping was fast. Great microwave!'"]},"metadata":{"tags":[]},"execution_count":137}]},{"cell_type":"code","metadata":{"id":"_SCNtblYHe9g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596088620869,"user_tz":420,"elapsed":285,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"a5d0656b-3001-4288-99da-9fc2fa92b969"},"source":["current.iloc[4639,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Works well I put it in another container... looks good now too'"]},"metadata":{"tags":[]},"execution_count":138}]},{"cell_type":"code","metadata":{"id":"fXpjd6bTHkQ9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596088634825,"user_tz":420,"elapsed":337,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"d3786ff5-9f86-4a37-a771-a4df69f96c65"},"source":["current.iloc[513,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Great quality jacket, fits perfectly. I definitely recommend.'"]},"metadata":{"tags":[]},"execution_count":139}]},{"cell_type":"code","metadata":{"id":"fLJ3FTcEHv0o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596088637524,"user_tz":420,"elapsed":342,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"7a0b89a9-8acf-4721-d276-8943879a9e22"},"source":["df_3.iloc[2500]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["preds    0.005441\n","Name: 2500, dtype: float32"]},"metadata":{"tags":[]},"execution_count":140}]},{"cell_type":"code","metadata":{"id":"_bqQE_H3HsL7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596088639736,"user_tz":420,"elapsed":371,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"4e5238fa-3c39-4a97-8574-172baf6396f2"},"source":["current.iloc[2500,0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"I got one, which was not in working condition, the smart keypad wasn't functioning so I sent it back and got the replacement next day. But somehow not happy with the replacement also as sometime touchpad is not functioning and I need to push couple of times\""]},"metadata":{"tags":[]},"execution_count":141}]},{"cell_type":"code","metadata":{"id":"RhHsZkcjVk4J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":194},"executionInfo":{"status":"ok","timestamp":1596404643613,"user_tz":420,"elapsed":3457,"user":{"displayName":"Carla Mariana Fera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSCtac3ASEWb2g_EfjxzWYfF0-FKdhkDhMk5t=s64","userId":"13606735559788586873"}},"outputId":"eef11d79-2029-4164-cdb4-faf84887bb1a"},"source":["for ind in df_3.index:\n","  if df_3['preds'][ind] >= 0.5:\n","    current.label[ind]=1\n","  else:\n","    current.label[ind]=0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]}]}